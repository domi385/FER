----------------------------------------
Starting experiment resnet_11-1559491145
Experiment parameters Experiment[name: resnet_11-1559491145, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 0.001, weight_decay: 0, batch_size: 32, num_epochs: 20), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.499542236328125, 0.6662596414107496
train metrics acc, f1
0.5000267028808594, 0.6666785348249913
Epoch 1/20
----------
eval metrics, batch: 1024 acc, f1
0.808837890625, 0.8121513824746597
eval metrics, batch: 2048 acc, f1
0.776031494140625, 0.7841914899873556
eval metrics, batch: 3072 acc, f1
0.773956298828125, 0.7816783093111681
eval metrics, batch: 4096 acc, f1
0.806243896484375, 0.8077982623437169
train metrics, batch: 4096  acc, f1 
0.82379150390625, 0.8312645659972092
eval metrics, batch: 5120 acc, f1
0.7808837890625, 0.7582654366709313
eval metrics, batch: 6144 acc, f1
0.80938720703125, 0.8030895334174023
eval metrics, batch: 7168 acc, f1
0.735748291015625, 0.6681994098938575
Epoch loss - train: tensor(0.4350, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4092, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8184814453125, 0.8072585871678548
train metrics acc, f1 
0.8569908142089844, 0.8554507212233614
Epoch 2/20
----------
eval metrics, batch: 1024 acc, f1
0.767669677734375, 0.743971750462418
eval metrics, batch: 2048 acc, f1
0.711212158203125, 0.6266324718879464
eval metrics, batch: 3072 acc, f1
0.82684326171875, 0.8192533129459735
eval metrics, batch: 4096 acc, f1
0.787994384765625, 0.7594612374917766
train metrics, batch: 4096  acc, f1 
0.8547134399414062, 0.8471583475797195
eval metrics, batch: 5120 acc, f1
0.81219482421875, 0.8214679431389614
eval metrics, batch: 6144 acc, f1
0.77862548828125, 0.7417034610454352
eval metrics, batch: 7168 acc, f1
0.823944091796875, 0.8205096294452568
Epoch loss - train: tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3929, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8226318359375, 0.8288272368498557
train metrics acc, f1 
0.8572349548339844, 0.8678295080114565
Epoch 3/20
----------
eval metrics, batch: 1024 acc, f1
0.72802734375, 0.6475520050620897
eval metrics, batch: 2048 acc, f1
0.806884765625, 0.7913892002373574
eval metrics, batch: 3072 acc, f1
0.822967529296875, 0.8195364753460881
eval metrics, batch: 4096 acc, f1
0.7939453125, 0.7663991143094382
train metrics, batch: 4096  acc, f1 
0.8802108764648438, 0.8765032995902058
eval metrics, batch: 5120 acc, f1
0.82562255859375, 0.8170583338669398
eval metrics, batch: 6144 acc, f1
0.8204345703125, 0.8064218976181077
eval metrics, batch: 7168 acc, f1
0.83160400390625, 0.8315217391304348
Epoch loss - train: tensor(0.3114, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4465, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8026123046875, 0.7751981092729042
train metrics acc, f1 
0.8894119262695312, 0.8850861754586247
Epoch 4/20
----------
eval metrics, batch: 1024 acc, f1
0.821014404296875, 0.8123139940478096
eval metrics, batch: 2048 acc, f1
0.813934326171875, 0.814697747925721
eval metrics, batch: 3072 acc, f1
0.82958984375, 0.8175521139645822
eval metrics, batch: 4096 acc, f1
0.809722900390625, 0.7894647982441331
train metrics, batch: 4096  acc, f1 
0.8977432250976562, 0.8960967479359665
eval metrics, batch: 5120 acc, f1
0.79327392578125, 0.759103840682788
eval metrics, batch: 6144 acc, f1
0.769073486328125, 0.7208058148544442
eval metrics, batch: 7168 acc, f1
0.807586669921875, 0.7794760588996538
Epoch loss - train: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5954, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.743896484375, 0.6665077094261643
train metrics acc, f1 
0.8491401672363281, 0.8270708254441621
Epoch 5/20
----------
eval metrics, batch: 1024 acc, f1
0.836944580078125, 0.8275951082572359
eval metrics, batch: 2048 acc, f1
0.819000244140625, 0.7973762426975505
eval metrics, batch: 3072 acc, f1
0.851654052734375, 0.8516766850761297
eval metrics, batch: 4096 acc, f1
0.847015380859375, 0.8391980753809142
train metrics, batch: 4096  acc, f1 
0.9128761291503906, 0.9139997514770173
eval metrics, batch: 5120 acc, f1
0.81439208984375, 0.7868059450364554
eval metrics, batch: 6144 acc, f1
0.79241943359375, 0.7540675392291561
eval metrics, batch: 7168 acc, f1
0.8187255859375, 0.8060344827586207
Epoch loss - train: tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5357, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.75531005859375, 0.6910688140556369
train metrics acc, f1 
0.9033927917480469, 0.8965900228257363
Epoch 6/20
----------
eval metrics, batch: 1024 acc, f1
0.836578369140625, 0.8222052524984229
eval metrics, batch: 2048 acc, f1
0.83221435546875, 0.8208069878104426
eval metrics, batch: 3072 acc, f1
0.85546875, 0.851340322681901
eval metrics, batch: 4096 acc, f1
0.844757080078125, 0.8410362176181995
train metrics, batch: 4096  acc, f1 
0.9070205688476562, 0.9106302157429271
eval metrics, batch: 5120 acc, f1
0.844757080078125, 0.8370647961308094
eval metrics, batch: 6144 acc, f1
0.824676513671875, 0.8055245252361125
eval metrics, batch: 7168 acc, f1
0.764404296875, 0.7046897712493306
Epoch loss - train: tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4379, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.821197509765625, 0.8011269135467228
train metrics acc, f1 
0.9275054931640625, 0.9271849496149278
Epoch 7/20
----------
eval metrics, batch: 1024 acc, f1
0.80218505859375, 0.7694879089615931
eval metrics, batch: 2048 acc, f1
0.825958251953125, 0.8089127156977718
eval metrics, batch: 3072 acc, f1
0.84893798828125, 0.8415492957746479
eval metrics, batch: 4096 acc, f1
0.72918701171875, 0.6432419393744472
train metrics, batch: 4096  acc, f1 
0.9004364013671875, 0.8921523255429572
eval metrics, batch: 5120 acc, f1
0.790985107421875, 0.7472227348219229
eval metrics, batch: 6144 acc, f1
0.822601318359375, 0.799143084205798
eval metrics, batch: 7168 acc, f1
0.815643310546875, 0.7899147974265345
Epoch loss - train: tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3962, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.824066162109375, 0.8028183466155898
train metrics acc, f1 
0.9365653991699219, 0.936203026989699
Epoch 8/20
----------
eval metrics, batch: 1024 acc, f1
0.82769775390625, 0.8079983676800653
eval metrics, batch: 2048 acc, f1
0.80859375, 0.7780608634111819
eval metrics, batch: 3072 acc, f1
0.83905029296875, 0.8244925124792013
eval metrics, batch: 4096 acc, f1
0.83209228515625, 0.8152327221438646
train metrics, batch: 4096  acc, f1 
0.93878173828125, 0.9391244973825962
eval metrics, batch: 5120 acc, f1
0.81402587890625, 0.7854074230579619
eval metrics, batch: 6144 acc, f1
0.804931640625, 0.7741183122482154
eval metrics, batch: 7168 acc, f1
0.769561767578125, 0.7151103565365026
Epoch loss - train: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3341, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.854766845703125, 0.846952886316128
train metrics acc, f1 
0.9362106323242188, 0.9373703173806546
Epoch 9/20
----------
eval metrics, batch: 1024 acc, f1
0.832855224609375, 0.8179975409563686
eval metrics, batch: 2048 acc, f1
0.808349609375, 0.7780918727915195
eval metrics, batch: 3072 acc, f1
0.76422119140625, 0.6994943601711396
eval metrics, batch: 4096 acc, f1
0.7469482421875, 0.6740566037735849
train metrics, batch: 4096  acc, f1 
0.9204826354980469, 0.915487875581287
eval metrics, batch: 5120 acc, f1
0.826873779296875, 0.8026439380761872
eval metrics, batch: 6144 acc, f1
0.831146240234375, 0.813709976095081
eval metrics, batch: 7168 acc, f1
0.8240966796875, 0.8004569687738005
Epoch loss - train: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3693, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.85174560546875, 0.8414904724614983
train metrics acc, f1 
0.9456939697265625, 0.9463549556475013
Epoch 10/20
----------
eval metrics, batch: 1024 acc, f1
0.824005126953125, 0.7992480941274759
eval metrics, batch: 2048 acc, f1
0.833984375, 0.8168103448275862
eval metrics, batch: 3072 acc, f1
0.85107421875, 0.8402514076207935
eval metrics, batch: 4096 acc, f1
0.808807373046875, 0.7748913082533865
train metrics, batch: 4096  acc, f1 
0.9468040466308594, 0.9454499935455353
eval metrics, batch: 5120 acc, f1
0.84686279296875, 0.8350861049033784
eval metrics, batch: 6144 acc, f1
0.7957763671875, 0.7574659321542476
eval metrics, batch: 7168 acc, f1
0.80419921875, 0.7725790443782787
Epoch loss - train: tensor(0.1617, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3827, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8587646484375, 0.8517236960143535
train metrics acc, f1 
0.9423828125, 0.9433054314777973
Epoch 11/20
----------
eval metrics, batch: 1024 acc, f1
0.827362060546875, 0.8039915456844877
eval metrics, batch: 2048 acc, f1
0.769195556640625, 0.7131424236677413
eval metrics, batch: 3072 acc, f1
0.834808349609375, 0.8216768242464174
eval metrics, batch: 4096 acc, f1
0.848480224609375, 0.83578634033405
train metrics, batch: 4096  acc, f1 
0.9516792297363281, 0.9518988687671118
eval metrics, batch: 5120 acc, f1
0.823516845703125, 0.8008128681155926
eval metrics, batch: 6144 acc, f1
0.79852294921875, 0.7622956722114208
eval metrics, batch: 7168 acc, f1
0.796142578125, 0.7551319648093842
Epoch loss - train: tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4815, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.825775146484375, 0.799761495563116
train metrics acc, f1 
0.9561996459960938, 0.9554422402284933
Epoch 12/20
----------
eval metrics, batch: 1024 acc, f1
0.833221435546875, 0.814298820890958
eval metrics, batch: 2048 acc, f1
0.814483642578125, 0.7867840482620743
eval metrics, batch: 3072 acc, f1
0.837005615234375, 0.8194204956554079
eval metrics, batch: 4096 acc, f1
0.796783447265625, 0.7576694930674334
train metrics, batch: 4096  acc, f1 
0.9452400207519531, 0.9434653328869897
eval metrics, batch: 5120 acc, f1
0.858489990234375, 0.8502115838098007
eval metrics, batch: 6144 acc, f1
0.830078125, 0.8109466250169768
eval metrics, batch: 7168 acc, f1
0.850494384765625, 0.8429858017371238
Epoch loss - train: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4654, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.82135009765625, 0.7937861068056925
train metrics acc, f1 
0.9529800415039062, 0.9521353847109717
Epoch 13/20
----------
eval metrics, batch: 1024 acc, f1
0.84674072265625, 0.8323653114360104
eval metrics, batch: 2048 acc, f1
0.851318359375, 0.8413752686071498
eval metrics, batch: 3072 acc, f1
0.787017822265625, 0.7401809314619708
eval metrics, batch: 4096 acc, f1
0.840362548828125, 0.8272171758876962
train metrics, batch: 4096  acc, f1 
0.957489013671875, 0.9580661669526476
eval metrics, batch: 5120 acc, f1
0.7357177734375, 0.6491654513044888
eval metrics, batch: 6144 acc, f1
0.8408203125, 0.8259244426645308
eval metrics, batch: 7168 acc, f1
0.808746337890625, 0.7749649897662394
Epoch loss - train: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5408, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.811126708984375, 0.7801655241004511
train metrics acc, f1 
0.9615592956542969, 0.9610672601040834
Epoch 14/20
----------
eval metrics, batch: 1024 acc, f1
0.845123291015625, 0.8273985647723021
eval metrics, batch: 2048 acc, f1
0.841094970703125, 0.8261145433294373
eval metrics, batch: 3072 acc, f1
0.826904296875, 0.8008426966292135
eval metrics, batch: 4096 acc, f1
0.847320556640625, 0.830665087155187
train metrics, batch: 4096  acc, f1 
0.966949462890625, 0.9667954378219279
eval metrics, batch: 5120 acc, f1
0.817291259765625, 0.7887363703729843
eval metrics, batch: 6144 acc, f1
0.85565185546875, 0.8525744919586087
eval metrics, batch: 7168 acc, f1
0.813323974609375, 0.788023703087639
Epoch loss - train: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5056, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.828582763671875, 0.8054718614718614
train metrics acc, f1 
0.9666709899902344, 0.9665936368467941
Epoch 15/20
----------
eval metrics, batch: 1024 acc, f1
0.8458251953125, 0.8339141297915708
eval metrics, batch: 2048 acc, f1
0.8060302734375, 0.77207200745894
eval metrics, batch: 3072 acc, f1
0.82318115234375, 0.7983152325257589
eval metrics, batch: 4096 acc, f1
0.82623291015625, 0.8016995193982029
train metrics, batch: 4096  acc, f1 
0.968414306640625, 0.9682442279665567
eval metrics, batch: 5120 acc, f1
0.84619140625, 0.8329577091342967
eval metrics, batch: 6144 acc, f1
0.82550048828125, 0.8002515195975687
eval metrics, batch: 7168 acc, f1
0.8192138671875, 0.7914671923401858
Epoch loss - train: tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5549, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.80108642578125, 0.7688652482269503
train metrics acc, f1 
0.9679336547851562, 0.9678812147518684
Epoch 16/20
----------
eval metrics, batch: 1024 acc, f1
0.83258056640625, 0.8120074018230417
eval metrics, batch: 2048 acc, f1
0.83355712890625, 0.8133214676889375
eval metrics, batch: 3072 acc, f1
0.850372314453125, 0.8389554935128921
eval metrics, batch: 4096 acc, f1
0.795074462890625, 0.7576424730212582
train metrics, batch: 4096  acc, f1 
0.9648513793945312, 0.9644581938251223
eval metrics, batch: 5120 acc, f1
0.823455810546875, 0.800138193124892
eval metrics, batch: 6144 acc, f1
0.809539794921875, 0.7758180969144006
eval metrics, batch: 7168 acc, f1
0.83941650390625, 0.8261300555114988
Epoch loss - train: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6309, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.80462646484375, 0.770191686409649
train metrics acc, f1 
0.976165771484375, 0.9759566542499153
Epoch 17/20
----------
eval metrics, batch: 1024 acc, f1
0.849212646484375, 0.8349644276695949
eval metrics, batch: 2048 acc, f1
0.831939697265625, 0.8096637058030622
eval metrics, batch: 3072 acc, f1
0.827972412109375, 0.8046032791431246
eval metrics, batch: 4096 acc, f1
0.8511962890625, 0.837520826391203
train metrics, batch: 4096  acc, f1 
0.9752769470214844, 0.9753876417935388
eval metrics, batch: 5120 acc, f1
0.7940673828125, 0.7503145119514542
eval metrics, batch: 6144 acc, f1
0.824310302734375, 0.8007889546351085
eval metrics, batch: 7168 acc, f1
0.82574462890625, 0.8036181042784427
Epoch loss - train: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5778, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8179931640625, 0.791599692501223
train metrics acc, f1 
0.9786796569824219, 0.9786427504193878
Epoch 18/20
----------
eval metrics, batch: 1024 acc, f1
0.8270263671875, 0.8021226085742215
eval metrics, batch: 2048 acc, f1
0.796966552734375, 0.7558263295041656
eval metrics, batch: 3072 acc, f1
0.8089599609375, 0.7755467909645034
eval metrics, batch: 4096 acc, f1
0.857635498046875, 0.8475041678925174
train metrics, batch: 4096  acc, f1 
0.9754371643066406, 0.9756896857668188
eval metrics, batch: 5120 acc, f1
0.8463134765625, 0.8343203053033293
eval metrics, batch: 6144 acc, f1
0.824615478515625, 0.801478462123044
eval metrics, batch: 7168 acc, f1
0.81414794921875, 0.7826397316011136
Epoch loss - train: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6638, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.801055908203125, 0.7671203515164505
train metrics acc, f1 
0.9797821044921875, 0.9797007974139582
Epoch 19/20
----------
eval metrics, batch: 1024 acc, f1
0.813385009765625, 0.7861813350117137
eval metrics, batch: 2048 acc, f1
0.79620361328125, 0.7549357798165137
eval metrics, batch: 3072 acc, f1
0.812408447265625, 0.7804878048780488
eval metrics, batch: 4096 acc, f1
0.807281494140625, 0.7712702379658807
train metrics, batch: 4096  acc, f1 
0.9753074645996094, 0.9749066704915935
eval metrics, batch: 5120 acc, f1
0.817169189453125, 0.790853552103334
eval metrics, batch: 6144 acc, f1
0.853973388671875, 0.8428313351946133
eval metrics, batch: 7168 acc, f1
0.813751220703125, 0.7838804490243989
Epoch loss - train: tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8958, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.790191650390625, 0.7451154858562266
train metrics acc, f1 
0.9754486083984375, 0.9749525203150783
Epoch 20/20
----------
eval metrics, batch: 1024 acc, f1
0.829132080078125, 0.8080364795830904
eval metrics, batch: 2048 acc, f1
0.830535888671875, 0.809691901710134
eval metrics, batch: 3072 acc, f1
0.838043212890625, 0.8195204897126339
eval metrics, batch: 4096 acc, f1
0.83984375, 0.824387632177754
train metrics, batch: 4096  acc, f1 
0.9798011779785156, 0.9799374822392726
eval metrics, batch: 5120 acc, f1
0.83367919921875, 0.8238070606491659
eval metrics, batch: 6144 acc, f1
0.84130859375, 0.8250807319698601
eval metrics, batch: 7168 acc, f1
0.789276123046875, 0.7449676823638043
Epoch loss - train: tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6352, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.828033447265625, 0.8051454061343754
train metrics acc, f1 
0.98193359375, 0.9818195777351247
Training time 284m 53s
train_acc
0.5000267028808594	0.82379150390625	0.8569908142089844	0.8547134399414062	0.8572349548339844	0.8802108764648438	0.8894119262695312	0.8977432250976562	0.8491401672363281	0.9128761291503906	0.9033927917480469	0.9070205688476562	0.9275054931640625	0.9004364013671875	0.9365653991699219	0.93878173828125	0.9362106323242188	0.9204826354980469	0.9456939697265625	0.9468040466308594	0.9423828125	0.9516792297363281	0.9561996459960938	0.9452400207519531	0.9529800415039062	0.957489013671875	0.9615592956542969	0.966949462890625	0.9666709899902344	0.968414306640625	0.9679336547851562	0.9648513793945312	0.976165771484375	0.9752769470214844	0.9786796569824219	0.9754371643066406	0.9797821044921875	0.9753074645996094	0.9754486083984375	0.9798011779785156	0.98193359375
train_f1
0.6666785348249913	0.8312645659972092	0.8554507212233614	0.8471583475797195	0.8678295080114565	0.8765032995902058	0.8850861754586247	0.8960967479359665	0.8270708254441621	0.9139997514770173	0.8965900228257363	0.9106302157429271	0.9271849496149278	0.8921523255429572	0.936203026989699	0.9391244973825962	0.9373703173806546	0.915487875581287	0.9463549556475013	0.9454499935455353	0.9433054314777973	0.9518988687671118	0.9554422402284933	0.9434653328869897	0.9521353847109717	0.9580661669526476	0.9610672601040834	0.9667954378219279	0.9665936368467941	0.9682442279665567	0.9678812147518684	0.9644581938251223	0.9759566542499153	0.9753876417935388	0.9786427504193878	0.9756896857668188	0.9797007974139582	0.9749066704915935	0.9749525203150783	0.9799374822392726	0.9818195777351247
train_loss
tensor(0.4350, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3114, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1617, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.499542236328125	0.808837890625	0.776031494140625	0.773956298828125	0.806243896484375	0.7808837890625	0.80938720703125	0.735748291015625	0.8184814453125	0.767669677734375	0.711212158203125	0.82684326171875	0.787994384765625	0.81219482421875	0.77862548828125	0.823944091796875	0.8226318359375	0.72802734375	0.806884765625	0.822967529296875	0.7939453125	0.82562255859375	0.8204345703125	0.83160400390625	0.8026123046875	0.821014404296875	0.813934326171875	0.82958984375	0.809722900390625	0.79327392578125	0.769073486328125	0.807586669921875	0.743896484375	0.836944580078125	0.819000244140625	0.851654052734375	0.847015380859375	0.81439208984375	0.79241943359375	0.8187255859375	0.75531005859375	0.836578369140625	0.83221435546875	0.85546875	0.844757080078125	0.844757080078125	0.824676513671875	0.764404296875	0.821197509765625	0.80218505859375	0.825958251953125	0.84893798828125	0.72918701171875	0.790985107421875	0.822601318359375	0.815643310546875	0.824066162109375	0.82769775390625	0.80859375	0.83905029296875	0.83209228515625	0.81402587890625	0.804931640625	0.769561767578125	0.854766845703125	0.832855224609375	0.808349609375	0.76422119140625	0.7469482421875	0.826873779296875	0.831146240234375	0.8240966796875	0.85174560546875	0.824005126953125	0.833984375	0.85107421875	0.808807373046875	0.84686279296875	0.7957763671875	0.80419921875	0.8587646484375	0.827362060546875	0.769195556640625	0.834808349609375	0.848480224609375	0.823516845703125	0.79852294921875	0.796142578125	0.825775146484375	0.833221435546875	0.814483642578125	0.837005615234375	0.796783447265625	0.858489990234375	0.830078125	0.850494384765625	0.82135009765625	0.84674072265625	0.851318359375	0.787017822265625	0.840362548828125	0.7357177734375	0.8408203125	0.808746337890625	0.811126708984375	0.845123291015625	0.841094970703125	0.826904296875	0.847320556640625	0.817291259765625	0.85565185546875	0.813323974609375	0.828582763671875	0.8458251953125	0.8060302734375	0.82318115234375	0.82623291015625	0.84619140625	0.82550048828125	0.8192138671875	0.80108642578125	0.83258056640625	0.83355712890625	0.850372314453125	0.795074462890625	0.823455810546875	0.809539794921875	0.83941650390625	0.80462646484375	0.849212646484375	0.831939697265625	0.827972412109375	0.8511962890625	0.7940673828125	0.824310302734375	0.82574462890625	0.8179931640625	0.8270263671875	0.796966552734375	0.8089599609375	0.857635498046875	0.8463134765625	0.824615478515625	0.81414794921875	0.801055908203125	0.813385009765625	0.79620361328125	0.812408447265625	0.807281494140625	0.817169189453125	0.853973388671875	0.813751220703125	0.790191650390625	0.829132080078125	0.830535888671875	0.838043212890625	0.83984375	0.83367919921875	0.84130859375	0.789276123046875	0.828033447265625
valid_f1
0.6662596414107496	0.8121513824746597	0.7841914899873556	0.7816783093111681	0.8077982623437169	0.7582654366709313	0.8030895334174023	0.6681994098938575	0.8072585871678548	0.743971750462418	0.6266324718879464	0.8192533129459735	0.7594612374917766	0.8214679431389614	0.7417034610454352	0.8205096294452568	0.8288272368498557	0.6475520050620897	0.7913892002373574	0.8195364753460881	0.7663991143094382	0.8170583338669398	0.8064218976181077	0.8315217391304348	0.7751981092729042	0.8123139940478096	0.814697747925721	0.8175521139645822	0.7894647982441331	0.759103840682788	0.7208058148544442	0.7794760588996538	0.6665077094261643	0.8275951082572359	0.7973762426975505	0.8516766850761297	0.8391980753809142	0.7868059450364554	0.7540675392291561	0.8060344827586207	0.6910688140556369	0.8222052524984229	0.8208069878104426	0.851340322681901	0.8410362176181995	0.8370647961308094	0.8055245252361125	0.7046897712493306	0.8011269135467228	0.7694879089615931	0.8089127156977718	0.8415492957746479	0.6432419393744472	0.7472227348219229	0.799143084205798	0.7899147974265345	0.8028183466155898	0.8079983676800653	0.7780608634111819	0.8244925124792013	0.8152327221438646	0.7854074230579619	0.7741183122482154	0.7151103565365026	0.846952886316128	0.8179975409563686	0.7780918727915195	0.6994943601711396	0.6740566037735849	0.8026439380761872	0.813709976095081	0.8004569687738005	0.8414904724614983	0.7992480941274759	0.8168103448275862	0.8402514076207935	0.7748913082533865	0.8350861049033784	0.7574659321542476	0.7725790443782787	0.8517236960143535	0.8039915456844877	0.7131424236677413	0.8216768242464174	0.83578634033405	0.8008128681155926	0.7622956722114208	0.7551319648093842	0.799761495563116	0.814298820890958	0.7867840482620743	0.8194204956554079	0.7576694930674334	0.8502115838098007	0.8109466250169768	0.8429858017371238	0.7937861068056925	0.8323653114360104	0.8413752686071498	0.7401809314619708	0.8272171758876962	0.6491654513044888	0.8259244426645308	0.7749649897662394	0.7801655241004511	0.8273985647723021	0.8261145433294373	0.8008426966292135	0.830665087155187	0.7887363703729843	0.8525744919586087	0.788023703087639	0.8054718614718614	0.8339141297915708	0.77207200745894	0.7983152325257589	0.8016995193982029	0.8329577091342967	0.8002515195975687	0.7914671923401858	0.7688652482269503	0.8120074018230417	0.8133214676889375	0.8389554935128921	0.7576424730212582	0.800138193124892	0.7758180969144006	0.8261300555114988	0.770191686409649	0.8349644276695949	0.8096637058030622	0.8046032791431246	0.837520826391203	0.7503145119514542	0.8007889546351085	0.8036181042784427	0.791599692501223	0.8021226085742215	0.7558263295041656	0.7755467909645034	0.8475041678925174	0.8343203053033293	0.801478462123044	0.7826397316011136	0.7671203515164505	0.7861813350117137	0.7549357798165137	0.7804878048780488	0.7712702379658807	0.790853552103334	0.8428313351946133	0.7838804490243989	0.7451154858562266	0.8080364795830904	0.809691901710134	0.8195204897126339	0.824387632177754	0.8238070606491659	0.8250807319698601	0.7449676823638043	0.8051454061343754
valid_loss
tensor(0.4092, device='cuda:0')	tensor(0.3929, device='cuda:0')	tensor(0.4465, device='cuda:0')	tensor(0.5954, device='cuda:0')	tensor(0.5357, device='cuda:0')	tensor(0.4379, device='cuda:0')	tensor(0.3962, device='cuda:0')	tensor(0.3341, device='cuda:0')	tensor(0.3693, device='cuda:0')	tensor(0.3827, device='cuda:0')	tensor(0.4815, device='cuda:0')	tensor(0.4654, device='cuda:0')	tensor(0.5408, device='cuda:0')	tensor(0.5056, device='cuda:0')	tensor(0.5549, device='cuda:0')	tensor(0.6309, device='cuda:0')	tensor(0.5778, device='cuda:0')	tensor(0.6638, device='cuda:0')	tensor(0.8958, device='cuda:0')	tensor(0.6352, device='cuda:0')
Best model metrics: train, valid, test: acc, f1
0.9423828125, 0.9433054314777973
0.8587646484375, 0.8517236960143535
0.81231689453125, 0.789801080046483
Model saved, path ./models/resnet_11-1559491145.pth
experiment validation
train set
Evaluation results
[[121387.   9685.]
 [  5419. 125653.]]
#############################
Accuracy
0.9423828125
------------------------
Recall
0.9586563110351562
------------------------
Specificity
0.9261093139648438
------------------------
Precision
0.9284384282315388
------------------------
Fall_out
0.07389068603515625
------------------------
F1
0.9433054314777973
------------------------
#############################
valid set
Evaluation results
[[14848.  1551.]
 [ 3077. 13292.]]
#############################
Accuracy
0.8587646484375
------------------------
Recall
0.8120227258842935
------------------------
Specificity
0.9054210622598939
------------------------
Precision
0.8955062992656471
------------------------
Fall_out
0.0945789377401061
------------------------
F1
0.8517236960143535
------------------------
#############################
test set
Evaluation results
[[15064.  1327.]
 [ 4823. 11554.]]
#############################
Accuracy
0.81231689453125
------------------------
Recall
0.7055016181229773
------------------------
Specificity
0.9190409370996279
------------------------
Precision
0.8969800481329089
------------------------
Fall_out
0.08095906290037215
------------------------
F1
0.789801080046483
------------------------
#############################
AUC: 0.9042447444349246
Experiment end
########################################
