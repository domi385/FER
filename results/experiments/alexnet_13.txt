----------------------------------------
Starting experiment alexnet_13-1559673726
Experiment parameters Experiment[name: alexnet_13-1559673726, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 1e-05, weight_decay: 0, batch_size: 32, num_epochs: 20), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.500457763671875, 0.0
train metrics acc, f1
0.5, 0.0
Epoch 1/20
----------
eval metrics, batch: 1024 acc, f1
0.76776123046875, 0.7746120127946926
eval metrics, batch: 2048 acc, f1
0.75738525390625, 0.7672580361847884
eval metrics, batch: 3072 acc, f1
0.763275146484375, 0.7712136852971538
eval metrics, batch: 4096 acc, f1
0.774627685546875, 0.7600636797816693
train metrics, batch: 4096  acc, f1 
0.8039436340332031, 0.7997147411041702
eval metrics, batch: 5120 acc, f1
0.797088623046875, 0.7970824304940947
eval metrics, batch: 6144 acc, f1
0.7862548828125, 0.7806726373144611
eval metrics, batch: 7168 acc, f1
0.774688720703125, 0.7461054369132364
Epoch loss - train: tensor(0.4487, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4310, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.795501708984375, 0.7913306137701243
train metrics acc, f1 
0.8318824768066406, 0.835076584549867
Epoch 2/20
----------
eval metrics, batch: 1024 acc, f1
0.760528564453125, 0.7854545454545454
eval metrics, batch: 2048 acc, f1
0.7933349609375, 0.7827258726899384
eval metrics, batch: 3072 acc, f1
0.7933349609375, 0.7744471089794831
eval metrics, batch: 4096 acc, f1
0.79449462890625, 0.784304932735426
train metrics, batch: 4096  acc, f1 
0.8448562622070312, 0.8449225184552498
eval metrics, batch: 5120 acc, f1
0.795989990234375, 0.7915562346044713
eval metrics, batch: 6144 acc, f1
0.792022705078125, 0.7767111169358802
eval metrics, batch: 7168 acc, f1
0.795684814453125, 0.7999043605606863
Epoch loss - train: tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4167, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.80450439453125, 0.8085475194261805
train metrics acc, f1 
0.85357666015625, 0.8614916066454006
Epoch 3/20
----------
eval metrics, batch: 1024 acc, f1
0.796234130859375, 0.782515227517019
eval metrics, batch: 2048 acc, f1
0.79168701171875, 0.7730868958180972
eval metrics, batch: 3072 acc, f1
0.79986572265625, 0.7860219263899765
eval metrics, batch: 4096 acc, f1
0.79949951171875, 0.7939793038570084
train metrics, batch: 4096  acc, f1 
0.8659400939941406, 0.8698026459593733
eval metrics, batch: 5120 acc, f1
0.77801513671875, 0.7432403812213202
eval metrics, batch: 6144 acc, f1
0.776611328125, 0.7411049020301337
eval metrics, batch: 7168 acc, f1
0.823577880859375, 0.8255845527228843
Epoch loss - train: tensor(0.3287, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4156, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.81353759765625, 0.8110231349746382
train metrics acc, f1 
0.8748397827148438, 0.8792506992492272
Epoch 4/20
----------
eval metrics, batch: 1024 acc, f1
0.804962158203125, 0.7958473087366236
eval metrics, batch: 2048 acc, f1
0.79571533203125, 0.7752635466326462
eval metrics, batch: 3072 acc, f1
0.79296875, 0.775274943686233
eval metrics, batch: 4096 acc, f1
0.775360107421875, 0.7435995680796963
train metrics, batch: 4096  acc, f1 
0.8848495483398438, 0.8808516349053476
eval metrics, batch: 5120 acc, f1
0.77880859375, 0.7503616449679686
eval metrics, batch: 6144 acc, f1
0.783966064453125, 0.7541928539185389
eval metrics, batch: 7168 acc, f1
0.790008544921875, 0.7737926953548769
Epoch loss - train: tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5861, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7498779296875, 0.693607476635514
train metrics acc, f1 
0.8785438537597656, 0.8697018681835853
Epoch 5/20
----------
eval metrics, batch: 1024 acc, f1
0.7735595703125, 0.7375309515387336
eval metrics, batch: 2048 acc, f1
0.768218994140625, 0.7233251976248588
eval metrics, batch: 3072 acc, f1
0.8045654296875, 0.7928044519218326
eval metrics, batch: 4096 acc, f1
0.7734375, 0.7399831885682264
train metrics, batch: 4096  acc, f1 
0.8989715576171875, 0.8957610107450703
eval metrics, batch: 5120 acc, f1
0.778228759765625, 0.7503178148084522
eval metrics, batch: 6144 acc, f1
0.750244140625, 0.6867008651711202
eval metrics, batch: 7168 acc, f1
0.77996826171875, 0.7492173913043478
Epoch loss - train: tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5375, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7537841796875, 0.7070230227322246
train metrics acc, f1 
0.9032096862792969, 0.8995061053615491
Epoch 6/20
----------
eval metrics, batch: 1024 acc, f1
0.79327392578125, 0.7731109324758842
eval metrics, batch: 2048 acc, f1
0.782623291015625, 0.7504991418263337
eval metrics, batch: 3072 acc, f1
0.819854736328125, 0.8200798561370356
eval metrics, batch: 4096 acc, f1
0.8099365234375, 0.8039289761994711
train metrics, batch: 4096  acc, f1 
0.9086875915527344, 0.9121839012990633
eval metrics, batch: 5120 acc, f1
0.788970947265625, 0.7620030975735673
eval metrics, batch: 6144 acc, f1
0.769561767578125, 0.7315390905535606
eval metrics, batch: 7168 acc, f1
0.786956787109375, 0.7599133335626096
Epoch loss - train: tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4394, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.804168701171875, 0.7930867700641666
train metrics acc, f1 
0.91693115234375, 0.9192512496477254
Epoch 7/20
----------
eval metrics, batch: 1024 acc, f1
0.810638427734375, 0.8027716855789708
eval metrics, batch: 2048 acc, f1
0.782623291015625, 0.7569854320903415
eval metrics, batch: 3072 acc, f1
0.761138916015625, 0.716361659720964
eval metrics, batch: 4096 acc, f1
0.742767333984375, 0.6893679749401143
train metrics, batch: 4096  acc, f1 
0.913482666015625, 0.9106594185771685
eval metrics, batch: 5120 acc, f1
0.745758056640625, 0.6879892138871203
eval metrics, batch: 6144 acc, f1
0.8023681640625, 0.7928607983623337
eval metrics, batch: 7168 acc, f1
0.80078125, 0.7858970154148901
Epoch loss - train: tensor(0.2140, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5390, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.78204345703125, 0.7523750086679148
train metrics acc, f1 
0.9312019348144531, 0.9305344246509388
Epoch 8/20
----------
eval metrics, batch: 1024 acc, f1
0.77813720703125, 0.7435987867672992
eval metrics, batch: 2048 acc, f1
0.76605224609375, 0.7260381673933243
eval metrics, batch: 3072 acc, f1
0.799072265625, 0.7794157062449746
eval metrics, batch: 4096 acc, f1
0.81005859375, 0.8012898282357448
train metrics, batch: 4096  acc, f1 
0.9251060485839844, 0.9271251303789434
eval metrics, batch: 5120 acc, f1
0.7899169921875, 0.771811190665606
eval metrics, batch: 6144 acc, f1
0.804473876953125, 0.7934092154902783
eval metrics, batch: 7168 acc, f1
0.7421875, 0.6839033151238494
Epoch loss - train: tensor(0.1919, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5236, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.783905029296875, 0.7550759226591954
train metrics acc, f1 
0.9430465698242188, 0.942948634664914
Epoch 9/20
----------
eval metrics, batch: 1024 acc, f1
0.76995849609375, 0.7324863368585421
eval metrics, batch: 2048 acc, f1
0.78143310546875, 0.7482601054481547
eval metrics, batch: 3072 acc, f1
0.795806884765625, 0.7744480026967807
eval metrics, batch: 4096 acc, f1
0.758819580078125, 0.712272909309353
train metrics, batch: 4096  acc, f1 
0.9419021606445312, 0.9402060398574054
eval metrics, batch: 5120 acc, f1
0.766815185546875, 0.7270779012037004
eval metrics, batch: 6144 acc, f1
0.7843017578125, 0.7557536802819822
eval metrics, batch: 7168 acc, f1
0.79669189453125, 0.7797540333245173
Epoch loss - train: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5618, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.799407958984375, 0.7824158363401635
train metrics acc, f1 
0.9461860656738281, 0.9466131296808595
Epoch 10/20
----------
eval metrics, batch: 1024 acc, f1
0.77947998046875, 0.7553328367305479
eval metrics, batch: 2048 acc, f1
0.7724609375, 0.7416314366899993
eval metrics, batch: 3072 acc, f1
0.76495361328125, 0.724258914506659
eval metrics, batch: 4096 acc, f1
0.760528564453125, 0.720856604176301
train metrics, batch: 4096  acc, f1 
0.95501708984375, 0.9546590585756362
eval metrics, batch: 5120 acc, f1
0.793548583984375, 0.7680756968013988
eval metrics, batch: 6144 acc, f1
0.76226806640625, 0.7240133210515128
eval metrics, batch: 7168 acc, f1
0.787506103515625, 0.7626546681664792
Epoch loss - train: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5692, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.807830810546875, 0.8029416366765765
train metrics acc, f1 
0.9370613098144531, 0.9396898040348138
Epoch 11/20
----------
eval metrics, batch: 1024 acc, f1
0.796234130859375, 0.7885620190633016
eval metrics, batch: 2048 acc, f1
0.7735595703125, 0.7407226221259348
eval metrics, batch: 3072 acc, f1
0.754180908203125, 0.7073994696501871
eval metrics, batch: 4096 acc, f1
0.79345703125, 0.7698272343898789
train metrics, batch: 4096  acc, f1 
0.9557113647460938, 0.9556948016760416
eval metrics, batch: 5120 acc, f1
0.775482177734375, 0.7472776613651197
eval metrics, batch: 6144 acc, f1
0.7708740234375, 0.7426475628984712
eval metrics, batch: 7168 acc, f1
0.78131103515625, 0.7470525944228733
Epoch loss - train: tensor(0.1254, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6184, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.79547119140625, 0.781166329262718
train metrics acc, f1 
0.9637336730957031, 0.9644368133409644
Epoch 12/20
----------
eval metrics, batch: 1024 acc, f1
0.768524169921875, 0.7306176084099869
eval metrics, batch: 2048 acc, f1
0.782562255859375, 0.7570829497800962
eval metrics, batch: 3072 acc, f1
0.795928955078125, 0.7902249270634
eval metrics, batch: 4096 acc, f1
0.79095458984375, 0.778474872259233
train metrics, batch: 4096  acc, f1 
0.9609146118164062, 0.9618693898209209
eval metrics, batch: 5120 acc, f1
0.79888916015625, 0.7908733181010409
eval metrics, batch: 6144 acc, f1
0.7596435546875, 0.7166294883787868
eval metrics, batch: 7168 acc, f1
0.76043701171875, 0.7419969762702951
Epoch loss - train: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.7661, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.762115478515625, 0.7145211499725325
train metrics acc, f1 
0.9684257507324219, 0.9677167719112123
Epoch 13/20
----------
eval metrics, batch: 1024 acc, f1
0.780853271484375, 0.7524390664322405
eval metrics, batch: 2048 acc, f1
0.783905029296875, 0.7616065717267616
eval metrics, batch: 3072 acc, f1
0.76507568359375, 0.7262641348410497
eval metrics, batch: 4096 acc, f1
0.762664794921875, 0.7244446019204195
train metrics, batch: 4096  acc, f1 
0.9691581726074219, 0.9688802669715131
eval metrics, batch: 5120 acc, f1
0.77618408203125, 0.746333702268954
eval metrics, batch: 6144 acc, f1
0.787628173828125, 0.7785239171254893
eval metrics, batch: 7168 acc, f1
0.77215576171875, 0.7410875294770426
Epoch loss - train: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.9471, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.74444580078125, 0.6908594211458948
train metrics acc, f1 
0.9753570556640625, 0.9750143106889243
Epoch 14/20
----------
eval metrics, batch: 1024 acc, f1
0.77398681640625, 0.7432572973722527
eval metrics, batch: 2048 acc, f1
0.791168212890625, 0.7926803405338262
eval metrics, batch: 3072 acc, f1
0.733428955078125, 0.6681104905201566
eval metrics, batch: 4096 acc, f1
0.770782470703125, 0.7378816960390857
train metrics, batch: 4096  acc, f1 
0.9793243408203125, 0.9792397616019857
eval metrics, batch: 5120 acc, f1
0.772674560546875, 0.7403172389750741
eval metrics, batch: 6144 acc, f1
0.796600341796875, 0.7823673469387755
eval metrics, batch: 7168 acc, f1
0.7908935546875, 0.7686385737439222
Epoch loss - train: tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.7854, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.78765869140625, 0.7756352379723978
train metrics acc, f1 
0.9731903076171875, 0.9737563387329256
Epoch 15/20
----------
eval metrics, batch: 1024 acc, f1
0.754241943359375, 0.700353488372093
eval metrics, batch: 2048 acc, f1
0.74822998046875, 0.7026384083044983
eval metrics, batch: 3072 acc, f1
0.735382080078125, 0.6823693175574197
eval metrics, batch: 4096 acc, f1
0.761688232421875, 0.7164385053923527
train metrics, batch: 4096  acc, f1 
0.9780044555664062, 0.9777686957326382
eval metrics, batch: 5120 acc, f1
0.778594970703125, 0.7634110549486385
eval metrics, batch: 6144 acc, f1
0.775238037109375, 0.742851157431654
eval metrics, batch: 7168 acc, f1
0.7615966796875, 0.7380984310044254
Epoch loss - train: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.0611, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.750518798828125, 0.7067264573991031
train metrics acc, f1 
0.9803504943847656, 0.9802182103068079
Epoch 16/20
----------
eval metrics, batch: 1024 acc, f1
0.780975341796875, 0.7566871207241415
eval metrics, batch: 2048 acc, f1
0.7862548828125, 0.7651398296559587
eval metrics, batch: 3072 acc, f1
0.77783203125, 0.7552776657254269
eval metrics, batch: 4096 acc, f1
0.768218994140625, 0.7459101401759727
train metrics, batch: 4096  acc, f1 
0.9834861755371094, 0.9836610064578466
eval metrics, batch: 5120 acc, f1
0.783294677734375, 0.757404940043046
eval metrics, batch: 6144 acc, f1
0.785247802734375, 0.7656442535051786
eval metrics, batch: 7168 acc, f1
0.777191162109375, 0.7533362613601811
Epoch loss - train: tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.0666, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7777099609375, 0.755324151830702
train metrics acc, f1 
0.9874954223632812, 0.9875702444240526
Epoch 17/20
----------
eval metrics, batch: 1024 acc, f1
0.783660888671875, 0.7653814330630482
eval metrics, batch: 2048 acc, f1
0.766021728515625, 0.7301777230336091
eval metrics, batch: 3072 acc, f1
0.77734375, 0.7513461931701997
eval metrics, batch: 4096 acc, f1
0.744110107421875, 0.691557844399485
train metrics, batch: 4096  acc, f1 
0.9787139892578125, 0.978410919896001
eval metrics, batch: 5120 acc, f1
0.731109619140625, 0.6694180767643417
eval metrics, batch: 6144 acc, f1
0.771087646484375, 0.7371114148529773
eval metrics, batch: 7168 acc, f1
0.772003173828125, 0.7450953631990174
Epoch loss - train: tensor(0.0518, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1742, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7666015625, 0.7365665472581978
train metrics acc, f1 
0.9870529174804688, 0.987125603131733
Epoch 18/20
----------
eval metrics, batch: 1024 acc, f1
0.756805419921875, 0.7060385849717806
eval metrics, batch: 2048 acc, f1
0.76324462890625, 0.7310359173484954
eval metrics, batch: 3072 acc, f1
0.760498046875, 0.7242057913972448
eval metrics, batch: 4096 acc, f1
0.778045654296875, 0.758283758184054
train metrics, batch: 4096  acc, f1 
0.9854698181152344, 0.9856072428555774
eval metrics, batch: 5120 acc, f1
0.76806640625, 0.7351731828001952
eval metrics, batch: 6144 acc, f1
0.767608642578125, 0.737928898372165
eval metrics, batch: 7168 acc, f1
0.792694091796875, 0.777037450356123
Epoch loss - train: tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1535, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.784393310546875, 0.7597020509506479
train metrics acc, f1 
0.9934501647949219, 0.9934565299410439
Epoch 19/20
----------
eval metrics, batch: 1024 acc, f1
0.7845458984375, 0.7559795382275681
eval metrics, batch: 2048 acc, f1
0.77923583984375, 0.7500518277935181
eval metrics, batch: 3072 acc, f1
0.787353515625, 0.7709702866158296
eval metrics, batch: 4096 acc, f1
0.779205322265625, 0.7587770479778615
train metrics, batch: 4096  acc, f1 
0.9823951721191406, 0.9824837077606853
eval metrics, batch: 5120 acc, f1
0.792327880859375, 0.7763205469546067
eval metrics, batch: 6144 acc, f1
0.77703857421875, 0.7509035117627003
eval metrics, batch: 7168 acc, f1
0.741790771484375, 0.6821443329952289
Epoch loss - train: tensor(0.0427, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1532, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.78460693359375, 0.7570061282104248
train metrics acc, f1 
0.991851806640625, 0.991834737534213
Epoch 20/20
----------
eval metrics, batch: 1024 acc, f1
0.792236328125, 0.7755949634122223
eval metrics, batch: 2048 acc, f1
0.763641357421875, 0.7209109581636698
eval metrics, batch: 3072 acc, f1
0.790008544921875, 0.7762349191896198
eval metrics, batch: 4096 acc, f1
0.763153076171875, 0.727961022117845
train metrics, batch: 4096  acc, f1 
0.9880027770996094, 0.9879735532892044
eval metrics, batch: 5120 acc, f1
0.778900146484375, 0.7549798775744868
eval metrics, batch: 6144 acc, f1
0.7862548828125, 0.7579485761680951
eval metrics, batch: 7168 acc, f1
0.744049072265625, 0.6872039682243688
Epoch loss - train: tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.2987, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.76324462890625, 0.7313339797755922
train metrics acc, f1 
0.9931297302246094, 0.9931343135647818
Training time 236m 19s
train_acc
0.5	0.8039436340332031	0.8318824768066406	0.8448562622070312	0.85357666015625	0.8659400939941406	0.8748397827148438	0.8848495483398438	0.8785438537597656	0.8989715576171875	0.9032096862792969	0.9086875915527344	0.91693115234375	0.913482666015625	0.9312019348144531	0.9251060485839844	0.9430465698242188	0.9419021606445312	0.9461860656738281	0.95501708984375	0.9370613098144531	0.9557113647460938	0.9637336730957031	0.9609146118164062	0.9684257507324219	0.9691581726074219	0.9753570556640625	0.9793243408203125	0.9731903076171875	0.9780044555664062	0.9803504943847656	0.9834861755371094	0.9874954223632812	0.9787139892578125	0.9870529174804688	0.9854698181152344	0.9934501647949219	0.9823951721191406	0.991851806640625	0.9880027770996094	0.9931297302246094
train_f1
0.0	0.7997147411041702	0.835076584549867	0.8449225184552498	0.8614916066454006	0.8698026459593733	0.8792506992492272	0.8808516349053476	0.8697018681835853	0.8957610107450703	0.8995061053615491	0.9121839012990633	0.9192512496477254	0.9106594185771685	0.9305344246509388	0.9271251303789434	0.942948634664914	0.9402060398574054	0.9466131296808595	0.9546590585756362	0.9396898040348138	0.9556948016760416	0.9644368133409644	0.9618693898209209	0.9677167719112123	0.9688802669715131	0.9750143106889243	0.9792397616019857	0.9737563387329256	0.9777686957326382	0.9802182103068079	0.9836610064578466	0.9875702444240526	0.978410919896001	0.987125603131733	0.9856072428555774	0.9934565299410439	0.9824837077606853	0.991834737534213	0.9879735532892044	0.9931343135647818
train_loss
tensor(0.4487, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3287, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2140, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1919, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1254, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0518, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0427, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.500457763671875	0.76776123046875	0.75738525390625	0.763275146484375	0.774627685546875	0.797088623046875	0.7862548828125	0.774688720703125	0.795501708984375	0.760528564453125	0.7933349609375	0.7933349609375	0.79449462890625	0.795989990234375	0.792022705078125	0.795684814453125	0.80450439453125	0.796234130859375	0.79168701171875	0.79986572265625	0.79949951171875	0.77801513671875	0.776611328125	0.823577880859375	0.81353759765625	0.804962158203125	0.79571533203125	0.79296875	0.775360107421875	0.77880859375	0.783966064453125	0.790008544921875	0.7498779296875	0.7735595703125	0.768218994140625	0.8045654296875	0.7734375	0.778228759765625	0.750244140625	0.77996826171875	0.7537841796875	0.79327392578125	0.782623291015625	0.819854736328125	0.8099365234375	0.788970947265625	0.769561767578125	0.786956787109375	0.804168701171875	0.810638427734375	0.782623291015625	0.761138916015625	0.742767333984375	0.745758056640625	0.8023681640625	0.80078125	0.78204345703125	0.77813720703125	0.76605224609375	0.799072265625	0.81005859375	0.7899169921875	0.804473876953125	0.7421875	0.783905029296875	0.76995849609375	0.78143310546875	0.795806884765625	0.758819580078125	0.766815185546875	0.7843017578125	0.79669189453125	0.799407958984375	0.77947998046875	0.7724609375	0.76495361328125	0.760528564453125	0.793548583984375	0.76226806640625	0.787506103515625	0.807830810546875	0.796234130859375	0.7735595703125	0.754180908203125	0.79345703125	0.775482177734375	0.7708740234375	0.78131103515625	0.79547119140625	0.768524169921875	0.782562255859375	0.795928955078125	0.79095458984375	0.79888916015625	0.7596435546875	0.76043701171875	0.762115478515625	0.780853271484375	0.783905029296875	0.76507568359375	0.762664794921875	0.77618408203125	0.787628173828125	0.77215576171875	0.74444580078125	0.77398681640625	0.791168212890625	0.733428955078125	0.770782470703125	0.772674560546875	0.796600341796875	0.7908935546875	0.78765869140625	0.754241943359375	0.74822998046875	0.735382080078125	0.761688232421875	0.778594970703125	0.775238037109375	0.7615966796875	0.750518798828125	0.780975341796875	0.7862548828125	0.77783203125	0.768218994140625	0.783294677734375	0.785247802734375	0.777191162109375	0.7777099609375	0.783660888671875	0.766021728515625	0.77734375	0.744110107421875	0.731109619140625	0.771087646484375	0.772003173828125	0.7666015625	0.756805419921875	0.76324462890625	0.760498046875	0.778045654296875	0.76806640625	0.767608642578125	0.792694091796875	0.784393310546875	0.7845458984375	0.77923583984375	0.787353515625	0.779205322265625	0.792327880859375	0.77703857421875	0.741790771484375	0.78460693359375	0.792236328125	0.763641357421875	0.790008544921875	0.763153076171875	0.778900146484375	0.7862548828125	0.744049072265625	0.76324462890625
valid_f1
0.0	0.7746120127946926	0.7672580361847884	0.7712136852971538	0.7600636797816693	0.7970824304940947	0.7806726373144611	0.7461054369132364	0.7913306137701243	0.7854545454545454	0.7827258726899384	0.7744471089794831	0.784304932735426	0.7915562346044713	0.7767111169358802	0.7999043605606863	0.8085475194261805	0.782515227517019	0.7730868958180972	0.7860219263899765	0.7939793038570084	0.7432403812213202	0.7411049020301337	0.8255845527228843	0.8110231349746382	0.7958473087366236	0.7752635466326462	0.775274943686233	0.7435995680796963	0.7503616449679686	0.7541928539185389	0.7737926953548769	0.693607476635514	0.7375309515387336	0.7233251976248588	0.7928044519218326	0.7399831885682264	0.7503178148084522	0.6867008651711202	0.7492173913043478	0.7070230227322246	0.7731109324758842	0.7504991418263337	0.8200798561370356	0.8039289761994711	0.7620030975735673	0.7315390905535606	0.7599133335626096	0.7930867700641666	0.8027716855789708	0.7569854320903415	0.716361659720964	0.6893679749401143	0.6879892138871203	0.7928607983623337	0.7858970154148901	0.7523750086679148	0.7435987867672992	0.7260381673933243	0.7794157062449746	0.8012898282357448	0.771811190665606	0.7934092154902783	0.6839033151238494	0.7550759226591954	0.7324863368585421	0.7482601054481547	0.7744480026967807	0.712272909309353	0.7270779012037004	0.7557536802819822	0.7797540333245173	0.7824158363401635	0.7553328367305479	0.7416314366899993	0.724258914506659	0.720856604176301	0.7680756968013988	0.7240133210515128	0.7626546681664792	0.8029416366765765	0.7885620190633016	0.7407226221259348	0.7073994696501871	0.7698272343898789	0.7472776613651197	0.7426475628984712	0.7470525944228733	0.781166329262718	0.7306176084099869	0.7570829497800962	0.7902249270634	0.778474872259233	0.7908733181010409	0.7166294883787868	0.7419969762702951	0.7145211499725325	0.7524390664322405	0.7616065717267616	0.7262641348410497	0.7244446019204195	0.746333702268954	0.7785239171254893	0.7410875294770426	0.6908594211458948	0.7432572973722527	0.7926803405338262	0.6681104905201566	0.7378816960390857	0.7403172389750741	0.7823673469387755	0.7686385737439222	0.7756352379723978	0.700353488372093	0.7026384083044983	0.6823693175574197	0.7164385053923527	0.7634110549486385	0.742851157431654	0.7380984310044254	0.7067264573991031	0.7566871207241415	0.7651398296559587	0.7552776657254269	0.7459101401759727	0.757404940043046	0.7656442535051786	0.7533362613601811	0.755324151830702	0.7653814330630482	0.7301777230336091	0.7513461931701997	0.691557844399485	0.6694180767643417	0.7371114148529773	0.7450953631990174	0.7365665472581978	0.7060385849717806	0.7310359173484954	0.7242057913972448	0.758283758184054	0.7351731828001952	0.737928898372165	0.777037450356123	0.7597020509506479	0.7559795382275681	0.7500518277935181	0.7709702866158296	0.7587770479778615	0.7763205469546067	0.7509035117627003	0.6821443329952289	0.7570061282104248	0.7755949634122223	0.7209109581636698	0.7762349191896198	0.727961022117845	0.7549798775744868	0.7579485761680951	0.6872039682243688	0.7313339797755922
valid_loss
tensor(0.4310, device='cuda:0')	tensor(0.4167, device='cuda:0')	tensor(0.4156, device='cuda:0')	tensor(0.5861, device='cuda:0')	tensor(0.5375, device='cuda:0')	tensor(0.4394, device='cuda:0')	tensor(0.5390, device='cuda:0')	tensor(0.5236, device='cuda:0')	tensor(0.5618, device='cuda:0')	tensor(0.5692, device='cuda:0')	tensor(0.6184, device='cuda:0')	tensor(0.7661, device='cuda:0')	tensor(0.9471, device='cuda:0')	tensor(0.7854, device='cuda:0')	tensor(1.0611, device='cuda:0')	tensor(1.0666, device='cuda:0')	tensor(1.1742, device='cuda:0')	tensor(1.1535, device='cuda:0')	tensor(1.1532, device='cuda:0')	tensor(1.2987, device='cuda:0')
Best model metrics: train, valid, test: acc, f1
0.8748397827148438, 0.8792506992492272
0.81353759765625, 0.8110231349746382
0.78466796875, 0.776255707762557
Model saved, path ./models/alexnet_13-1559673726.pth
experiment validation
train set
Evaluation results
[[109879.  21193.]
 [ 11617. 119455.]]
#############################
Accuracy
0.8748397827148438
------------------------
Recall
0.9113693237304688
------------------------
Specificity
0.8383102416992188
------------------------
Precision
0.8493188669586486
------------------------
Fall_out
0.16168975830078125
------------------------
F1
0.8792506992492272
------------------------
#############################
valid set
Evaluation results
[[13547.  2852.]
 [ 3258. 13111.]]
#############################
Accuracy
0.81353759765625
------------------------
Recall
0.8009652391716049
------------------------
Specificity
0.8260869565217391
------------------------
Precision
0.8213368414458435
------------------------
Fall_out
0.17391304347826086
------------------------
F1
0.8110231349746382
------------------------
#############################
test set
Evaluation results
[[13472.  2919.]
 [ 4137. 12240.]]
#############################
Accuracy
0.78466796875
------------------------
Recall
0.7473896318006961
------------------------
Specificity
0.8219144652553231
------------------------
Precision
0.8074411240847021
------------------------
Fall_out
0.17808553474467695
------------------------
F1
0.776255707762557
------------------------
#############################
AUC: 0.8662283921435148
Experiment end
########################################