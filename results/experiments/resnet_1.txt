----------------------------------------
Starting experiment resnet_1
Experiment parameters Experiment[name: resnet_1, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 1e-05, weight_decay: 0, batch_size: 32, num_epochs: 10), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.4434814453125, 0.33029746603011384
train metrics acc, f1
0.43099212646484375, 0.30922411477581113
Epoch 1/10
----------
eval metrics, batch: 1024 acc, f1
0.7842553428317008, 0.7683804857646461
eval metrics, batch: 2048 acc, f1
0.8400735294117647, 0.833754546014917
eval metrics, batch: 3072 acc, f1
0.8113898756660746, 0.8030259115413599
eval metrics, batch: 4096 acc, f1
0.7468799920127795, 0.7371776597123234
train metrics, batch: 4096  acc, f1 
0.93719482421875, 0.9353404601258316
eval metrics, batch: 5120 acc, f1
0.8619541746641075, 0.8583648727653158
eval metrics, batch: 6144 acc, f1
0.7808685701830863, 0.7651610265993167
eval metrics, batch: 7168 acc, f1
0.7734118009868421, 0.7667645424966273
Epoch loss - train: tensor(0.2080, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.2810, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8621375116931712, 0.8596846176733115
train metrics acc, f1 
0.9477462768554688, 0.9488506519693507
Epoch 2/10
----------
eval metrics, batch: 1024 acc, f1
0.7865331783601014, 0.7789600372001423
eval metrics, batch: 2048 acc, f1
0.8212952488687782, 0.8140321963565732
eval metrics, batch: 3072 acc, f1
0.8380189324817519, 0.8333186632632104
eval metrics, batch: 4096 acc, f1
0.7736053719008265, 0.7661526970068826
train metrics, batch: 4096  acc, f1 
0.9643440246582031, 0.9641837598813662
eval metrics, batch: 5120 acc, f1
0.8675373134328358, 0.867351704810836
eval metrics, batch: 6144 acc, f1
0.7649360236220473, 0.76288813323736
eval metrics, batch: 7168 acc, f1
0.7314771884272997, 0.7300943725969941
Epoch loss - train: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4465, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7065391459074734, 0.7056881552531786
train metrics acc, f1 
0.9696693420410156, 0.9691353951143011
Epoch 3/10
----------
eval metrics, batch: 1024 acc, f1
0.7500247231012658, 0.7431605151522849
eval metrics, batch: 2048 acc, f1
0.8450255102040817, 0.841740674955595
eval metrics, batch: 3072 acc, f1
0.7784849749582637, 0.7695522388059701
eval metrics, batch: 4096 acc, f1
0.6859363831308077, 0.6776707932141219
train metrics, batch: 4096  acc, f1 
0.9719085693359375, 0.9714063834744118
eval metrics, batch: 5120 acc, f1
0.8664482838589982, 0.8651938551572788
eval metrics, batch: 6144 acc, f1
0.7490203761755486, 0.743067743067743
eval metrics, batch: 7168 acc, f1
0.6664506688963211, 0.6650574085346656
Epoch loss - train: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5408, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.6998791189111748, 0.6961035428519619
train metrics acc, f1 
0.9814376831054688, 0.981270207852194
Epoch 4/10
----------
eval metrics, batch: 1024 acc, f1
0.7223704268292683, 0.7129629629629629
eval metrics, batch: 2048 acc, f1
0.7421088303640588, 0.7365088786664689
eval metrics, batch: 3072 acc, f1
0.7603102906520032, 0.7575366277626024
eval metrics, batch: 4096 acc, f1
0.7244485294117647, 0.7232274741506647
train metrics, batch: 4096  acc, f1 
0.9863967895507812, 0.9863330803841761
eval metrics, batch: 5120 acc, f1
0.7941131342062193, 0.7934316869788326
eval metrics, batch: 6144 acc, f1
0.6967923516797713, 0.6919620569146281
eval metrics, batch: 7168 acc, f1
0.8139364700780573, 0.8096070111212802
Epoch loss - train: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4779, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7527195411392406, 0.7461936662606578
train metrics acc, f1 
0.9902534484863281, 0.9902507335798314
Epoch 5/10
----------
eval metrics, batch: 1024 acc, f1
0.7009413468501087, 0.6951045079130715
eval metrics, batch: 2048 acc, f1
0.7735073111291633, 0.7687522678969467
eval metrics, batch: 3072 acc, f1
0.6935832732516222, 0.6863323954056921
eval metrics, batch: 4096 acc, f1
0.7136611769059955, 0.7072484332505616
train metrics, batch: 4096  acc, f1 
0.9874114990234375, 0.9873087661813231
eval metrics, batch: 5120 acc, f1
0.7513860887096774, 0.7425693483990501
eval metrics, batch: 6144 acc, f1
0.7339313123561013, 0.7282747134319585
eval metrics, batch: 7168 acc, f1
0.7878636172006745, 0.7807999128753845
Epoch loss - train: tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6785, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7074487554904831, 0.7015914500396696
train metrics acc, f1 
0.99359130859375, 0.9935738056076197
Epoch 6/10
----------
eval metrics, batch: 1024 acc, f1
0.7587440381558028, 0.753464994669239
eval metrics, batch: 2048 acc, f1
0.7735714285714286, 0.7677169475557416
eval metrics, batch: 3072 acc, f1
0.7594506048387096, 0.7519297242508511
eval metrics, batch: 4096 acc, f1
0.773664314516129, 0.7701599488163787
train metrics, batch: 4096  acc, f1 
0.9939155578613281, 0.9939229992570437
eval metrics, batch: 5120 acc, f1
0.7699002442996743, 0.7635460251046026
eval metrics, batch: 6144 acc, f1
0.8073516386182462, 0.8011087615019717
eval metrics, batch: 7168 acc, f1
0.7365731939163498, 0.7325500036190797
Epoch loss - train: tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8102, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.6844639139486468, 0.6815216915466444
train metrics acc, f1 
0.9948921203613281, 0.9948708912544674
Epoch 7/10
----------
eval metrics, batch: 1024 acc, f1
0.7328777047913446, 0.72532220815019
eval metrics, batch: 2048 acc, f1
0.7201378608438194, 0.7154716271194412
eval metrics, batch: 3072 acc, f1
0.8051438535309503, 0.7977604343400068
eval metrics, batch: 4096 acc, f1
0.7156939338235294, 0.7113226476283802
train metrics, batch: 4096  acc, f1 
0.9944839477539062, 0.9944657920117573
eval metrics, batch: 5120 acc, f1
0.664346399730821, 0.6605703591859303
eval metrics, batch: 6144 acc, f1
0.7220882789317508, 0.7185651234857733
eval metrics, batch: 7168 acc, f1
0.8142755681818182, 0.8104491343499958
Epoch loss - train: tensor(0.0256, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8001, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.736922554347826, 0.7291349204366616
train metrics acc, f1 
0.9968223571777344, 0.9968207198989347
Epoch 8/10
----------
eval metrics, batch: 1024 acc, f1
0.7432692307692308, 0.7396011118154776
eval metrics, batch: 2048 acc, f1
0.753477626459144, 0.7504984124640035
eval metrics, batch: 3072 acc, f1
0.7305730712166172, 0.7296706363974693
eval metrics, batch: 4096 acc, f1
0.7744229183841714, 0.7666186896956128
train metrics, batch: 4096  acc, f1 
0.9975357055664062, 0.9975371899566149
eval metrics, batch: 5120 acc, f1
0.7196312881097561, 0.7104091322852855
eval metrics, batch: 6144 acc, f1
0.7697166530278232, 0.7620683277406399
eval metrics, batch: 7168 acc, f1
0.7579608386075949, 0.7536239178578619
Epoch loss - train: tensor(0.0206, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8496, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7501476377952756, 0.7447589362023026
train metrics acc, f1 
0.9972572326660156, 0.9972589370470479
Epoch 9/10
----------
eval metrics, batch: 1024 acc, f1
0.7225456408345753, 0.7185809773494887
eval metrics, batch: 2048 acc, f1
0.7704897425583266, 0.7670281995661605
eval metrics, batch: 3072 acc, f1
0.7386473663826492, 0.7318115204053752
eval metrics, batch: 4096 acc, f1
0.7593376494023905, 0.753789326200484
train metrics, batch: 4096  acc, f1 
0.9966773986816406, 0.9966769550072679
eval metrics, batch: 5120 acc, f1
0.7887100082034455, 0.7860110084120885
eval metrics, batch: 6144 acc, f1
0.6983894902234636, 0.699131419117487
eval metrics, batch: 7168 acc, f1
0.7182139027877055, 0.7206784314593805
Epoch loss - train: tensor(0.0181, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1210, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.6654560810810811, 0.6617998633879781
train metrics acc, f1 
0.9966964721679688, 0.9966867654260528
Epoch 10/10
----------
eval metrics, batch: 1024 acc, f1
0.6923591298145506, 0.6866457794124324
eval metrics, batch: 2048 acc, f1
0.7902277542372881, 0.7835614941115392
eval metrics, batch: 3072 acc, f1
0.7917110306643952, 0.7842272163242796
eval metrics, batch: 4096 acc, f1
0.6912191901408451, 0.6874986079868148
train metrics, batch: 4096  acc, f1 
0.9944190979003906, 0.9943951299310789
eval metrics, batch: 5120 acc, f1
0.7419354838709677, 0.7418023173992588
eval metrics, batch: 6144 acc, f1
0.7785149918962723, 0.7755939857340791
eval metrics, batch: 7168 acc, f1
0.7879983388704319, 0.78364060182242
Epoch loss - train: tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1673, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.6679868944923689, 0.6687767641035189
train metrics acc, f1 
0.9939689636230469, 0.9939337198460599
Training time 154m 10s
Experiment end
########################################