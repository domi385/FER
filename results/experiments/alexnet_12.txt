Starting experiment alexnet_12-1559491146
Experiment parameters Experiment[name: alexnet_12-1559491146, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 0.0001, weight_decay: 0, batch_size: 32, num_epochs: 20), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.499542236328125, 0.6662596414107496
train metrics acc, f1
0.5, 0.6666666666666666
Epoch 1/20
----------
eval metrics, batch: 1024 acc, f1
0.795562744140625, 0.8048588656820764
eval metrics, batch: 2048 acc, f1
0.785980224609375, 0.7880692635459793
eval metrics, batch: 3072 acc, f1
0.8006591796875, 0.8164343525179856
eval metrics, batch: 4096 acc, f1
0.787353515625, 0.7690114698667374
train metrics, batch: 4096  acc, f1 
0.8280372619628906, 0.8229133521109055
eval metrics, batch: 5120 acc, f1
0.793731689453125, 0.7743916686137722
eval metrics, batch: 6144 acc, f1
0.799468994140625, 0.7984541299880379
eval metrics, batch: 7168 acc, f1
0.714019775390625, 0.6352703070875335
Epoch loss - train: tensor(0.4173, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3975, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.812591552734375, 0.8168669668684579
train metrics acc, f1 
0.8441200256347656, 0.8531834856122474
Epoch 2/20
----------
eval metrics, batch: 1024 acc, f1
0.773834228515625, 0.7950327737367592
eval metrics, batch: 2048 acc, f1
0.814849853515625, 0.8127642502237448
eval metrics, batch: 3072 acc, f1
0.7744140625, 0.7447690076652165
eval metrics, batch: 4096 acc, f1
0.756378173828125, 0.7107084616778402
train metrics, batch: 4096  acc, f1 
0.8617324829101562, 0.852982453293962
eval metrics, batch: 5120 acc, f1
0.801513671875, 0.7860807788448888
eval metrics, batch: 6144 acc, f1
0.785888671875, 0.76410463317867
eval metrics, batch: 7168 acc, f1
0.795318603515625, 0.7811245635218483
Epoch loss - train: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4063, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8148193359375, 0.8107062640379337
train metrics acc, f1 
0.8765068054199219, 0.8805243597739879
Epoch 3/20
----------
eval metrics, batch: 1024 acc, f1
0.794219970703125, 0.7849740106508498
eval metrics, batch: 2048 acc, f1
0.748138427734375, 0.6914189568143578
eval metrics, batch: 3072 acc, f1
0.788787841796875, 0.7631335774667168
eval metrics, batch: 4096 acc, f1
0.8026123046875, 0.7927055957951413
train metrics, batch: 4096  acc, f1 
0.8921852111816406, 0.8948114734879359
eval metrics, batch: 5120 acc, f1
0.76239013671875, 0.7148820858356526
eval metrics, batch: 6144 acc, f1
0.7479248046875, 0.6864799210506338
eval metrics, batch: 7168 acc, f1
0.810577392578125, 0.8097004629487691
Epoch loss - train: tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4676, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.794677734375, 0.7790621305661368
train metrics acc, f1 
0.9034233093261719, 0.9056719064953259
Epoch 4/20
----------
eval metrics, batch: 1024 acc, f1
0.80902099609375, 0.8028603830645161
eval metrics, batch: 2048 acc, f1
0.81011962890625, 0.805050758240381
eval metrics, batch: 3072 acc, f1
0.7525634765625, 0.6984976944816302
eval metrics, batch: 4096 acc, f1
0.774200439453125, 0.7356461467004894
train metrics, batch: 4096  acc, f1 
0.9108085632324219, 0.9085017707946074
eval metrics, batch: 5120 acc, f1
0.785247802734375, 0.7484719591092683
eval metrics, batch: 6144 acc, f1
0.78802490234375, 0.759003538963292
eval metrics, batch: 7168 acc, f1
0.774078369140625, 0.7492463503031535
Epoch loss - train: tensor(0.2471, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5900, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.74322509765625, 0.674406005727111
train metrics acc, f1 
0.89971923828125, 0.8926696226615386
Epoch 5/20
----------
eval metrics, batch: 1024 acc, f1
0.78802490234375, 0.7633228840125392
eval metrics, batch: 2048 acc, f1
0.745574951171875, 0.6804645279981603
eval metrics, batch: 3072 acc, f1
0.81005859375, 0.7984977984977984
eval metrics, batch: 4096 acc, f1
0.770050048828125, 0.725770644539069
train metrics, batch: 4096  acc, f1 
0.9233245849609375, 0.9209849753520296
eval metrics, batch: 5120 acc, f1
0.76251220703125, 0.7133912787271656
eval metrics, batch: 6144 acc, f1
0.735076904296875, 0.6612292682926829
eval metrics, batch: 7168 acc, f1
0.778533935546875, 0.7481520041644977
Epoch loss - train: tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6470, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.719085693359375, 0.6349395201269086
train metrics acc, f1 
0.9066009521484375, 0.9005152209599038
Epoch 6/20
----------
eval metrics, batch: 1024 acc, f1
0.735443115234375, 0.6746237285590962
eval metrics, batch: 2048 acc, f1
0.773345947265625, 0.7327552085207442
eval metrics, batch: 3072 acc, f1
0.80413818359375, 0.7890203813280736
eval metrics, batch: 4096 acc, f1
0.793060302734375, 0.7714295344996124
train metrics, batch: 4096  acc, f1 
0.9353523254394531, 0.9359782703139697
eval metrics, batch: 5120 acc, f1
0.762725830078125, 0.7106330715694666
eval metrics, batch: 6144 acc, f1
0.78302001953125, 0.7575034106412005
eval metrics, batch: 7168 acc, f1
0.786224365234375, 0.7526046265230443
Epoch loss - train: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5247, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.779022216796875, 0.7452952970558233
train metrics acc, f1 
0.9456138610839844, 0.945361034143126
Epoch 7/20
----------
eval metrics, batch: 1024 acc, f1
0.78753662109375, 0.7595662384307225
eval metrics, batch: 2048 acc, f1
0.775543212890625, 0.7359161250942515
eval metrics, batch: 3072 acc, f1
0.8062744140625, 0.7864783047426842
eval metrics, batch: 4096 acc, f1
0.731201171875, 0.6674218396012687
train metrics, batch: 4096  acc, f1 
0.9402198791503906, 0.9388937630383498
eval metrics, batch: 5120 acc, f1
0.78228759765625, 0.7471826493727408
eval metrics, batch: 6144 acc, f1
0.79901123046875, 0.7815733616343857
eval metrics, batch: 7168 acc, f1
0.80181884765625, 0.7886755613407094
Epoch loss - train: tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5347, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.804534912109375, 0.7922545489928967
train metrics acc, f1 
0.9414176940917969, 0.9429830586505582
Epoch 8/20
----------
eval metrics, batch: 1024 acc, f1
0.76092529296875, 0.7125981363269499
eval metrics, batch: 2048 acc, f1
0.76385498046875, 0.7184543734536457
eval metrics, batch: 3072 acc, f1
0.760040283203125, 0.7117774275136541
eval metrics, batch: 4096 acc, f1
0.79522705078125, 0.7730654761904762
train metrics, batch: 4096  acc, f1 
0.9511299133300781, 0.9515708933924568
eval metrics, batch: 5120 acc, f1
0.779754638671875, 0.7518310924658712
eval metrics, batch: 6144 acc, f1
0.78704833984375, 0.7589803813208068
eval metrics, batch: 7168 acc, f1
0.74859619140625, 0.6977989728539985
Epoch loss - train: tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5479, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.791351318359375, 0.7644606745443897
train metrics acc, f1 
0.9596633911132812, 0.9598371303337156
Epoch 9/20
----------
eval metrics, batch: 1024 acc, f1
0.7862548828125, 0.7590974754075807
eval metrics, batch: 2048 acc, f1
0.762847900390625, 0.7132578133648205
eval metrics, batch: 3072 acc, f1
0.76202392578125, 0.7111423914654023
eval metrics, batch: 4096 acc, f1
0.762115478515625, 0.7173164097914778
train metrics, batch: 4096  acc, f1 
0.9592475891113281, 0.958806177338192
eval metrics, batch: 5120 acc, f1
0.768890380859375, 0.7256656402825575
eval metrics, batch: 6144 acc, f1
0.763702392578125, 0.7090738305466842
eval metrics, batch: 7168 acc, f1
0.805877685546875, 0.7929564170165674
Epoch loss - train: tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4968, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.820892333984375, 0.8172277412724611
train metrics acc, f1 
0.93603515625, 0.9387147942662076
Epoch 10/20
----------
eval metrics, batch: 1024 acc, f1
0.763336181640625, 0.7176406335335882
eval metrics, batch: 2048 acc, f1
0.77435302734375, 0.741378104232249
eval metrics, batch: 3072 acc, f1
0.79705810546875, 0.7811348077935756
eval metrics, batch: 4096 acc, f1
0.760040283203125, 0.7094342411588633
train metrics, batch: 4096  acc, f1 
0.9630470275878906, 0.9624638180965703
eval metrics, batch: 5120 acc, f1
0.76739501953125, 0.7273182598740698
eval metrics, batch: 6144 acc, f1
0.767913818359375, 0.7298305446019396
eval metrics, batch: 7168 acc, f1
0.776275634765625, 0.7375505674292056
Epoch loss - train: tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.7230, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.77349853515625, 0.7449835074216603
train metrics acc, f1 
0.962188720703125, 0.9626843757764677
Epoch 11/20
----------
eval metrics, batch: 1024 acc, f1
0.786865234375, 0.7592056268100952
eval metrics, batch: 2048 acc, f1
0.739654541015625, 0.677844492277482
eval metrics, batch: 3072 acc, f1
0.759063720703125, 0.713378108549646
eval metrics, batch: 4096 acc, f1
0.7789306640625, 0.7430841254078593
train metrics, batch: 4096  acc, f1 
0.96630859375, 0.9663098789261274
eval metrics, batch: 5120 acc, f1
0.772003173828125, 0.7360163951803823
eval metrics, batch: 6144 acc, f1
0.776947021484375, 0.7495116350800233
eval metrics, batch: 7168 acc, f1
0.78021240234375, 0.7443016402755095
Epoch loss - train: tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8485, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.77349853515625, 0.7366964665815241
train metrics acc, f1 
0.9634780883789062, 0.963436803030766
Epoch 12/20
----------
eval metrics, batch: 1024 acc, f1
0.76727294921875, 0.7356672443674177
eval metrics, batch: 2048 acc, f1
0.79229736328125, 0.7717026700657453
eval metrics, batch: 3072 acc, f1
0.79986572265625, 0.781603836419342
eval metrics, batch: 4096 acc, f1
0.789276123046875, 0.7637135133285425
train metrics, batch: 4096  acc, f1 
0.9753952026367188, 0.9755589238347859
eval metrics, batch: 5120 acc, f1
0.7652587890625, 0.7351786820904772
eval metrics, batch: 6144 acc, f1
0.748504638671875, 0.6914985213192079
eval metrics, batch: 7168 acc, f1
0.78790283203125, 0.7680395167211802
Epoch loss - train: tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8736, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.759429931640625, 0.7133558779680739
train metrics acc, f1 
0.96490478515625, 0.9644196929264802
Epoch 13/20
----------
eval metrics, batch: 1024 acc, f1
0.7911376953125, 0.7657127207996713
eval metrics, batch: 2048 acc, f1
0.773101806640625, 0.7401349131452938
eval metrics, batch: 3072 acc, f1
0.760650634765625, 0.7174813587406794
eval metrics, batch: 4096 acc, f1
0.796234130859375, 0.781390171233998
train metrics, batch: 4096  acc, f1 
0.9668312072753906, 0.9676435017210904
eval metrics, batch: 5120 acc, f1
0.76129150390625, 0.7193196497775226
eval metrics, batch: 6144 acc, f1
0.772491455078125, 0.7433646597128989
eval metrics, batch: 7168 acc, f1
0.757720947265625, 0.7087567408929161
Epoch loss - train: tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.7911, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.77239990234375, 0.7392125323449192
train metrics acc, f1 
0.9811019897460938, 0.9812159221033314
Epoch 14/20
----------
eval metrics, batch: 1024 acc, f1
0.780853271484375, 0.7431044968339713
eval metrics, batch: 2048 acc, f1
0.78369140625, 0.7607345395625169
eval metrics, batch: 3072 acc, f1
0.7537841796875, 0.7023097926352299
eval metrics, batch: 4096 acc, f1
0.78515625, 0.7630108395610314
train metrics, batch: 4096  acc, f1 
0.9681167602539062, 0.9686879509676839
eval metrics, batch: 5120 acc, f1
0.7769775390625, 0.7455786102214176
eval metrics, batch: 6144 acc, f1
0.781494140625, 0.7548281057389399
eval metrics, batch: 7168 acc, f1
0.778045654296875, 0.7529131985731272
Epoch loss - train: tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.9810, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.778656005859375, 0.7440268219516499
train metrics acc, f1 
0.9851493835449219, 0.9851752278171065
Epoch 15/20
----------
eval metrics, batch: 1024 acc, f1
0.70880126953125, 0.6137467616580311
eval metrics, batch: 2048 acc, f1
0.76849365234375, 0.7373268698060942
eval metrics, batch: 3072 acc, f1
0.785125732421875, 0.7596189955959168
eval metrics, batch: 4096 acc, f1
0.739898681640625, 0.675943880460819
train metrics, batch: 4096  acc, f1 
0.968109130859375, 0.9674424401034365
eval metrics, batch: 5120 acc, f1
0.752838134765625, 0.7019029040450513
eval metrics, batch: 6144 acc, f1
0.759765625, 0.7164265129682997
eval metrics, batch: 7168 acc, f1
0.757110595703125, 0.707787201233616
Epoch loss - train: tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.2262, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.753143310546875, 0.6993719106552199
train metrics acc, f1 
0.9781150817871094, 0.9778346153994754
Epoch 16/20
----------
eval metrics, batch: 1024 acc, f1
0.7451171875, 0.7121984838042729
eval metrics, batch: 2048 acc, f1
0.7740478515625, 0.7385593220338983
eval metrics, batch: 3072 acc, f1
0.778900146484375, 0.7506624909660323
eval metrics, batch: 4096 acc, f1
0.779876708984375, 0.7508376800580331
train metrics, batch: 4096  acc, f1 
0.98358154296875, 0.9836686372570596
eval metrics, batch: 5120 acc, f1
0.765045166015625, 0.7214040166455582
eval metrics, batch: 6144 acc, f1
0.77081298828125, 0.7326641036594048
eval metrics, batch: 7168 acc, f1
0.780303955078125, 0.7450688763766422
Epoch loss - train: tensor(0.0584, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1148, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.760833740234375, 0.7097944825032402
train metrics acc, f1 
0.9857444763183594, 0.9856139202740939
Epoch 17/20
----------
eval metrics, batch: 1024 acc, f1
0.772979736328125, 0.7359341166447766
eval metrics, batch: 2048 acc, f1
0.732391357421875, 0.6642673915540411
eval metrics, batch: 3072 acc, f1
0.7479248046875, 0.6888420100956829
eval metrics, batch: 4096 acc, f1
0.76556396484375, 0.7285704190516571
train metrics, batch: 4096  acc, f1 
0.9857902526855469, 0.9858159539104178
eval metrics, batch: 5120 acc, f1
0.770111083984375, 0.7281977268627097
eval metrics, batch: 6144 acc, f1
0.780975341796875, 0.7486428746541519
eval metrics, batch: 7168 acc, f1
0.772308349609375, 0.7339632733107506
Epoch loss - train: tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.2697, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.775665283203125, 0.7423142987345323
train metrics acc, f1 
0.9885635375976562, 0.9886042268511479
Epoch 18/20
----------
eval metrics, batch: 1024 acc, f1
0.78277587890625, 0.7512406514293702
eval metrics, batch: 2048 acc, f1
0.74285888671875, 0.6835661709478744
eval metrics, batch: 3072 acc, f1
0.763336181640625, 0.716919145829531
eval metrics, batch: 4096 acc, f1
0.7642822265625, 0.7197590886002467
train metrics, batch: 4096  acc, f1 
0.9874076843261719, 0.9873531203426649
eval metrics, batch: 5120 acc, f1
0.759307861328125, 0.7153015918853554
eval metrics, batch: 6144 acc, f1
0.766937255859375, 0.7297498142184791
eval metrics, batch: 7168 acc, f1
0.79522705078125, 0.7771208396997277
Epoch loss - train: tensor(0.0494, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.2703, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7578125, 0.7096231247713136
train metrics acc, f1 
0.9893760681152344, 0.9893276618574084
Epoch 19/20
----------
eval metrics, batch: 1024 acc, f1
0.780792236328125, 0.7567476040502557
eval metrics, batch: 2048 acc, f1
0.774017333984375, 0.7409117945488262
eval metrics, batch: 3072 acc, f1
0.7816162109375, 0.7491938875648395
eval metrics, batch: 4096 acc, f1
0.8001708984375, 0.7801651782716712
train metrics, batch: 4096  acc, f1 
0.9829483032226562, 0.9830977607368923
eval metrics, batch: 5120 acc, f1
0.781280517578125, 0.749098547173114
eval metrics, batch: 6144 acc, f1
0.77337646484375, 0.736890589569161
eval metrics, batch: 7168 acc, f1
0.777008056640625, 0.7463815903647912
Epoch loss - train: tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.5226, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.761688232421875, 0.7159847244953628
train metrics acc, f1 
0.9873237609863281, 0.9872774121421652
Epoch 20/20
----------
eval metrics, batch: 1024 acc, f1
0.756439208984375, 0.7107599753560686
eval metrics, batch: 2048 acc, f1
0.768646240234375, 0.7292016431505626
eval metrics, batch: 3072 acc, f1
0.787322998046875, 0.7661644800858974
eval metrics, batch: 4096 acc, f1
0.764892578125, 0.7234546629334482
train metrics, batch: 4096  acc, f1 
0.9870719909667969, 0.9870386164325408
eval metrics, batch: 5120 acc, f1
0.77496337890625, 0.7384364358683314
eval metrics, batch: 6144 acc, f1
0.77734375, 0.7423910740766895
eval metrics, batch: 7168 acc, f1
0.7850341796875, 0.7567847524342242
Epoch loss - train: tensor(0.0429, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.3067, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.776031494140625, 0.7444370930111084
train metrics acc, f1 
0.9814529418945312, 0.9815003652745647
Training time 572m 24s
train_acc
0.5	0.8280372619628906	0.8441200256347656	0.8617324829101562	0.8765068054199219	0.8921852111816406	0.9034233093261719	0.9108085632324219	0.89971923828125	0.9233245849609375	0.9066009521484375	0.9353523254394531	0.9456138610839844	0.9402198791503906	0.9414176940917969	0.9511299133300781	0.9596633911132812	0.9592475891113281	0.93603515625	0.9630470275878906	0.962188720703125	0.96630859375	0.9634780883789062	0.9753952026367188	0.96490478515625	0.9668312072753906	0.9811019897460938	0.9681167602539062	0.9851493835449219	0.968109130859375	0.9781150817871094	0.98358154296875	0.9857444763183594	0.9857902526855469	0.9885635375976562	0.9874076843261719	0.9893760681152344	0.9829483032226562	0.9873237609863281	0.9870719909667969	0.9814529418945312
train_f1
0.6666666666666666	0.8229133521109055	0.8531834856122474	0.852982453293962	0.8805243597739879	0.8948114734879359	0.9056719064953259	0.9085017707946074	0.8926696226615386	0.9209849753520296	0.9005152209599038	0.9359782703139697	0.945361034143126	0.9388937630383498	0.9429830586505582	0.9515708933924568	0.9598371303337156	0.958806177338192	0.9387147942662076	0.9624638180965703	0.9626843757764677	0.9663098789261274	0.963436803030766	0.9755589238347859	0.9644196929264802	0.9676435017210904	0.9812159221033314	0.9686879509676839	0.9851752278171065	0.9674424401034365	0.9778346153994754	0.9836686372570596	0.9856139202740939	0.9858159539104178	0.9886042268511479	0.9873531203426649	0.9893276618574084	0.9830977607368923	0.9872774121421652	0.9870386164325408	0.9815003652745647
train_loss
tensor(0.4173, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2471, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2178, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1762, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1508, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1331, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1169, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1034, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0639, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0584, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0527, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0494, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0429, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.499542236328125	0.795562744140625	0.785980224609375	0.8006591796875	0.787353515625	0.793731689453125	0.799468994140625	0.714019775390625	0.812591552734375	0.773834228515625	0.814849853515625	0.7744140625	0.756378173828125	0.801513671875	0.785888671875	0.795318603515625	0.8148193359375	0.794219970703125	0.748138427734375	0.788787841796875	0.8026123046875	0.76239013671875	0.7479248046875	0.810577392578125	0.794677734375	0.80902099609375	0.81011962890625	0.7525634765625	0.774200439453125	0.785247802734375	0.78802490234375	0.774078369140625	0.74322509765625	0.78802490234375	0.745574951171875	0.81005859375	0.770050048828125	0.76251220703125	0.735076904296875	0.778533935546875	0.719085693359375	0.735443115234375	0.773345947265625	0.80413818359375	0.793060302734375	0.762725830078125	0.78302001953125	0.786224365234375	0.779022216796875	0.78753662109375	0.775543212890625	0.8062744140625	0.731201171875	0.78228759765625	0.79901123046875	0.80181884765625	0.804534912109375	0.76092529296875	0.76385498046875	0.760040283203125	0.79522705078125	0.779754638671875	0.78704833984375	0.74859619140625	0.791351318359375	0.7862548828125	0.762847900390625	0.76202392578125	0.762115478515625	0.768890380859375	0.763702392578125	0.805877685546875	0.820892333984375	0.763336181640625	0.77435302734375	0.79705810546875	0.760040283203125	0.76739501953125	0.767913818359375	0.776275634765625	0.77349853515625	0.786865234375	0.739654541015625	0.759063720703125	0.7789306640625	0.772003173828125	0.776947021484375	0.78021240234375	0.77349853515625	0.76727294921875	0.79229736328125	0.79986572265625	0.789276123046875	0.7652587890625	0.748504638671875	0.78790283203125	0.759429931640625	0.7911376953125	0.773101806640625	0.760650634765625	0.796234130859375	0.76129150390625	0.772491455078125	0.757720947265625	0.77239990234375	0.780853271484375	0.78369140625	0.7537841796875	0.78515625	0.7769775390625	0.781494140625	0.778045654296875	0.778656005859375	0.70880126953125	0.76849365234375	0.785125732421875	0.739898681640625	0.752838134765625	0.759765625	0.757110595703125	0.753143310546875	0.7451171875	0.7740478515625	0.778900146484375	0.779876708984375	0.765045166015625	0.77081298828125	0.780303955078125	0.760833740234375	0.772979736328125	0.732391357421875	0.7479248046875	0.76556396484375	0.770111083984375	0.780975341796875	0.772308349609375	0.775665283203125	0.78277587890625	0.74285888671875	0.763336181640625	0.7642822265625	0.759307861328125	0.766937255859375	0.79522705078125	0.7578125	0.780792236328125	0.774017333984375	0.7816162109375	0.8001708984375	0.781280517578125	0.77337646484375	0.777008056640625	0.761688232421875	0.756439208984375	0.768646240234375	0.787322998046875	0.764892578125	0.77496337890625	0.77734375	0.7850341796875	0.776031494140625
valid_f1
0.6662596414107496	0.8048588656820764	0.7880692635459793	0.8164343525179856	0.7690114698667374	0.7743916686137722	0.7984541299880379	0.6352703070875335	0.8168669668684579	0.7950327737367592	0.8127642502237448	0.7447690076652165	0.7107084616778402	0.7860807788448888	0.76410463317867	0.7811245635218483	0.8107062640379337	0.7849740106508498	0.6914189568143578	0.7631335774667168	0.7927055957951413	0.7148820858356526	0.6864799210506338	0.8097004629487691	0.7790621305661368	0.8028603830645161	0.805050758240381	0.6984976944816302	0.7356461467004894	0.7484719591092683	0.759003538963292	0.7492463503031535	0.674406005727111	0.7633228840125392	0.6804645279981603	0.7984977984977984	0.725770644539069	0.7133912787271656	0.6612292682926829	0.7481520041644977	0.6349395201269086	0.6746237285590962	0.7327552085207442	0.7890203813280736	0.7714295344996124	0.7106330715694666	0.7575034106412005	0.7526046265230443	0.7452952970558233	0.7595662384307225	0.7359161250942515	0.7864783047426842	0.6674218396012687	0.7471826493727408	0.7815733616343857	0.7886755613407094	0.7922545489928967	0.7125981363269499	0.7184543734536457	0.7117774275136541	0.7730654761904762	0.7518310924658712	0.7589803813208068	0.6977989728539985	0.7644606745443897	0.7590974754075807	0.7132578133648205	0.7111423914654023	0.7173164097914778	0.7256656402825575	0.7090738305466842	0.7929564170165674	0.8172277412724611	0.7176406335335882	0.741378104232249	0.7811348077935756	0.7094342411588633	0.7273182598740698	0.7298305446019396	0.7375505674292056	0.7449835074216603	0.7592056268100952	0.677844492277482	0.713378108549646	0.7430841254078593	0.7360163951803823	0.7495116350800233	0.7443016402755095	0.7366964665815241	0.7356672443674177	0.7717026700657453	0.781603836419342	0.7637135133285425	0.7351786820904772	0.6914985213192079	0.7680395167211802	0.7133558779680739	0.7657127207996713	0.7401349131452938	0.7174813587406794	0.781390171233998	0.7193196497775226	0.7433646597128989	0.7087567408929161	0.7392125323449192	0.7431044968339713	0.7607345395625169	0.7023097926352299	0.7630108395610314	0.7455786102214176	0.7548281057389399	0.7529131985731272	0.7440268219516499	0.6137467616580311	0.7373268698060942	0.7596189955959168	0.675943880460819	0.7019029040450513	0.7164265129682997	0.707787201233616	0.6993719106552199	0.7121984838042729	0.7385593220338983	0.7506624909660323	0.7508376800580331	0.7214040166455582	0.7326641036594048	0.7450688763766422	0.7097944825032402	0.7359341166447766	0.6642673915540411	0.6888420100956829	0.7285704190516571	0.7281977268627097	0.7486428746541519	0.7339632733107506	0.7423142987345323	0.7512406514293702	0.6835661709478744	0.716919145829531	0.7197590886002467	0.7153015918853554	0.7297498142184791	0.7771208396997277	0.7096231247713136	0.7567476040502557	0.7409117945488262	0.7491938875648395	0.7801651782716712	0.749098547173114	0.736890589569161	0.7463815903647912	0.7159847244953628	0.7107599753560686	0.7292016431505626	0.7661644800858974	0.7234546629334482	0.7384364358683314	0.7423910740766895	0.7567847524342242	0.7444370930111084
valid_loss
tensor(0.3975, device='cuda:0')	tensor(0.4063, device='cuda:0')	tensor(0.4676, device='cuda:0')	tensor(0.5900, device='cuda:0')	tensor(0.6470, device='cuda:0')	tensor(0.5247, device='cuda:0')	tensor(0.5347, device='cuda:0')	tensor(0.5479, device='cuda:0')	tensor(0.4968, device='cuda:0')	tensor(0.7230, device='cuda:0')	tensor(0.8485, device='cuda:0')	tensor(0.8736, device='cuda:0')	tensor(0.7911, device='cuda:0')	tensor(0.9810, device='cuda:0')	tensor(1.2262, device='cuda:0')	tensor(1.1148, device='cuda:0')	tensor(1.2697, device='cuda:0')	tensor(1.2703, device='cuda:0')	tensor(1.5226, device='cuda:0')	tensor(1.3067, device='cuda:0')
Best model metrics: train, valid, test: acc, f1
0.93603515625, 0.9387147942662076
0.820892333984375, 0.8172277412724611
0.7838134765625, 0.7697458233114477
Model saved, path ./models/alexnet_12-1559491146.pth
experiment validation
train set
Evaluation results
[[116957.  14115.]
 [  2653. 128419.]]
#############################
Accuracy
0.93603515625
------------------------
Recall
0.9797592163085938
------------------------
Specificity
0.8923110961914062
------------------------
Precision
0.9009709963938429
------------------------
Fall_out
0.10768890380859375
------------------------
F1
0.9387147942662076
------------------------
#############################
valid set
Evaluation results
[[13778.  2621.]
 [ 3248. 13121.]]
#############################
Accuracy
0.820892333984375
------------------------
Recall
0.8015761500397092
------------------------
Specificity
0.8401731812915422
------------------------
Precision
0.8335027315461822
------------------------
Fall_out
0.15982681870845783
------------------------
F1
0.8172277412724611
------------------------
#############################
test set
Evaluation results
[[13843.  2548.]
 [ 4536. 11841.]]
#############################
Accuracy
0.7838134765625
------------------------
Recall
0.7230261952738597
------------------------
Specificity
0.8445488377768288
------------------------
Precision
0.8229202863298353
------------------------
Fall_out
0.15545116222317126
------------------------
F1
0.7697458233114477
------------------------
#############################
AUC: 0.8711222640610894
Experiment end
########################################