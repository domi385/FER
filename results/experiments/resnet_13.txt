----------------------------------------
Starting experiment resnet_13-1559491145
Experiment parameters Experiment[name: resnet_13-1559491145, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 1e-05, weight_decay: 0, batch_size: 32, num_epochs: 20), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.5, 0.6664630918936525
train metrics acc, f1
0.5006904602050781, 0.6669736791888763
Epoch 1/20
----------
eval metrics, batch: 1024 acc, f1
0.78082275390625, 0.7697191227395151
eval metrics, batch: 2048 acc, f1
0.7957763671875, 0.7967316687929045
eval metrics, batch: 3072 acc, f1
0.780029296875, 0.7696094099597264
eval metrics, batch: 4096 acc, f1
0.7802734375, 0.7580157289776165
train metrics, batch: 4096  acc, f1 
0.831939697265625, 0.8237210009522972
eval metrics, batch: 5120 acc, f1
0.795745849609375, 0.787800006340953
eval metrics, batch: 6144 acc, f1
0.795867919921875, 0.7845940810871735
eval metrics, batch: 7168 acc, f1
0.784210205078125, 0.7582481452357346
Epoch loss - train: tensor(0.3936, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4132, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.814727783203125, 0.8145863237943988
train metrics acc, f1 
0.8598785400390625, 0.865902453271028
Epoch 2/20
----------
eval metrics, batch: 1024 acc, f1
0.772003173828125, 0.7407613033068462
eval metrics, batch: 2048 acc, f1
0.79107666015625, 0.7736260829310231
eval metrics, batch: 3072 acc, f1
0.805938720703125, 0.7913234666754175
eval metrics, batch: 4096 acc, f1
0.79730224609375, 0.7803571428571429
train metrics, batch: 4096  acc, f1 
0.8735771179199219, 0.8725782328356831
eval metrics, batch: 5120 acc, f1
0.79144287109375, 0.7786917098445596
eval metrics, batch: 6144 acc, f1
0.78594970703125, 0.7584378013500482
eval metrics, batch: 7168 acc, f1
0.79736328125, 0.79262960649594
Epoch loss - train: tensor(0.3312, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4262, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.799835205078125, 0.7933717670037489
train metrics acc, f1 
0.8853034973144531, 0.8897905922284901
Epoch 3/20
----------
eval metrics, batch: 1024 acc, f1
0.782012939453125, 0.7581349676632919
eval metrics, batch: 2048 acc, f1
0.7984619140625, 0.7763175721446959
eval metrics, batch: 3072 acc, f1
0.79388427734375, 0.7732491774659236
eval metrics, batch: 4096 acc, f1
0.795684814453125, 0.7865182870444182
train metrics, batch: 4096  acc, f1 
0.8922386169433594, 0.8959593987897716
eval metrics, batch: 5120 acc, f1
0.77972412109375, 0.7464699683877766
eval metrics, batch: 6144 acc, f1
0.75421142578125, 0.7026068975703419
eval metrics, batch: 7168 acc, f1
0.81256103515625, 0.8118836140888208
Epoch loss - train: tensor(0.2875, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5312, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7744140625, 0.74162880111849
train metrics acc, f1 
0.9060745239257812, 0.9047821614472554
Epoch 4/20
----------
eval metrics, batch: 1024 acc, f1
0.789520263671875, 0.7729980581246092
eval metrics, batch: 2048 acc, f1
0.8072509765625, 0.8093915982617094
eval metrics, batch: 3072 acc, f1
0.804443359375, 0.7969066937119675
eval metrics, batch: 4096 acc, f1
0.7659912109375, 0.7304176627759809
train metrics, batch: 4096  acc, f1 
0.91424560546875, 0.9133284497050546
eval metrics, batch: 5120 acc, f1
0.76806640625, 0.7296720495126983
eval metrics, batch: 6144 acc, f1
0.7606201171875, 0.7154052681227777
eval metrics, batch: 7168 acc, f1
0.75518798828125, 0.7071407710280374
Epoch loss - train: tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.7175, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7412109375, 0.6737457679285934
train metrics acc, f1 
0.8999366760253906, 0.8926898515388172
Epoch 5/20
----------
eval metrics, batch: 1024 acc, f1
0.77032470703125, 0.7427536231884058
eval metrics, batch: 2048 acc, f1
0.769134521484375, 0.7282784382744872
eval metrics, batch: 3072 acc, f1
0.775970458984375, 0.7401875774199257
eval metrics, batch: 4096 acc, f1
0.781158447265625, 0.7585115339282708
train metrics, batch: 4096  acc, f1 
0.9374618530273438, 0.9381880976080597
eval metrics, batch: 5120 acc, f1
0.781829833984375, 0.7620093877958654
eval metrics, batch: 6144 acc, f1
0.769073486328125, 0.7310084959653051
eval metrics, batch: 7168 acc, f1
0.78729248046875, 0.771220376813497
Epoch loss - train: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6977, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.732757568359375, 0.6618788370207344
train metrics acc, f1 
0.927276611328125, 0.9234162214277106
Epoch 6/20
----------
eval metrics, batch: 1024 acc, f1
0.77069091796875, 0.7382428760537867
eval metrics, batch: 2048 acc, f1
0.773345947265625, 0.7388445444635887
eval metrics, batch: 3072 acc, f1
0.80535888671875, 0.8156221091581869
eval metrics, batch: 4096 acc, f1
0.797088623046875, 0.7957861113670567
train metrics, batch: 4096  acc, f1 
0.9307327270507812, 0.9341060515887416
eval metrics, batch: 5120 acc, f1
0.7720947265625, 0.7321953668507495
eval metrics, batch: 6144 acc, f1
0.7828369140625, 0.7602102709260008
eval metrics, batch: 7168 acc, f1
0.743927001953125, 0.6821229685191499
Epoch loss - train: tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.7038, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.754364013671875, 0.7036996134732192
train metrics acc, f1 
0.9460601806640625, 0.9444479366376466
Epoch 7/20
----------
eval metrics, batch: 1024 acc, f1
0.77392578125, 0.7379554297842236
eval metrics, batch: 2048 acc, f1
0.7635498046875, 0.7271830985915493
eval metrics, batch: 3072 acc, f1
0.74835205078125, 0.691484585453457
eval metrics, batch: 4096 acc, f1
0.771575927734375, 0.7439887813387146
train metrics, batch: 4096  acc, f1 
0.9648666381835938, 0.9651176002726963
eval metrics, batch: 5120 acc, f1
0.76708984375, 0.7300891215164804
eval metrics, batch: 6144 acc, f1
0.795654296875, 0.7928986762340715
eval metrics, batch: 7168 acc, f1
0.78564453125, 0.7803215112278726
Epoch loss - train: tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6690, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.76641845703125, 0.7489833398924308
train metrics acc, f1 
0.9614944458007812, 0.9623717642848623
Epoch 8/20
----------
eval metrics, batch: 1024 acc, f1
0.762115478515625, 0.7283309518000907
eval metrics, batch: 2048 acc, f1
0.77227783203125, 0.7372905224616251
eval metrics, batch: 3072 acc, f1
0.79010009765625, 0.7850625
eval metrics, batch: 4096 acc, f1
0.77386474609375, 0.7492216055232165
train metrics, batch: 4096  acc, f1 
0.9736328125, 0.9739268200678989
eval metrics, batch: 5120 acc, f1
0.77557373046875, 0.7539645366343258
eval metrics, batch: 6144 acc, f1
0.76348876953125, 0.7244738339021616
eval metrics, batch: 7168 acc, f1
0.739654541015625, 0.6922993688007214
Epoch loss - train: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.9064, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.753021240234375, 0.7046889253785805
train metrics acc, f1 
0.97491455078125, 0.9745441876669376
Epoch 9/20
----------
eval metrics, batch: 1024 acc, f1
0.75592041015625, 0.7173851590106007
eval metrics, batch: 2048 acc, f1
0.732330322265625, 0.6670209938878554
eval metrics, batch: 3072 acc, f1
0.769561767578125, 0.732603845745246
eval metrics, batch: 4096 acc, f1
0.724151611328125, 0.6428260955466867
train metrics, batch: 4096  acc, f1 
0.9492340087890625, 0.9468109767308015
eval metrics, batch: 5120 acc, f1
0.78472900390625, 0.7801259273112648
eval metrics, batch: 6144 acc, f1
0.77197265625, 0.7443547283426851
eval metrics, batch: 7168 acc, f1
0.780181884765625, 0.7638747746271103
Epoch loss - train: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.0521, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.75946044921875, 0.7141095393543707
train metrics acc, f1 
0.982757568359375, 0.9825506879352677
Epoch 10/20
----------
eval metrics, batch: 1024 acc, f1
0.769775390625, 0.7500165683610577
eval metrics, batch: 2048 acc, f1
0.764434814453125, 0.7358406625372164
eval metrics, batch: 3072 acc, f1
0.780426025390625, 0.7588564533967892
eval metrics, batch: 4096 acc, f1
0.77630615234375, 0.7546197107659347
train metrics, batch: 4096  acc, f1 
0.9844131469726562, 0.9845213201200109
eval metrics, batch: 5120 acc, f1
0.742919921875, 0.6812471621008022
eval metrics, batch: 6144 acc, f1
0.76324462890625, 0.735510705032047
eval metrics, batch: 7168 acc, f1
0.769805908203125, 0.7318997689710325
Epoch loss - train: tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.9424, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7889404296875, 0.7695588431294149
train metrics acc, f1 
0.989715576171875, 0.9897592512402094
Epoch 11/20
----------
eval metrics, batch: 1024 acc, f1
0.76019287109375, 0.7266402282056634
eval metrics, batch: 2048 acc, f1
0.76434326171875, 0.7367200818274804
eval metrics, batch: 3072 acc, f1
0.7459716796875, 0.6921142180795976
eval metrics, batch: 4096 acc, f1
0.79296875, 0.7830092118730808
train metrics, batch: 4096  acc, f1 
0.9808006286621094, 0.9810587956359585
eval metrics, batch: 5120 acc, f1
0.7635498046875, 0.7195598668017953
eval metrics, batch: 6144 acc, f1
0.7474365234375, 0.6897585844954266
eval metrics, batch: 7168 acc, f1
0.7724609375, 0.7433920704845814
Epoch loss - train: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.4422, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.74945068359375, 0.6978284873021715
train metrics acc, f1 
0.9879150390625, 0.9878062862289555
Epoch 12/20
----------
eval metrics, batch: 1024 acc, f1
0.769073486328125, 0.7394911694839398
eval metrics, batch: 2048 acc, f1
0.78924560546875, 0.780747983998984
eval metrics, batch: 3072 acc, f1
0.756011962890625, 0.7100003627262504
eval metrics, batch: 4096 acc, f1
0.765899658203125, 0.7305300874697017
train metrics, batch: 4096  acc, f1 
0.9923820495605469, 0.9923731176266151
eval metrics, batch: 5120 acc, f1
0.75775146484375, 0.714234286125711
eval metrics, batch: 6144 acc, f1
0.7379150390625, 0.6753610040069554
eval metrics, batch: 7168 acc, f1
0.77313232421875, 0.7517697342059569
Epoch loss - train: tensor(0.0561, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.3766, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.762451171875, 0.7217615098655991
train metrics acc, f1 
0.9869766235351562, 0.9869189388017839
Epoch 13/20
----------
eval metrics, batch: 1024 acc, f1
0.76995849609375, 0.7385725185544842
eval metrics, batch: 2048 acc, f1
0.7838134765625, 0.771483870967742
eval metrics, batch: 3072 acc, f1
0.746368408203125, 0.6978147838417628
eval metrics, batch: 4096 acc, f1
0.787841796875, 0.7706367535466843
train metrics, batch: 4096  acc, f1 
0.9877853393554688, 0.987866891999424
eval metrics, batch: 5120 acc, f1
0.758636474609375, 0.7152270190472761
eval metrics, batch: 6144 acc, f1
0.773345947265625, 0.7503948916148546
eval metrics, batch: 7168 acc, f1
0.763671875, 0.7234088149153511
Epoch loss - train: tensor(0.0506, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.4358, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7425537109375, 0.6897160511990584
train metrics acc, f1 
0.989959716796875, 0.9898864920114046
Epoch 14/20
----------
eval metrics, batch: 1024 acc, f1
0.77557373046875, 0.747111416781293
eval metrics, batch: 2048 acc, f1
0.779052734375, 0.7674269193703823
eval metrics, batch: 3072 acc, f1
0.75567626953125, 0.7076821965824449
eval metrics, batch: 4096 acc, f1
0.77130126953125, 0.7578049253441924
train metrics, batch: 4096  acc, f1 
0.9822731018066406, 0.9825225191342122
eval metrics, batch: 5120 acc, f1
0.793304443359375, 0.7914267237397222
eval metrics, batch: 6144 acc, f1
0.744476318359375, 0.6971899750461105
eval metrics, batch: 7168 acc, f1
0.7811279296875, 0.7615057196062782
Epoch loss - train: tensor(0.0468, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.0804, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.787017822265625, 0.7687004938189772
train metrics acc, f1 
0.99420166015625, 0.9942178061139092
Epoch 15/20
----------
eval metrics, batch: 1024 acc, f1
0.7681884765625, 0.7401477832512315
eval metrics, batch: 2048 acc, f1
0.743011474609375, 0.6814691530809094
eval metrics, batch: 3072 acc, f1
0.78375244140625, 0.7691555903049258
eval metrics, batch: 4096 acc, f1
0.7769775390625, 0.7568538727708278
train metrics, batch: 4096  acc, f1 
0.9867897033691406, 0.9869076198937639
eval metrics, batch: 5120 acc, f1
0.788360595703125, 0.7788231542018816
eval metrics, batch: 6144 acc, f1
0.73028564453125, 0.6581044487427467
eval metrics, batch: 7168 acc, f1
0.7764892578125, 0.7465042226221792
Epoch loss - train: tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.2257, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.768798828125, 0.7375277161862528
train metrics acc, f1 
0.9962387084960938, 0.9962404581607985
Epoch 16/20
----------
eval metrics, batch: 1024 acc, f1
0.766082763671875, 0.7299439805517387
eval metrics, batch: 2048 acc, f1
0.75469970703125, 0.7069204404579597
eval metrics, batch: 3072 acc, f1
0.7613525390625, 0.7376191115286539
eval metrics, batch: 4096 acc, f1
0.7384033203125, 0.6816932788711474
train metrics, batch: 4096  acc, f1 
0.9893417358398438, 0.989248966838796
eval metrics, batch: 5120 acc, f1
0.766632080078125, 0.7281066666666667
eval metrics, batch: 6144 acc, f1
0.77398681640625, 0.7469937141295436
eval metrics, batch: 7168 acc, f1
0.77252197265625, 0.7388776010649478
Epoch loss - train: tensor(0.0390, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1282, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.79058837890625, 0.776015145580363
train metrics acc, f1 
0.9939537048339844, 0.9939756517508619
Epoch 17/20
----------
eval metrics, batch: 1024 acc, f1
0.7607421875, 0.7221631582677723
eval metrics, batch: 2048 acc, f1
0.747802734375, 0.6944013016788699
eval metrics, batch: 3072 acc, f1
0.761505126953125, 0.7238027920127231
eval metrics, batch: 4096 acc, f1
0.7767333984375, 0.7517306909189629
train metrics, batch: 4096  acc, f1 
0.9884147644042969, 0.9884203743456196
eval metrics, batch: 5120 acc, f1
0.792633056640625, 0.7860718445990618
eval metrics, batch: 6144 acc, f1
0.779205322265625, 0.7540872166139833
eval metrics, batch: 7168 acc, f1
0.775848388671875, 0.7541751731985675
Epoch loss - train: tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.4225, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.755859375, 0.7124991015596924
train metrics acc, f1 
0.9951934814453125, 0.9951821602275855
Epoch 18/20
----------
eval metrics, batch: 1024 acc, f1
0.75830078125, 0.7185100938299688
eval metrics, batch: 2048 acc, f1
0.767974853515625, 0.7385758002957054
eval metrics, batch: 3072 acc, f1
0.78094482421875, 0.7565294077742352
eval metrics, batch: 4096 acc, f1
0.761322021484375, 0.7261266939804601
train metrics, batch: 4096  acc, f1 
0.9945945739746094, 0.994591128228814
eval metrics, batch: 5120 acc, f1
0.7928466796875, 0.785081053698075
eval metrics, batch: 6144 acc, f1
0.744415283203125, 0.7013088911872749
eval metrics, batch: 7168 acc, f1
0.7791748046875, 0.7536429252349176
Epoch loss - train: tensor(0.0346, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1356, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.79296875, 0.7784165142409197
train metrics acc, f1 
0.9892234802246094, 0.9892874342551828
Epoch 19/20
----------
eval metrics, batch: 1024 acc, f1
0.7606201171875, 0.7242494551079238
eval metrics, batch: 2048 acc, f1
0.78118896484375, 0.7595895922746781
eval metrics, batch: 3072 acc, f1
0.78375244140625, 0.7607859023698602
eval metrics, batch: 4096 acc, f1
0.773681640625, 0.7410614525139665
train metrics, batch: 4096  acc, f1 
0.9954872131347656, 0.9954779151774622
eval metrics, batch: 5120 acc, f1
0.78643798828125, 0.7673537234042553
eval metrics, batch: 6144 acc, f1
0.760772705078125, 0.7262441068622315
eval metrics, batch: 7168 acc, f1
0.796630859375, 0.7915024091108191
Epoch loss - train: tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.4269, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.771881103515625, 0.7373229785290086
train metrics acc, f1 
0.9967727661132812, 0.9967665988900949
Epoch 20/20
----------
eval metrics, batch: 1024 acc, f1
0.763427734375, 0.7296505545093116
eval metrics, batch: 2048 acc, f1
0.7490234375, 0.6923997606223818
eval metrics, batch: 3072 acc, f1
0.7755126953125, 0.7542265285666555
eval metrics, batch: 4096 acc, f1
0.76873779296875, 0.7314480119072932
train metrics, batch: 4096  acc, f1 
0.9941864013671875, 0.9941647202971244
eval metrics, batch: 5120 acc, f1
0.762359619140625, 0.7209660658616118
eval metrics, batch: 6144 acc, f1
0.787353515625, 0.7647058823529411
eval metrics, batch: 7168 acc, f1
0.7579345703125, 0.7136875541438059
Epoch loss - train: tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.4551, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.773956298828125, 0.7423204035484432
train metrics acc, f1 
0.9968948364257812, 0.9968915636885759
Training time 505m 31s
train_acc
0.5006904602050781	0.831939697265625	0.8598785400390625	0.8735771179199219	0.8853034973144531	0.8922386169433594	0.9060745239257812	0.91424560546875	0.8999366760253906	0.9374618530273438	0.927276611328125	0.9307327270507812	0.9460601806640625	0.9648666381835938	0.9614944458007812	0.9736328125	0.97491455078125	0.9492340087890625	0.982757568359375	0.9844131469726562	0.989715576171875	0.9808006286621094	0.9879150390625	0.9923820495605469	0.9869766235351562	0.9877853393554688	0.989959716796875	0.9822731018066406	0.99420166015625	0.9867897033691406	0.9962387084960938	0.9893417358398438	0.9939537048339844	0.9884147644042969	0.9951934814453125	0.9945945739746094	0.9892234802246094	0.9954872131347656	0.9967727661132812	0.9941864013671875	0.9968948364257812
train_f1
0.6669736791888763	0.8237210009522972	0.865902453271028	0.8725782328356831	0.8897905922284901	0.8959593987897716	0.9047821614472554	0.9133284497050546	0.8926898515388172	0.9381880976080597	0.9234162214277106	0.9341060515887416	0.9444479366376466	0.9651176002726963	0.9623717642848623	0.9739268200678989	0.9745441876669376	0.9468109767308015	0.9825506879352677	0.9845213201200109	0.9897592512402094	0.9810587956359585	0.9878062862289555	0.9923731176266151	0.9869189388017839	0.987866891999424	0.9898864920114046	0.9825225191342122	0.9942178061139092	0.9869076198937639	0.9962404581607985	0.989248966838796	0.9939756517508619	0.9884203743456196	0.9951821602275855	0.994591128228814	0.9892874342551828	0.9954779151774622	0.9967665988900949	0.9941647202971244	0.9968915636885759
train_loss
tensor(0.3936, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3312, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2875, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0561, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0506, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0468, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0390, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0346, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.5	0.78082275390625	0.7957763671875	0.780029296875	0.7802734375	0.795745849609375	0.795867919921875	0.784210205078125	0.814727783203125	0.772003173828125	0.79107666015625	0.805938720703125	0.79730224609375	0.79144287109375	0.78594970703125	0.79736328125	0.799835205078125	0.782012939453125	0.7984619140625	0.79388427734375	0.795684814453125	0.77972412109375	0.75421142578125	0.81256103515625	0.7744140625	0.789520263671875	0.8072509765625	0.804443359375	0.7659912109375	0.76806640625	0.7606201171875	0.75518798828125	0.7412109375	0.77032470703125	0.769134521484375	0.775970458984375	0.781158447265625	0.781829833984375	0.769073486328125	0.78729248046875	0.732757568359375	0.77069091796875	0.773345947265625	0.80535888671875	0.797088623046875	0.7720947265625	0.7828369140625	0.743927001953125	0.754364013671875	0.77392578125	0.7635498046875	0.74835205078125	0.771575927734375	0.76708984375	0.795654296875	0.78564453125	0.76641845703125	0.762115478515625	0.77227783203125	0.79010009765625	0.77386474609375	0.77557373046875	0.76348876953125	0.739654541015625	0.753021240234375	0.75592041015625	0.732330322265625	0.769561767578125	0.724151611328125	0.78472900390625	0.77197265625	0.780181884765625	0.75946044921875	0.769775390625	0.764434814453125	0.780426025390625	0.77630615234375	0.742919921875	0.76324462890625	0.769805908203125	0.7889404296875	0.76019287109375	0.76434326171875	0.7459716796875	0.79296875	0.7635498046875	0.7474365234375	0.7724609375	0.74945068359375	0.769073486328125	0.78924560546875	0.756011962890625	0.765899658203125	0.75775146484375	0.7379150390625	0.77313232421875	0.762451171875	0.76995849609375	0.7838134765625	0.746368408203125	0.787841796875	0.758636474609375	0.773345947265625	0.763671875	0.7425537109375	0.77557373046875	0.779052734375	0.75567626953125	0.77130126953125	0.793304443359375	0.744476318359375	0.7811279296875	0.787017822265625	0.7681884765625	0.743011474609375	0.78375244140625	0.7769775390625	0.788360595703125	0.73028564453125	0.7764892578125	0.768798828125	0.766082763671875	0.75469970703125	0.7613525390625	0.7384033203125	0.766632080078125	0.77398681640625	0.77252197265625	0.79058837890625	0.7607421875	0.747802734375	0.761505126953125	0.7767333984375	0.792633056640625	0.779205322265625	0.775848388671875	0.755859375	0.75830078125	0.767974853515625	0.78094482421875	0.761322021484375	0.7928466796875	0.744415283203125	0.7791748046875	0.79296875	0.7606201171875	0.78118896484375	0.78375244140625	0.773681640625	0.78643798828125	0.760772705078125	0.796630859375	0.771881103515625	0.763427734375	0.7490234375	0.7755126953125	0.76873779296875	0.762359619140625	0.787353515625	0.7579345703125	0.773956298828125
valid_f1
0.6664630918936525	0.7697191227395151	0.7967316687929045	0.7696094099597264	0.7580157289776165	0.787800006340953	0.7845940810871735	0.7582481452357346	0.8145863237943988	0.7407613033068462	0.7736260829310231	0.7913234666754175	0.7803571428571429	0.7786917098445596	0.7584378013500482	0.79262960649594	0.7933717670037489	0.7581349676632919	0.7763175721446959	0.7732491774659236	0.7865182870444182	0.7464699683877766	0.7026068975703419	0.8118836140888208	0.74162880111849	0.7729980581246092	0.8093915982617094	0.7969066937119675	0.7304176627759809	0.7296720495126983	0.7154052681227777	0.7071407710280374	0.6737457679285934	0.7427536231884058	0.7282784382744872	0.7401875774199257	0.7585115339282708	0.7620093877958654	0.7310084959653051	0.771220376813497	0.6618788370207344	0.7382428760537867	0.7388445444635887	0.8156221091581869	0.7957861113670567	0.7321953668507495	0.7602102709260008	0.6821229685191499	0.7036996134732192	0.7379554297842236	0.7271830985915493	0.691484585453457	0.7439887813387146	0.7300891215164804	0.7928986762340715	0.7803215112278726	0.7489833398924308	0.7283309518000907	0.7372905224616251	0.7850625	0.7492216055232165	0.7539645366343258	0.7244738339021616	0.6922993688007214	0.7046889253785805	0.7173851590106007	0.6670209938878554	0.732603845745246	0.6428260955466867	0.7801259273112648	0.7443547283426851	0.7638747746271103	0.7141095393543707	0.7500165683610577	0.7358406625372164	0.7588564533967892	0.7546197107659347	0.6812471621008022	0.735510705032047	0.7318997689710325	0.7695588431294149	0.7266402282056634	0.7367200818274804	0.6921142180795976	0.7830092118730808	0.7195598668017953	0.6897585844954266	0.7433920704845814	0.6978284873021715	0.7394911694839398	0.780747983998984	0.7100003627262504	0.7305300874697017	0.714234286125711	0.6753610040069554	0.7517697342059569	0.7217615098655991	0.7385725185544842	0.771483870967742	0.6978147838417628	0.7706367535466843	0.7152270190472761	0.7503948916148546	0.7234088149153511	0.6897160511990584	0.747111416781293	0.7674269193703823	0.7076821965824449	0.7578049253441924	0.7914267237397222	0.6971899750461105	0.7615057196062782	0.7687004938189772	0.7401477832512315	0.6814691530809094	0.7691555903049258	0.7568538727708278	0.7788231542018816	0.6581044487427467	0.7465042226221792	0.7375277161862528	0.7299439805517387	0.7069204404579597	0.7376191115286539	0.6816932788711474	0.7281066666666667	0.7469937141295436	0.7388776010649478	0.776015145580363	0.7221631582677723	0.6944013016788699	0.7238027920127231	0.7517306909189629	0.7860718445990618	0.7540872166139833	0.7541751731985675	0.7124991015596924	0.7185100938299688	0.7385758002957054	0.7565294077742352	0.7261266939804601	0.785081053698075	0.7013088911872749	0.7536429252349176	0.7784165142409197	0.7242494551079238	0.7595895922746781	0.7607859023698602	0.7410614525139665	0.7673537234042553	0.7262441068622315	0.7915024091108191	0.7373229785290086	0.7296505545093116	0.6923997606223818	0.7542265285666555	0.7314480119072932	0.7209660658616118	0.7647058823529411	0.7136875541438059	0.7423204035484432
valid_loss
tensor(0.4132, device='cuda:0')	tensor(0.4262, device='cuda:0')	tensor(0.5312, device='cuda:0')	tensor(0.7175, device='cuda:0')	tensor(0.6977, device='cuda:0')	tensor(0.7038, device='cuda:0')	tensor(0.6690, device='cuda:0')	tensor(0.9064, device='cuda:0')	tensor(1.0521, device='cuda:0')	tensor(0.9424, device='cuda:0')	tensor(1.4422, device='cuda:0')	tensor(1.3766, device='cuda:0')	tensor(1.4358, device='cuda:0')	tensor(1.0804, device='cuda:0')	tensor(1.2257, device='cuda:0')	tensor(1.1282, device='cuda:0')	tensor(1.4225, device='cuda:0')	tensor(1.1356, device='cuda:0')	tensor(1.4269, device='cuda:0')	tensor(1.4551, device='cuda:0')
Best model metrics: train, valid, test: acc, f1
0.8598785400390625, 0.865902453271028
0.814727783203125, 0.8145863237943988
0.7891845703125, 0.7856788284934226
Model saved, path ./models/resnet_13-1559491145.pth
experiment validation
train set
Evaluation results
[[106818.  24254.]
 [ 12478. 118594.]]
#############################
Accuracy
0.8598785400390625
------------------------
Recall
0.9048004150390625
------------------------
Specificity
0.8149566650390625
------------------------
Precision
0.8302111335125448
------------------------
Fall_out
0.1850433349609375
------------------------
F1
0.865902453271028
------------------------
#############################
valid set
Evaluation results
[[13361.  3038.]
 [ 3033. 13336.]]
#############################
Accuracy
0.814727783203125
------------------------
Recall
0.8147107337039526
------------------------
Specificity
0.8147448015122873
------------------------
Precision
0.8144619518749237
------------------------
Fall_out
0.18525519848771266
------------------------
F1
0.8145863237943988
------------------------
#############################
test set
Evaluation results
[[13198.  3193.]
 [ 3715. 12662.]]
#############################
Accuracy
0.7891845703125
------------------------
Recall
0.7731574769493802
------------------------
Specificity
0.8051979744982002
------------------------
Precision
0.7986124251024913
------------------------
Fall_out
0.19480202550179976
------------------------
F1
0.7856788284934226
------------------------
#############################
AUC: 0.8719719098010048
Experiment end
########################################
