----------------------------------------
Starting experiment resnet_9
Experiment parameters Experiment[name: resnet_9, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 1e-05, weight_decay: 0, batch_size: 32, num_epochs: 8), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.521514892578125, 0.674662295354097
train metrics acc, f1
0.5159645080566406, 0.6704019741541658
Epoch 1/8
----------
eval metrics, batch: 1024 acc, f1
0.615875244140625, 0.6337048569682507
eval metrics, batch: 2048 acc, f1
0.67401123046875, 0.6820644085957498
eval metrics, batch: 3072 acc, f1
0.7083740234375, 0.7102134885977681
eval metrics, batch: 4096 acc, f1
0.732574462890625, 0.7319609702382773
train metrics, batch: 4096  acc, f1 
0.7330780029296875, 0.7370580808080808
eval metrics, batch: 5120 acc, f1
0.7459716796875, 0.7436086983305612
eval metrics, batch: 6144 acc, f1
0.7557373046875, 0.7467569448838828
eval metrics, batch: 7168 acc, f1
0.763885498046875, 0.7559690900488882
Epoch loss - train: tensor(0.5646, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4990, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.769927978515625, 0.7622591529753082
train metrics acc, f1 
0.7738304138183594, 0.7714053276681716
Epoch 2/8
----------
eval metrics, batch: 1024 acc, f1
0.7730712890625, 0.7635612082670906
eval metrics, batch: 2048 acc, f1
0.775726318359375, 0.7647793105655667
eval metrics, batch: 3072 acc, f1
0.7777099609375, 0.7670759785111282
eval metrics, batch: 4096 acc, f1
0.7786865234375, 0.7667717244484467
train metrics, batch: 4096  acc, f1 
0.7886428833007812, 0.782862920608545
eval metrics, batch: 5120 acc, f1
0.78021240234375, 0.7678122380553227
eval metrics, batch: 6144 acc, f1
0.7822265625, 0.7709002183125723
eval metrics, batch: 7168 acc, f1
0.783355712890625, 0.7718463763458139
Epoch loss - train: tensor(0.4709, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4622, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.783203125, 0.7705574575285834
train metrics acc, f1 
0.7961387634277344, 0.7904282728303026
Epoch 3/8
----------
eval metrics, batch: 1024 acc, f1
0.78424072265625, 0.7698567708333334
eval metrics, batch: 2048 acc, f1
0.787841796875, 0.7789928789420142
eval metrics, batch: 3072 acc, f1
0.78668212890625, 0.7751833269008105
eval metrics, batch: 4096 acc, f1
0.7880859375, 0.7781611398632675
train metrics, batch: 4096  acc, f1 
0.8003730773925781, 0.7964716726496291
eval metrics, batch: 5120 acc, f1
0.786590576171875, 0.7742372881355932
eval metrics, batch: 6144 acc, f1
0.7889404296875, 0.7784753363228699
eval metrics, batch: 7168 acc, f1
0.790313720703125, 0.7801068902614651
Epoch loss - train: tensor(0.4475, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4492, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.79132080078125, 0.7815475049517603
train metrics acc, f1 
0.8039093017578125, 0.8001803678882963
Epoch 4/8
----------
eval metrics, batch: 1024 acc, f1
0.792633056640625, 0.7833296132138644
eval metrics, batch: 2048 acc, f1
0.79193115234375, 0.7803337843933243
eval metrics, batch: 3072 acc, f1
0.792694091796875, 0.7815123347592551
eval metrics, batch: 4096 acc, f1
0.7947998046875, 0.7859280483922317
train metrics, batch: 4096  acc, f1 
0.8058052062988281, 0.8026806928870163
eval metrics, batch: 5120 acc, f1
0.792449951171875, 0.7798815418972715
eval metrics, batch: 6144 acc, f1
0.792816162109375, 0.7804120710288838
eval metrics, batch: 7168 acc, f1
0.793426513671875, 0.7825360619397951
Epoch loss - train: tensor(0.4342, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4417, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.79327392578125, 0.7835367802134594
train metrics acc, f1 
0.8078994750976562, 0.8045897618973706
Epoch 5/8
----------
eval metrics, batch: 1024 acc, f1
0.78729248046875, 0.7717747216764899
eval metrics, batch: 2048 acc, f1
0.788482666015625, 0.7736520688416446
eval metrics, batch: 3072 acc, f1
0.790008544921875, 0.7771047261183636
eval metrics, batch: 4096 acc, f1
0.7916259765625, 0.7795997417688831
train metrics, batch: 4096  acc, f1 
0.8090896606445312, 0.8046466964892147
eval metrics, batch: 5120 acc, f1
0.79156494140625, 0.7798620511828789
eval metrics, batch: 6144 acc, f1
0.791229248046875, 0.7785008903998705
eval metrics, batch: 7168 acc, f1
0.791351318359375, 0.7794018004065434
Epoch loss - train: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4408, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.792877197265625, 0.7816350825263022
train metrics acc, f1 
0.8102951049804688, 0.8063081309299391
Epoch 6/8
----------
eval metrics, batch: 1024 acc, f1
0.796051025390625, 0.7829419597908344
eval metrics, batch: 2048 acc, f1
0.796844482421875, 0.7852788439828404
eval metrics, batch: 3072 acc, f1
0.79730224609375, 0.7868694647670389
eval metrics, batch: 4096 acc, f1
0.7969970703125, 0.787258539081489
train metrics, batch: 4096  acc, f1 
0.8124008178710938, 0.8091271812705707
eval metrics, batch: 5120 acc, f1
0.797149658203125, 0.7861119155645654
eval metrics, batch: 6144 acc, f1
0.796905517578125, 0.7852602368429544
eval metrics, batch: 7168 acc, f1
0.796600341796875, 0.7846735372984848
Epoch loss - train: tensor(0.4207, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4355, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.796600341796875, 0.7867131748215943
train metrics acc, f1 
0.8136520385742188, 0.8105693389897548
Epoch 7/8
----------
eval metrics, batch: 1024 acc, f1
0.791748046875, 0.7784415584415585
eval metrics, batch: 2048 acc, f1
0.7921142578125, 0.7779516265727883
eval metrics, batch: 3072 acc, f1
0.793548583984375, 0.7791741472172352
eval metrics, batch: 4096 acc, f1
0.79583740234375, 0.7837331092002328
train metrics, batch: 4096  acc, f1 
0.8145484924316406, 0.8098265104543587
eval metrics, batch: 5120 acc, f1
0.796844482421875, 0.7863675748531819
eval metrics, batch: 6144 acc, f1
0.796112060546875, 0.784017069149452
eval metrics, batch: 7168 acc, f1
0.79656982421875, 0.7855488354137177
Epoch loss - train: tensor(0.4176, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4339, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7972412109375, 0.7863940329218106
train metrics acc, f1 
0.8157539367675781, 0.8118633702473094
Epoch 8/8
----------
eval metrics, batch: 1024 acc, f1
0.7939453125, 0.7809499091616922
eval metrics, batch: 2048 acc, f1
0.795440673828125, 0.7840458777666807
eval metrics, batch: 3072 acc, f1
0.79595947265625, 0.7854575792581183
eval metrics, batch: 4096 acc, f1
0.794586181640625, 0.781595768843895
train metrics, batch: 4096  acc, f1 
0.8162994384765625, 0.8111381284806651
eval metrics, batch: 5120 acc, f1
0.794525146484375, 0.7812469540920758
eval metrics, batch: 6144 acc, f1
0.79437255859375, 0.781955860462106
eval metrics, batch: 7168 acc, f1
0.797119140625, 0.7874816188223259
Epoch loss - train: tensor(0.4155, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4324, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.794525146484375, 0.7815308738116097
train metrics acc, f1 
0.816925048828125, 0.8119096702383658
Training time 97m 54s
train_acc
0.5159645080566406	0.7330780029296875	0.7738304138183594	0.7886428833007812	0.7961387634277344	0.8003730773925781	0.8039093017578125	0.8058052062988281	0.8078994750976562	0.8090896606445312	0.8102951049804688	0.8124008178710938	0.8136520385742188	0.8145484924316406	0.8157539367675781	0.8162994384765625	0.816925048828125
train_f1
0.6704019741541658	0.7370580808080808	0.7714053276681716	0.782862920608545	0.7904282728303026	0.7964716726496291	0.8001803678882963	0.8026806928870163	0.8045897618973706	0.8046466964892147	0.8063081309299391	0.8091271812705707	0.8105693389897548	0.8098265104543587	0.8118633702473094	0.8111381284806651	0.8119096702383658
train_loss
tensor(0.5646, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4709, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4475, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4342, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4207, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4176, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4155, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.521514892578125	0.615875244140625	0.67401123046875	0.7083740234375	0.732574462890625	0.7459716796875	0.7557373046875	0.763885498046875	0.769927978515625	0.7730712890625	0.775726318359375	0.7777099609375	0.7786865234375	0.78021240234375	0.7822265625	0.783355712890625	0.783203125	0.78424072265625	0.787841796875	0.78668212890625	0.7880859375	0.786590576171875	0.7889404296875	0.790313720703125	0.79132080078125	0.792633056640625	0.79193115234375	0.792694091796875	0.7947998046875	0.792449951171875	0.792816162109375	0.793426513671875	0.79327392578125	0.78729248046875	0.788482666015625	0.790008544921875	0.7916259765625	0.79156494140625	0.791229248046875	0.791351318359375	0.792877197265625	0.796051025390625	0.796844482421875	0.79730224609375	0.7969970703125	0.797149658203125	0.796905517578125	0.796600341796875	0.796600341796875	0.791748046875	0.7921142578125	0.793548583984375	0.79583740234375	0.796844482421875	0.796112060546875	0.79656982421875	0.7972412109375	0.7939453125	0.795440673828125	0.79595947265625	0.794586181640625	0.794525146484375	0.79437255859375	0.797119140625	0.794525146484375
valid_f1
0.674662295354097	0.6337048569682507	0.6820644085957498	0.7102134885977681	0.7319609702382773	0.7436086983305612	0.7467569448838828	0.7559690900488882	0.7622591529753082	0.7635612082670906	0.7647793105655667	0.7670759785111282	0.7667717244484467	0.7678122380553227	0.7709002183125723	0.7718463763458139	0.7705574575285834	0.7698567708333334	0.7789928789420142	0.7751833269008105	0.7781611398632675	0.7742372881355932	0.7784753363228699	0.7801068902614651	0.7815475049517603	0.7833296132138644	0.7803337843933243	0.7815123347592551	0.7859280483922317	0.7798815418972715	0.7804120710288838	0.7825360619397951	0.7835367802134594	0.7717747216764899	0.7736520688416446	0.7771047261183636	0.7795997417688831	0.7798620511828789	0.7785008903998705	0.7794018004065434	0.7816350825263022	0.7829419597908344	0.7852788439828404	0.7868694647670389	0.787258539081489	0.7861119155645654	0.7852602368429544	0.7846735372984848	0.7867131748215943	0.7784415584415585	0.7779516265727883	0.7791741472172352	0.7837331092002328	0.7863675748531819	0.784017069149452	0.7855488354137177	0.7863940329218106	0.7809499091616922	0.7840458777666807	0.7854575792581183	0.781595768843895	0.7812469540920758	0.781955860462106	0.7874816188223259	0.7815308738116097
valid_loss
tensor(0.4990, device='cuda:0')	tensor(0.4622, device='cuda:0')	tensor(0.4492, device='cuda:0')	tensor(0.4417, device='cuda:0')	tensor(0.4408, device='cuda:0')	tensor(0.4355, device='cuda:0')	tensor(0.4339, device='cuda:0')	tensor(0.4324, device='cuda:0')
Experiment end
########################################