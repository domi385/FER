----------------------------------------
Starting experiment horizontalflip-1560101954
Experiment parameters Experiment[name: horizontalflip-1560101954, model: DenseNet(
  (features): Sequential(
    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu0): ReLU(inplace)
    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (denseblock1): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition1): _Transition(
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock2): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition2): _Transition(
      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock3): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer17): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer18): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer19): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer20): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer21): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer22): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer23): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer24): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition3): _Transition(
      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock4): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (classifier): Linear(in_features=1024, out_features=1, bias=True)
), params: Params(lr: 0.0001, weight_decay: 0, batch_size: 32, num_epochs: 20), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.541595458984375, 0.6343031040779062
train metrics acc, f1
0.5066299438476562, 0.599714023967515
Epoch 1/20
----------
eval metrics, batch: 1024 acc, f1
0.882171630859375, 0.8741566441771781
eval metrics, batch: 2048 acc, f1
0.88153076171875, 0.8791256694482501
eval metrics, batch: 3072 acc, f1
0.891693115234375, 0.8878850102669404
eval metrics, batch: 4096 acc, f1
0.8701171875, 0.8549816001090363
train metrics, batch: 4096  acc, f1 
0.949249267578125, 0.9478524000282218
eval metrics, batch: 5120 acc, f1
0.881103515625, 0.870219853431046
eval metrics, batch: 6144 acc, f1
0.89593505859375, 0.8886348791639451
eval metrics, batch: 7168 acc, f1
0.858184814453125, 0.8403476826880132
Epoch loss - train: tensor(0.1793, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3533, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.874908447265625, 0.8620376291609169
train metrics acc, f1 
0.9592514038085938, 0.95878635420123
Epoch 2/20
----------
eval metrics, batch: 1024 acc, f1
0.880462646484375, 0.8687640298857506
eval metrics, batch: 2048 acc, f1
0.859619140625, 0.8414667769506479
eval metrics, batch: 3072 acc, f1
0.869537353515625, 0.8545473104011432
eval metrics, batch: 4096 acc, f1
0.84539794921875, 0.8193939393939393
train metrics, batch: 4096  acc, f1 
0.9505577087402344, 0.9485358057535389
eval metrics, batch: 5120 acc, f1
0.87835693359375, 0.8666086607322133
eval metrics, batch: 6144 acc, f1
0.90496826171875, 0.9000705988062384
eval metrics, batch: 7168 acc, f1
0.897491455078125, 0.8977691207353076
Epoch loss - train: tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.2997, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.892669677734375, 0.8850465762379474
train metrics acc, f1 
0.9677009582519531, 0.9676517220959331
Epoch 3/20
----------
eval metrics, batch: 1024 acc, f1
0.855499267578125, 0.8370556454110603
eval metrics, batch: 2048 acc, f1
0.8614501953125, 0.8443392991839813
eval metrics, batch: 3072 acc, f1
0.855377197265625, 0.8363322396822656
eval metrics, batch: 4096 acc, f1
0.871978759765625, 0.8581092508033147
train metrics, batch: 4096  acc, f1 
0.9693412780761719, 0.9691632998377016
eval metrics, batch: 5120 acc, f1
0.82470703125, 0.7913851964843466
eval metrics, batch: 6144 acc, f1
0.912567138671875, 0.9102865194927195
eval metrics, batch: 7168 acc, f1
0.8865966796875, 0.8820467242254951
Epoch loss - train: tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3493, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8802490234375, 0.8682779456193354
train metrics acc, f1 
0.9612045288085938, 0.960639368372165
Epoch 4/20
----------
eval metrics, batch: 1024 acc, f1
0.84576416015625, 0.8229648311615525
eval metrics, batch: 2048 acc, f1
0.879364013671875, 0.8706775280531291
eval metrics, batch: 3072 acc, f1
0.83038330078125, 0.8012444571592047
eval metrics, batch: 4096 acc, f1
0.86932373046875, 0.8552791672299581
train metrics, batch: 4096  acc, f1 
0.9726524353027344, 0.9725307778667576
eval metrics, batch: 5120 acc, f1
0.86346435546875, 0.8497750318984622
eval metrics, batch: 6144 acc, f1
0.8331298828125, 0.804700335738267
eval metrics, batch: 7168 acc, f1
0.88916015625, 0.8827706410173649
Epoch loss - train: tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3071, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8873291015625, 0.8772687986171133
train metrics acc, f1 
0.9722480773925781, 0.9720884728270253
Epoch 5/20
----------
eval metrics, batch: 1024 acc, f1
0.85052490234375, 0.8288011184900385
eval metrics, batch: 2048 acc, f1
0.897613525390625, 0.8950545841283744
eval metrics, batch: 3072 acc, f1
0.860015869140625, 0.8397778476370115
eval metrics, batch: 4096 acc, f1
0.878692626953125, 0.8683905572294143
train metrics, batch: 4096  acc, f1 
0.973968505859375, 0.974167758152071
eval metrics, batch: 5120 acc, f1
0.85809326171875, 0.8390557939914163
eval metrics, batch: 6144 acc, f1
0.789886474609375, 0.739962986743211
eval metrics, batch: 7168 acc, f1
0.876220703125, 0.8629914876368059
Epoch loss - train: tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3429, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.881866455078125, 0.8703747111810601
train metrics acc, f1 
0.9785804748535156, 0.9785228789669562
Epoch 6/20
----------
eval metrics, batch: 1024 acc, f1
0.875823974609375, 0.8623710468459327
eval metrics, batch: 2048 acc, f1
0.890411376953125, 0.8833447032452977
eval metrics, batch: 3072 acc, f1
0.8699951171875, 0.854855195911414
eval metrics, batch: 4096 acc, f1
0.8297119140625, 0.7978993118435349
train metrics, batch: 4096  acc, f1 
0.9635887145996094, 0.9625093775653287
eval metrics, batch: 5120 acc, f1
0.9090576171875, 0.905993690851735
eval metrics, batch: 6144 acc, f1
0.858642578125, 0.8390101487557348
eval metrics, batch: 7168 acc, f1
0.87445068359375, 0.8599537037037037
Epoch loss - train: tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.2676, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.90216064453125, 0.8973225723802204
train metrics acc, f1 
0.9729461669921875, 0.9732822989579645
Epoch 7/20
----------
eval metrics, batch: 1024 acc, f1
0.878143310546875, 0.8653424611337808
eval metrics, batch: 2048 acc, f1
0.86883544921875, 0.8552861952861953
eval metrics, batch: 3072 acc, f1
0.85321044921875, 0.830907684735991
eval metrics, batch: 4096 acc, f1
0.882568359375, 0.8709244599490138
train metrics, batch: 4096  acc, f1 
0.9811286926269531, 0.9810560659265755
eval metrics, batch: 5120 acc, f1
0.881622314453125, 0.8694422940998283
eval metrics, batch: 6144 acc, f1
0.89031982421875, 0.88070897503983
eval metrics, batch: 7168 acc, f1
0.86834716796875, 0.8515893766340994
Epoch loss - train: tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6541, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.804046630859375, 0.759016701069619
train metrics acc, f1 
0.9623146057128906, 0.9610552417145313
Epoch 8/20
----------
eval metrics, batch: 1024 acc, f1
0.87066650390625, 0.8570175438596491
eval metrics, batch: 2048 acc, f1
0.878509521484375, 0.8667626091904013
eval metrics, batch: 3072 acc, f1
0.80450439453125, 0.762582462382329
eval metrics, batch: 4096 acc, f1
0.8905029296875, 0.8845113943607571
train metrics, batch: 4096  acc, f1 
0.9734916687011719, 0.9738303889853391
eval metrics, batch: 5120 acc, f1
0.870361328125, 0.8560780593576366
eval metrics, batch: 6144 acc, f1
0.863800048828125, 0.8462571910847773
eval metrics, batch: 7168 acc, f1
0.839202880859375, 0.8120965728754324
Epoch loss - train: tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4137, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8665771484375, 0.84974912365111
train metrics acc, f1 
0.9796981811523438, 0.9795955924639415
Epoch 9/20
----------
eval metrics, batch: 1024 acc, f1
0.8502197265625, 0.8271587547541908
eval metrics, batch: 2048 acc, f1
0.8798828125, 0.867546103109436
eval metrics, batch: 3072 acc, f1
0.890472412109375, 0.8811077616192401
eval metrics, batch: 4096 acc, f1
0.829254150390625, 0.7982547867161864
train metrics, batch: 4096  acc, f1 
0.9728775024414062, 0.9723791246785334
eval metrics, batch: 5120 acc, f1
0.873992919921875, 0.860868686187957
eval metrics, batch: 6144 acc, f1
0.880615234375, 0.8691901290710894
eval metrics, batch: 7168 acc, f1
0.896575927734375, 0.8911724093638611
Epoch loss - train: tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4380, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.887725830078125, 0.8768782838593085
train metrics acc, f1 
0.9833145141601562, 0.9832217082096251
Epoch 10/20
----------
eval metrics, batch: 1024 acc, f1
0.862945556640625, 0.8464142813173284
eval metrics, batch: 2048 acc, f1
0.846527099609375, 0.8220893621537482
eval metrics, batch: 3072 acc, f1
0.86956787109375, 0.8534796023311622
eval metrics, batch: 4096 acc, f1
0.88409423828125, 0.8730445246690735
train metrics, batch: 4096  acc, f1 
0.9855270385742188, 0.9854814021123527
eval metrics, batch: 5120 acc, f1
0.90045166015625, 0.895045045045045
eval metrics, batch: 6144 acc, f1
0.837982177734375, 0.8120109061293863
eval metrics, batch: 7168 acc, f1
0.88116455078125, 0.8682055100521221
Epoch loss - train: tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3081, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.900360107421875, 0.8992190634935333
train metrics acc, f1 
0.9635696411132812, 0.9646157380304861
Epoch 11/20
----------
eval metrics, batch: 1024 acc, f1
0.873779296875, 0.8597205263871931
eval metrics, batch: 2048 acc, f1
0.861297607421875, 0.843486345948552
eval metrics, batch: 3072 acc, f1
0.87408447265625, 0.8596312172552222
eval metrics, batch: 4096 acc, f1
0.89300537109375, 0.8858501009311714
train metrics, batch: 4096  acc, f1 
0.9801101684570312, 0.9802818179755395
eval metrics, batch: 5120 acc, f1
0.8756103515625, 0.863496316141996
eval metrics, batch: 6144 acc, f1
0.813568115234375, 0.7745340468721166
eval metrics, batch: 7168 acc, f1
0.84405517578125, 0.8186142268919494
Epoch loss - train: tensor(0.0565, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5074, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.861419677734375, 0.8421125830117172
train metrics acc, f1 
0.9826126098632812, 0.9824290879933386
Epoch 12/20
----------
eval metrics, batch: 1024 acc, f1
0.8707275390625, 0.8553476301051769
eval metrics, batch: 2048 acc, f1
0.8592529296875, 0.8404373097149184
eval metrics, batch: 3072 acc, f1
0.886505126953125, 0.8781095342663302
eval metrics, batch: 4096 acc, f1
0.86163330078125, 0.8444063143445436
train metrics, batch: 4096  acc, f1 
0.9836387634277344, 0.983610316062196
eval metrics, batch: 5120 acc, f1
0.87738037109375, 0.8649684097324909
eval metrics, batch: 6144 acc, f1
0.870452880859375, 0.8559796437659033
eval metrics, batch: 7168 acc, f1
0.8673095703125, 0.8509325287986835
Epoch loss - train: tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6216, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.868408203125, 0.8529331514324693
train metrics acc, f1 
0.9845771789550781, 0.9845459931578847
Epoch 13/20
----------
eval metrics, batch: 1024 acc, f1
0.885467529296875, 0.8753942693980544
eval metrics, batch: 2048 acc, f1
0.845977783203125, 0.8230798892277491
eval metrics, batch: 3072 acc, f1
0.839599609375, 0.8127671701339413
eval metrics, batch: 4096 acc, f1
0.82513427734375, 0.7908148364485982
train metrics, batch: 4096  acc, f1 
0.9739227294921875, 0.9733615979923779
eval metrics, batch: 5120 acc, f1
0.856781005859375, 0.8400313597163991
eval metrics, batch: 6144 acc, f1
0.855865478515625, 0.8359214868855307
eval metrics, batch: 7168 acc, f1
0.871795654296875, 0.8561153543172244
Epoch loss - train: tensor(0.0500, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3624, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.89898681640625, 0.8922526041666666
train metrics acc, f1 
0.9875907897949219, 0.9876567569105845
Epoch 14/20
----------
eval metrics, batch: 1024 acc, f1
0.87347412109375, 0.860262891809909
eval metrics, batch: 2048 acc, f1
0.849456787109375, 0.8273061438823736
eval metrics, batch: 3072 acc, f1
0.8492431640625, 0.826970227670753
eval metrics, batch: 4096 acc, f1
0.87872314453125, 0.8667069162138593
train metrics, batch: 4096  acc, f1 
0.9877243041992188, 0.9877473937510947
eval metrics, batch: 5120 acc, f1
0.865203857421875, 0.8487484162586035
eval metrics, batch: 6144 acc, f1
0.871795654296875, 0.8572108357975595
eval metrics, batch: 7168 acc, f1
0.88311767578125, 0.8729347753964568
Epoch loss - train: tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5650, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.872344970703125, 0.8582466366193364
train metrics acc, f1 
0.9878654479980469, 0.9878447211851874
Epoch 15/20
----------
eval metrics, batch: 1024 acc, f1
0.865875244140625, 0.8495635803525586
eval metrics, batch: 2048 acc, f1
0.879608154296875, 0.8667004561581348
eval metrics, batch: 3072 acc, f1
0.87640380859375, 0.864376130198915
eval metrics, batch: 4096 acc, f1
0.847686767578125, 0.824192468914016
train metrics, batch: 4096  acc, f1 
0.9835395812988281, 0.9834187055446465
eval metrics, batch: 5120 acc, f1
0.889892578125, 0.8813079807882097
eval metrics, batch: 6144 acc, f1
0.843231201171875, 0.8170388574277879
eval metrics, batch: 7168 acc, f1
0.88201904296875, 0.8719188974291016
Epoch loss - train: tensor(0.0442, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3835, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8970947265625, 0.8921167135909905
train metrics acc, f1 
0.9821548461914062, 0.9823769627196287
Epoch 16/20
----------
eval metrics, batch: 1024 acc, f1
0.86651611328125, 0.8505535055350554
eval metrics, batch: 2048 acc, f1
0.858673095703125, 0.8400400677005976
eval metrics, batch: 3072 acc, f1
0.860931396484375, 0.8429541303373884
eval metrics, batch: 4096 acc, f1
0.79315185546875, 0.7427508729315319
train metrics, batch: 4096  acc, f1 
0.983001708984375, 0.9827523475541311
eval metrics, batch: 5120 acc, f1
0.85577392578125, 0.8344194520355966
eval metrics, batch: 6144 acc, f1
0.87347412109375, 0.8589508062869974
eval metrics, batch: 7168 acc, f1
0.8841552734375, 0.8730944102701257
Epoch loss - train: tensor(0.0413, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4709, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.875823974609375, 0.8649115235217955
train metrics acc, f1 
0.9871292114257812, 0.9872314981607908
Epoch 17/20
----------
eval metrics, batch: 1024 acc, f1
0.845550537109375, 0.8217769482691833
eval metrics, batch: 2048 acc, f1
0.845306396484375, 0.8203183155506717
eval metrics, batch: 3072 acc, f1
0.86572265625, 0.8495726495726496
eval metrics, batch: 4096 acc, f1
0.876251220703125, 0.8629187654237518
train metrics, batch: 4096  acc, f1 
0.9895172119140625, 0.9895324653558124
eval metrics, batch: 5120 acc, f1
0.875732421875, 0.8628586824733935
eval metrics, batch: 6144 acc, f1
0.881103515625, 0.8711725414985781
eval metrics, batch: 7168 acc, f1
0.86883544921875, 0.8532905516111414
Epoch loss - train: tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5316, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.863555908203125, 0.8470459443741234
train metrics acc, f1 
0.9899787902832031, 0.989984941194411
Epoch 18/20
----------
eval metrics, batch: 1024 acc, f1
0.85626220703125, 0.8359228035950672
eval metrics, batch: 2048 acc, f1
0.87445068359375, 0.8608254397834912
eval metrics, batch: 3072 acc, f1
0.881805419921875, 0.8698894749218934
eval metrics, batch: 4096 acc, f1
0.87176513671875, 0.856302578483004
train metrics, batch: 4096  acc, f1 
0.9919586181640625, 0.9919461446179003
eval metrics, batch: 5120 acc, f1
0.8646240234375, 0.8485386506419011
eval metrics, batch: 6144 acc, f1
0.82574462890625, 0.7926501561478684
eval metrics, batch: 7168 acc, f1
0.890106201171875, 0.8817910251780849
Epoch loss - train: tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5622, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.85736083984375, 0.8383817427385892
train metrics acc, f1 
0.9924545288085938, 0.992456370515011
Epoch 19/20
----------
eval metrics, batch: 1024 acc, f1
0.86785888671875, 0.8526408930029948
eval metrics, batch: 2048 acc, f1
0.8997802734375, 0.8935908236666451
eval metrics, batch: 3072 acc, f1
0.886077880859375, 0.8760418396148099
eval metrics, batch: 4096 acc, f1
0.855010986328125, 0.8361441627866874
train metrics, batch: 4096  acc, f1 
0.9912185668945312, 0.9912353510047744
eval metrics, batch: 5120 acc, f1
0.845947265625, 0.8214361513972409
eval metrics, batch: 6144 acc, f1
0.852691650390625, 0.831347611893365
eval metrics, batch: 7168 acc, f1
0.878753662109375, 0.8678441938595616
Epoch loss - train: tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5861, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.879058837890625, 0.865455780003395
train metrics acc, f1 
0.9919967651367188, 0.9919728807333833
Epoch 20/20
----------
eval metrics, batch: 1024 acc, f1
0.861602783203125, 0.8436368651518809
eval metrics, batch: 2048 acc, f1
0.870880126953125, 0.8559365317171167
eval metrics, batch: 3072 acc, f1
0.857666015625, 0.8396810119620515
eval metrics, batch: 4096 acc, f1
0.784576416015625, 0.7309319611206404
train metrics, batch: 4096  acc, f1 
0.9855308532714844, 0.985368262283446
eval metrics, batch: 5120 acc, f1
0.843292236328125, 0.8202219654798165
eval metrics, batch: 6144 acc, f1
0.87744140625, 0.864397622906537
eval metrics, batch: 7168 acc, f1
0.819000244140625, 0.7839422971840735
Epoch loss - train: tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3937, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.895782470703125, 0.890323409448566
train metrics acc, f1 
0.986602783203125, 0.9867216151839389
Training time 477m 17s
train_acc
0.5066299438476562	0.949249267578125	0.9592514038085938	0.9505577087402344	0.9677009582519531	0.9693412780761719	0.9612045288085938	0.9726524353027344	0.9722480773925781	0.973968505859375	0.9785804748535156	0.9635887145996094	0.9729461669921875	0.9811286926269531	0.9623146057128906	0.9734916687011719	0.9796981811523438	0.9728775024414062	0.9833145141601562	0.9855270385742188	0.9635696411132812	0.9801101684570312	0.9826126098632812	0.9836387634277344	0.9845771789550781	0.9739227294921875	0.9875907897949219	0.9877243041992188	0.9878654479980469	0.9835395812988281	0.9821548461914062	0.983001708984375	0.9871292114257812	0.9895172119140625	0.9899787902832031	0.9919586181640625	0.9924545288085938	0.9912185668945312	0.9919967651367188	0.9855308532714844	0.986602783203125
train_f1
0.599714023967515	0.9478524000282218	0.95878635420123	0.9485358057535389	0.9676517220959331	0.9691632998377016	0.960639368372165	0.9725307778667576	0.9720884728270253	0.974167758152071	0.9785228789669562	0.9625093775653287	0.9732822989579645	0.9810560659265755	0.9610552417145313	0.9738303889853391	0.9795955924639415	0.9723791246785334	0.9832217082096251	0.9854814021123527	0.9646157380304861	0.9802818179755395	0.9824290879933386	0.983610316062196	0.9845459931578847	0.9733615979923779	0.9876567569105845	0.9877473937510947	0.9878447211851874	0.9834187055446465	0.9823769627196287	0.9827523475541311	0.9872314981607908	0.9895324653558124	0.989984941194411	0.9919461446179003	0.992456370515011	0.9912353510047744	0.9919728807333833	0.985368262283446	0.9867216151839389
train_loss
tensor(0.1793, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1117, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0983, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0890, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0819, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0756, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0705, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0657, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0565, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0500, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0442, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0413, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0343, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.541595458984375	0.882171630859375	0.88153076171875	0.891693115234375	0.8701171875	0.881103515625	0.89593505859375	0.858184814453125	0.874908447265625	0.880462646484375	0.859619140625	0.869537353515625	0.84539794921875	0.87835693359375	0.90496826171875	0.897491455078125	0.892669677734375	0.855499267578125	0.8614501953125	0.855377197265625	0.871978759765625	0.82470703125	0.912567138671875	0.8865966796875	0.8802490234375	0.84576416015625	0.879364013671875	0.83038330078125	0.86932373046875	0.86346435546875	0.8331298828125	0.88916015625	0.8873291015625	0.85052490234375	0.897613525390625	0.860015869140625	0.878692626953125	0.85809326171875	0.789886474609375	0.876220703125	0.881866455078125	0.875823974609375	0.890411376953125	0.8699951171875	0.8297119140625	0.9090576171875	0.858642578125	0.87445068359375	0.90216064453125	0.878143310546875	0.86883544921875	0.85321044921875	0.882568359375	0.881622314453125	0.89031982421875	0.86834716796875	0.804046630859375	0.87066650390625	0.878509521484375	0.80450439453125	0.8905029296875	0.870361328125	0.863800048828125	0.839202880859375	0.8665771484375	0.8502197265625	0.8798828125	0.890472412109375	0.829254150390625	0.873992919921875	0.880615234375	0.896575927734375	0.887725830078125	0.862945556640625	0.846527099609375	0.86956787109375	0.88409423828125	0.90045166015625	0.837982177734375	0.88116455078125	0.900360107421875	0.873779296875	0.861297607421875	0.87408447265625	0.89300537109375	0.8756103515625	0.813568115234375	0.84405517578125	0.861419677734375	0.8707275390625	0.8592529296875	0.886505126953125	0.86163330078125	0.87738037109375	0.870452880859375	0.8673095703125	0.868408203125	0.885467529296875	0.845977783203125	0.839599609375	0.82513427734375	0.856781005859375	0.855865478515625	0.871795654296875	0.89898681640625	0.87347412109375	0.849456787109375	0.8492431640625	0.87872314453125	0.865203857421875	0.871795654296875	0.88311767578125	0.872344970703125	0.865875244140625	0.879608154296875	0.87640380859375	0.847686767578125	0.889892578125	0.843231201171875	0.88201904296875	0.8970947265625	0.86651611328125	0.858673095703125	0.860931396484375	0.79315185546875	0.85577392578125	0.87347412109375	0.8841552734375	0.875823974609375	0.845550537109375	0.845306396484375	0.86572265625	0.876251220703125	0.875732421875	0.881103515625	0.86883544921875	0.863555908203125	0.85626220703125	0.87445068359375	0.881805419921875	0.87176513671875	0.8646240234375	0.82574462890625	0.890106201171875	0.85736083984375	0.86785888671875	0.8997802734375	0.886077880859375	0.855010986328125	0.845947265625	0.852691650390625	0.878753662109375	0.879058837890625	0.861602783203125	0.870880126953125	0.857666015625	0.784576416015625	0.843292236328125	0.87744140625	0.819000244140625	0.895782470703125
valid_f1
0.6343031040779062	0.8741566441771781	0.8791256694482501	0.8878850102669404	0.8549816001090363	0.870219853431046	0.8886348791639451	0.8403476826880132	0.8620376291609169	0.8687640298857506	0.8414667769506479	0.8545473104011432	0.8193939393939393	0.8666086607322133	0.9000705988062384	0.8977691207353076	0.8850465762379474	0.8370556454110603	0.8443392991839813	0.8363322396822656	0.8581092508033147	0.7913851964843466	0.9102865194927195	0.8820467242254951	0.8682779456193354	0.8229648311615525	0.8706775280531291	0.8012444571592047	0.8552791672299581	0.8497750318984622	0.804700335738267	0.8827706410173649	0.8772687986171133	0.8288011184900385	0.8950545841283744	0.8397778476370115	0.8683905572294143	0.8390557939914163	0.739962986743211	0.8629914876368059	0.8703747111810601	0.8623710468459327	0.8833447032452977	0.854855195911414	0.7978993118435349	0.905993690851735	0.8390101487557348	0.8599537037037037	0.8973225723802204	0.8653424611337808	0.8552861952861953	0.830907684735991	0.8709244599490138	0.8694422940998283	0.88070897503983	0.8515893766340994	0.759016701069619	0.8570175438596491	0.8667626091904013	0.762582462382329	0.8845113943607571	0.8560780593576366	0.8462571910847773	0.8120965728754324	0.84974912365111	0.8271587547541908	0.867546103109436	0.8811077616192401	0.7982547867161864	0.860868686187957	0.8691901290710894	0.8911724093638611	0.8768782838593085	0.8464142813173284	0.8220893621537482	0.8534796023311622	0.8730445246690735	0.895045045045045	0.8120109061293863	0.8682055100521221	0.8992190634935333	0.8597205263871931	0.843486345948552	0.8596312172552222	0.8858501009311714	0.863496316141996	0.7745340468721166	0.8186142268919494	0.8421125830117172	0.8553476301051769	0.8404373097149184	0.8781095342663302	0.8444063143445436	0.8649684097324909	0.8559796437659033	0.8509325287986835	0.8529331514324693	0.8753942693980544	0.8230798892277491	0.8127671701339413	0.7908148364485982	0.8400313597163991	0.8359214868855307	0.8561153543172244	0.8922526041666666	0.860262891809909	0.8273061438823736	0.826970227670753	0.8667069162138593	0.8487484162586035	0.8572108357975595	0.8729347753964568	0.8582466366193364	0.8495635803525586	0.8667004561581348	0.864376130198915	0.824192468914016	0.8813079807882097	0.8170388574277879	0.8719188974291016	0.8921167135909905	0.8505535055350554	0.8400400677005976	0.8429541303373884	0.7427508729315319	0.8344194520355966	0.8589508062869974	0.8730944102701257	0.8649115235217955	0.8217769482691833	0.8203183155506717	0.8495726495726496	0.8629187654237518	0.8628586824733935	0.8711725414985781	0.8532905516111414	0.8470459443741234	0.8359228035950672	0.8608254397834912	0.8698894749218934	0.856302578483004	0.8485386506419011	0.7926501561478684	0.8817910251780849	0.8383817427385892	0.8526408930029948	0.8935908236666451	0.8760418396148099	0.8361441627866874	0.8214361513972409	0.831347611893365	0.8678441938595616	0.865455780003395	0.8436368651518809	0.8559365317171167	0.8396810119620515	0.7309319611206404	0.8202219654798165	0.864397622906537	0.7839422971840735	0.890323409448566
valid_loss
tensor(0.3533, device='cuda:0')	tensor(0.2997, device='cuda:0')	tensor(0.3493, device='cuda:0')	tensor(0.3071, device='cuda:0')	tensor(0.3429, device='cuda:0')	tensor(0.2676, device='cuda:0')	tensor(0.6541, device='cuda:0')	tensor(0.4137, device='cuda:0')	tensor(0.4380, device='cuda:0')	tensor(0.3081, device='cuda:0')	tensor(0.5074, device='cuda:0')	tensor(0.6216, device='cuda:0')	tensor(0.3624, device='cuda:0')	tensor(0.5650, device='cuda:0')	tensor(0.3835, device='cuda:0')	tensor(0.4709, device='cuda:0')	tensor(0.5316, device='cuda:0')	tensor(0.5622, device='cuda:0')	tensor(0.5861, device='cuda:0')	tensor(0.3937, device='cuda:0')
Best model metrics: train, valid, test: acc, f1
0.9638099670410156, 0.9648474698107684
0.900360107421875, 0.8992190634935333
0.8765869140625, 0.8701265334960498
Model saved, path ./models/horizontalflip-1560101954.pth
experiment validation
train set
Evaluation results
[[122428.   8644.]
 [   889. 130183.]]
#############################
Accuracy
0.9636344909667969
------------------------
Recall
0.9932174682617188
------------------------
Specificity
0.934051513671875
------------------------
Precision
0.9377354549187118
------------------------
Fall_out
0.065948486328125
------------------------
F1
0.9646793800643945
------------------------
#############################
valid set
Evaluation results
[[14937.  1462.]
 [ 1803. 14566.]]
#############################
Accuracy
0.900360107421875
------------------------
Recall
0.8898527704807868
------------------------
Specificity
0.9108482224525886
------------------------
Precision
0.90878462690292
------------------------
Fall_out
0.08915177754741142
------------------------
F1
0.8992190634935333
------------------------
#############################
test set
Evaluation results
[[15177.  1214.]
 [ 2830. 13547.]]
#############################
Accuracy
0.8765869140625
------------------------
Recall
0.8271966782683031
------------------------
Specificity
0.9259349643096821
------------------------
Precision
0.917756249576587
------------------------
Fall_out
0.07406503569031786
------------------------
F1
0.8701265334960498
------------------------
#############################
AUC: 0.9419182786866862
Experiment end
########################################
