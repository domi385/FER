----------------------------------------
Starting experiment resnet_11-1559491145
Experiment parameters Experiment[name: resnet_11-1559491145, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 0.001, weight_decay: 0, batch_size: 32, num_epochs: 20), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.499542236328125, 0.6662596414107496
train metrics acc, f1
0.5000267028808594, 0.6666785348249913
Epoch 1/20
----------
eval metrics, batch: 1024 acc, f1
0.808837890625, 0.8121513824746597
eval metrics, batch: 2048 acc, f1
0.776031494140625, 0.7841914899873556
eval metrics, batch: 3072 acc, f1
0.773956298828125, 0.7816783093111681
eval metrics, batch: 4096 acc, f1
0.806243896484375, 0.8077982623437169
train metrics, batch: 4096  acc, f1 
0.82379150390625, 0.8312645659972092
eval metrics, batch: 5120 acc, f1
0.7808837890625, 0.7582654366709313
eval metrics, batch: 6144 acc, f1
0.80938720703125, 0.8030895334174023
eval metrics, batch: 7168 acc, f1
0.735748291015625, 0.6681994098938575
Epoch loss - train: tensor(0.4350, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4092, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8184814453125, 0.8072585871678548
train metrics acc, f1 
0.8569908142089844, 0.8554507212233614
Epoch 2/20
----------
eval metrics, batch: 1024 acc, f1
0.767669677734375, 0.743971750462418
eval metrics, batch: 2048 acc, f1
0.711212158203125, 0.6266324718879464
eval metrics, batch: 3072 acc, f1
0.82684326171875, 0.8192533129459735
eval metrics, batch: 4096 acc, f1
0.787994384765625, 0.7594612374917766
train metrics, batch: 4096  acc, f1 
0.8547134399414062, 0.8471583475797195
eval metrics, batch: 5120 acc, f1
0.81219482421875, 0.8214679431389614
eval metrics, batch: 6144 acc, f1
0.77862548828125, 0.7417034610454352
eval metrics, batch: 7168 acc, f1
0.823944091796875, 0.8205096294452568
Epoch loss - train: tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3929, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8226318359375, 0.8288272368498557
train metrics acc, f1 
0.8572349548339844, 0.8678295080114565
Epoch 3/20
----------
eval metrics, batch: 1024 acc, f1
0.72802734375, 0.6475520050620897
eval metrics, batch: 2048 acc, f1
0.806884765625, 0.7913892002373574
eval metrics, batch: 3072 acc, f1
0.822967529296875, 0.8195364753460881
eval metrics, batch: 4096 acc, f1
0.7939453125, 0.7663991143094382
train metrics, batch: 4096  acc, f1 
0.8802108764648438, 0.8765032995902058
eval metrics, batch: 5120 acc, f1
0.82562255859375, 0.8170583338669398
eval metrics, batch: 6144 acc, f1
0.8204345703125, 0.8064218976181077
eval metrics, batch: 7168 acc, f1
0.83160400390625, 0.8315217391304348
Epoch loss - train: tensor(0.3114, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4465, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8026123046875, 0.7751981092729042
train metrics acc, f1 
0.8894119262695312, 0.8850861754586247
Epoch 4/20
----------
eval metrics, batch: 1024 acc, f1
0.821014404296875, 0.8123139940478096
eval metrics, batch: 2048 acc, f1
0.813934326171875, 0.814697747925721
eval metrics, batch: 3072 acc, f1
0.82958984375, 0.8175521139645822
eval metrics, batch: 4096 acc, f1
0.809722900390625, 0.7894647982441331
train metrics, batch: 4096  acc, f1 
0.8977432250976562, 0.8960967479359665
eval metrics, batch: 5120 acc, f1
0.79327392578125, 0.759103840682788
eval metrics, batch: 6144 acc, f1
0.769073486328125, 0.7208058148544442
eval metrics, batch: 7168 acc, f1
0.807586669921875, 0.7794760588996538
Epoch loss - train: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5954, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.743896484375, 0.6665077094261643
train metrics acc, f1 
0.8491401672363281, 0.8270708254441621
Epoch 5/20
----------
eval metrics, batch: 1024 acc, f1
0.836944580078125, 0.8275951082572359
eval metrics, batch: 2048 acc, f1
0.819000244140625, 0.7973762426975505
eval metrics, batch: 3072 acc, f1
0.851654052734375, 0.8516766850761297
eval metrics, batch: 4096 acc, f1
0.847015380859375, 0.8391980753809142
train metrics, batch: 4096  acc, f1 
0.9128761291503906, 0.9139997514770173
eval metrics, batch: 5120 acc, f1
0.81439208984375, 0.7868059450364554
eval metrics, batch: 6144 acc, f1
0.79241943359375, 0.7540675392291561
eval metrics, batch: 7168 acc, f1
0.8187255859375, 0.8060344827586207
Epoch loss - train: tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5357, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.75531005859375, 0.6910688140556369
train metrics acc, f1 
0.9033927917480469, 0.8965900228257363
Epoch 6/20
----------
eval metrics, batch: 1024 acc, f1
0.836578369140625, 0.8222052524984229
eval metrics, batch: 2048 acc, f1
0.83221435546875, 0.8208069878104426
eval metrics, batch: 3072 acc, f1
0.85546875, 0.851340322681901
eval metrics, batch: 4096 acc, f1
0.844757080078125, 0.8410362176181995
train metrics, batch: 4096  acc, f1 
0.9070205688476562, 0.9106302157429271
eval metrics, batch: 5120 acc, f1
0.844757080078125, 0.8370647961308094
eval metrics, batch: 6144 acc, f1
0.824676513671875, 0.8055245252361125
eval metrics, batch: 7168 acc, f1
0.764404296875, 0.7046897712493306
Epoch loss - train: tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4379, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.821197509765625, 0.8011269135467228
train metrics acc, f1 
0.9275054931640625, 0.9271849496149278
Epoch 7/20
----------
eval metrics, batch: 1024 acc, f1
0.80218505859375, 0.7694879089615931
eval metrics, batch: 2048 acc, f1
0.825958251953125, 0.8089127156977718
eval metrics, batch: 3072 acc, f1
0.84893798828125, 0.8415492957746479
eval metrics, batch: 4096 acc, f1
0.72918701171875, 0.6432419393744472
train metrics, batch: 4096  acc, f1 
0.9004364013671875, 0.8921523255429572
eval metrics, batch: 5120 acc, f1
0.790985107421875, 0.7472227348219229
eval metrics, batch: 6144 acc, f1
0.822601318359375, 0.799143084205798
eval metrics, batch: 7168 acc, f1
0.815643310546875, 0.7899147974265345
Epoch loss - train: tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3962, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.824066162109375, 0.8028183466155898
train metrics acc, f1 
0.9365653991699219, 0.936203026989699
Epoch 8/20
----------
eval metrics, batch: 1024 acc, f1
0.82769775390625, 0.8079983676800653
eval metrics, batch: 2048 acc, f1
0.80859375, 0.7780608634111819
eval metrics, batch: 3072 acc, f1
0.83905029296875, 0.8244925124792013
eval metrics, batch: 4096 acc, f1
0.83209228515625, 0.8152327221438646
train metrics, batch: 4096  acc, f1 
0.93878173828125, 0.9391244973825962
eval metrics, batch: 5120 acc, f1
0.81402587890625, 0.7854074230579619
eval metrics, batch: 6144 acc, f1
0.804931640625, 0.7741183122482154
eval metrics, batch: 7168 acc, f1
0.769561767578125, 0.7151103565365026
Epoch loss - train: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3341, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.854766845703125, 0.846952886316128
train metrics acc, f1 
0.9362106323242188, 0.9373703173806546
Epoch 9/20
----------
eval metrics, batch: 1024 acc, f1
0.832855224609375, 0.8179975409563686
eval metrics, batch: 2048 acc, f1
0.808349609375, 0.7780918727915195
eval metrics, batch: 3072 acc, f1
0.76422119140625, 0.6994943601711396
eval metrics, batch: 4096 acc, f1
0.7469482421875, 0.6740566037735849
train metrics, batch: 4096  acc, f1 
0.9204826354980469, 0.915487875581287
eval metrics, batch: 5120 acc, f1
0.826873779296875, 0.8026439380761872
eval metrics, batch: 6144 acc, f1
0.831146240234375, 0.813709976095081
eval metrics, batch: 7168 acc, f1
0.8240966796875, 0.8004569687738005
Epoch loss - train: tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3693, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.85174560546875, 0.8414904724614983
train metrics acc, f1 
0.9456939697265625, 0.9463549556475013
Epoch 10/20
----------
eval metrics, batch: 1024 acc, f1
0.824005126953125, 0.7992480941274759
eval metrics, batch: 2048 acc, f1
0.833984375, 0.8168103448275862
eval metrics, batch: 3072 acc, f1
0.85107421875, 0.8402514076207935
eval metrics, batch: 4096 acc, f1
0.808807373046875, 0.7748913082533865
train metrics, batch: 4096  acc, f1 
0.9468040466308594, 0.9454499935455353
eval metrics, batch: 5120 acc, f1
0.84686279296875, 0.8350861049033784
eval metrics, batch: 6144 acc, f1
0.7957763671875, 0.7574659321542476
eval metrics, batch: 7168 acc, f1
0.80419921875, 0.7725790443782787
Epoch loss - train: tensor(0.1617, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3827, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8587646484375, 0.8517236960143535
train metrics acc, f1 
0.9423828125, 0.9433054314777973
Epoch 11/20
----------
eval metrics, batch: 1024 acc, f1
0.827362060546875, 0.8039915456844877
eval metrics, batch: 2048 acc, f1
0.769195556640625, 0.7131424236677413
eval metrics, batch: 3072 acc, f1
0.834808349609375, 0.8216768242464174
eval metrics, batch: 4096 acc, f1
0.848480224609375, 0.83578634033405
train metrics, batch: 4096  acc, f1 
0.9516792297363281, 0.9518988687671118
eval metrics, batch: 5120 acc, f1
0.823516845703125, 0.8008128681155926
eval metrics, batch: 6144 acc, f1
0.79852294921875, 0.7622956722114208
eval metrics, batch: 7168 acc, f1
0.796142578125, 0.7551319648093842
Epoch loss - train: tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4815, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.825775146484375, 0.799761495563116
train metrics acc, f1 
0.9561996459960938, 0.9554422402284933
Epoch 12/20
----------
eval metrics, batch: 1024 acc, f1
0.833221435546875, 0.814298820890958
eval metrics, batch: 2048 acc, f1
0.814483642578125, 0.7867840482620743
eval metrics, batch: 3072 acc, f1
0.837005615234375, 0.8194204956554079
eval metrics, batch: 4096 acc, f1
0.796783447265625, 0.7576694930674334
train metrics, batch: 4096  acc, f1 
0.9452400207519531, 0.9434653328869897
eval metrics, batch: 5120 acc, f1
0.858489990234375, 0.8502115838098007
eval metrics, batch: 6144 acc, f1
0.830078125, 0.8109466250169768
eval metrics, batch: 7168 acc, f1
0.850494384765625, 0.8429858017371238
Epoch loss - train: tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4654, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.82135009765625, 0.7937861068056925
train metrics acc, f1 
0.9529800415039062, 0.9521353847109717
Epoch 13/20
----------
eval metrics, batch: 1024 acc, f1
0.84674072265625, 0.8323653114360104
eval metrics, batch: 2048 acc, f1
0.851318359375, 0.8413752686071498
eval metrics, batch: 3072 acc, f1
0.787017822265625, 0.7401809314619708
eval metrics, batch: 4096 acc, f1
0.840362548828125, 0.8272171758876962
train metrics, batch: 4096  acc, f1 
0.957489013671875, 0.9580661669526476
eval metrics, batch: 5120 acc, f1
0.7357177734375, 0.6491654513044888
eval metrics, batch: 6144 acc, f1
0.8408203125, 0.8259244426645308
eval metrics, batch: 7168 acc, f1
0.808746337890625, 0.7749649897662394
Epoch loss - train: tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5408, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.811126708984375, 0.7801655241004511
train metrics acc, f1 
0.9615592956542969, 0.9610672601040834
Epoch 14/20
----------
eval metrics, batch: 1024 acc, f1
0.845123291015625, 0.8273985647723021
eval metrics, batch: 2048 acc, f1
0.841094970703125, 0.8261145433294373
eval metrics, batch: 3072 acc, f1
0.826904296875, 0.8008426966292135
eval metrics, batch: 4096 acc, f1
0.847320556640625, 0.830665087155187
train metrics, batch: 4096  acc, f1 
0.966949462890625, 0.9667954378219279
eval metrics, batch: 5120 acc, f1
0.817291259765625, 0.7887363703729843
eval metrics, batch: 6144 acc, f1
0.85565185546875, 0.8525744919586087
eval metrics, batch: 7168 acc, f1
0.813323974609375, 0.788023703087639
Epoch loss - train: tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5056, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.828582763671875, 0.8054718614718614
train metrics acc, f1 
0.9666709899902344, 0.9665936368467941
Epoch 15/20
----------
eval metrics, batch: 1024 acc, f1
0.8458251953125, 0.8339141297915708
eval metrics, batch: 2048 acc, f1
0.8060302734375, 0.77207200745894
eval metrics, batch: 3072 acc, f1
0.82318115234375, 0.7983152325257589
eval metrics, batch: 4096 acc, f1
0.82623291015625, 0.8016995193982029
train metrics, batch: 4096  acc, f1 
0.968414306640625, 0.9682442279665567
eval metrics, batch: 5120 acc, f1
0.84619140625, 0.8329577091342967
eval metrics, batch: 6144 acc, f1
0.82550048828125, 0.8002515195975687
eval metrics, batch: 7168 acc, f1
0.8192138671875, 0.7914671923401858
Epoch loss - train: tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5549, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.80108642578125, 0.7688652482269503
train metrics acc, f1 
0.9679336547851562, 0.9678812147518684
Epoch 16/20
----------
eval metrics, batch: 1024 acc, f1
0.83258056640625, 0.8120074018230417
eval metrics, batch: 2048 acc, f1
0.83355712890625, 0.8133214676889375
eval metrics, batch: 3072 acc, f1
0.850372314453125, 0.8389554935128921
eval metrics, batch: 4096 acc, f1
0.795074462890625, 0.7576424730212582
train metrics, batch: 4096  acc, f1 
0.9648513793945312, 0.9644581938251223
eval metrics, batch: 5120 acc, f1
0.823455810546875, 0.800138193124892
eval metrics, batch: 6144 acc, f1
0.809539794921875, 0.7758180969144006
eval metrics, batch: 7168 acc, f1
0.83941650390625, 0.8261300555114988
Epoch loss - train: tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6309, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.80462646484375, 0.770191686409649
train metrics acc, f1 
0.976165771484375, 0.9759566542499153
Epoch 17/20
----------
eval metrics, batch: 1024 acc, f1
0.849212646484375, 0.8349644276695949
eval metrics, batch: 2048 acc, f1
0.831939697265625, 0.8096637058030622
eval metrics, batch: 3072 acc, f1
0.827972412109375, 0.8046032791431246
eval metrics, batch: 4096 acc, f1
0.8511962890625, 0.837520826391203
train metrics, batch: 4096  acc, f1 
0.9752769470214844, 0.9753876417935388
eval metrics, batch: 5120 acc, f1
0.7940673828125, 0.7503145119514542
eval metrics, batch: 6144 acc, f1
0.824310302734375, 0.8007889546351085
eval metrics, batch: 7168 acc, f1
0.82574462890625, 0.8036181042784427
Epoch loss - train: tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5778, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8179931640625, 0.791599692501223
train metrics acc, f1 
0.9786796569824219, 0.9786427504193878
Epoch 18/20
----------
eval metrics, batch: 1024 acc, f1
0.8270263671875, 0.8021226085742215
eval metrics, batch: 2048 acc, f1
0.796966552734375, 0.7558263295041656
eval metrics, batch: 3072 acc, f1
0.8089599609375, 0.7755467909645034
eval metrics, batch: 4096 acc, f1
0.857635498046875, 0.8475041678925174
train metrics, batch: 4096  acc, f1 
0.9754371643066406, 0.9756896857668188
eval metrics, batch: 5120 acc, f1
0.8463134765625, 0.8343203053033293
eval metrics, batch: 6144 acc, f1
0.824615478515625, 0.801478462123044
eval metrics, batch: 7168 acc, f1
0.81414794921875, 0.7826397316011136
Epoch loss - train: tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6638, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.801055908203125, 0.7671203515164505
train metrics acc, f1 
0.9797821044921875, 0.9797007974139582
Epoch 19/20
----------
eval metrics, batch: 1024 acc, f1
0.813385009765625, 0.7861813350117137
eval metrics, batch: 2048 acc, f1
0.79620361328125, 0.7549357798165137
eval metrics, batch: 3072 acc, f1
0.812408447265625, 0.7804878048780488
eval metrics, batch: 4096 acc, f1
0.807281494140625, 0.7712702379658807
train metrics, batch: 4096  acc, f1 
0.9753074645996094, 0.9749066704915935
eval metrics, batch: 5120 acc, f1
0.817169189453125, 0.790853552103334
eval metrics, batch: 6144 acc, f1
0.853973388671875, 0.8428313351946133
eval metrics, batch: 7168 acc, f1
0.813751220703125, 0.7838804490243989
Epoch loss - train: tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8958, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.790191650390625, 0.7451154858562266
train metrics acc, f1 
0.9754486083984375, 0.9749525203150783
Epoch 20/20
----------
eval metrics, batch: 1024 acc, f1
0.829132080078125, 0.8080364795830904
eval metrics, batch: 2048 acc, f1
0.830535888671875, 0.809691901710134
eval metrics, batch: 3072 acc, f1
0.838043212890625, 0.8195204897126339
eval metrics, batch: 4096 acc, f1
0.83984375, 0.824387632177754
train metrics, batch: 4096  acc, f1 
0.9798011779785156, 0.9799374822392726
eval metrics, batch: 5120 acc, f1
0.83367919921875, 0.8238070606491659
eval metrics, batch: 6144 acc, f1
0.84130859375, 0.8250807319698601
eval metrics, batch: 7168 acc, f1
0.789276123046875, 0.7449676823638043
Epoch loss - train: tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6352, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.828033447265625, 0.8051454061343754
train metrics acc, f1 
0.98193359375, 0.9818195777351247
Training time 284m 53s
train_acc
0.5000267028808594	0.82379150390625	0.8569908142089844	0.8547134399414062	0.8572349548339844	0.8802108764648438	0.8894119262695312	0.8977432250976562	0.8491401672363281	0.9128761291503906	0.9033927917480469	0.9070205688476562	0.9275054931640625	0.9004364013671875	0.9365653991699219	0.93878173828125	0.9362106323242188	0.9204826354980469	0.9456939697265625	0.9468040466308594	0.9423828125	0.9516792297363281	0.9561996459960938	0.9452400207519531	0.9529800415039062	0.957489013671875	0.9615592956542969	0.966949462890625	0.9666709899902344	0.968414306640625	0.9679336547851562	0.9648513793945312	0.976165771484375	0.9752769470214844	0.9786796569824219	0.9754371643066406	0.9797821044921875	0.9753074645996094	0.9754486083984375	0.9798011779785156	0.98193359375
train_f1
0.6666785348249913	0.8312645659972092	0.8554507212233614	0.8471583475797195	0.8678295080114565	0.8765032995902058	0.8850861754586247	0.8960967479359665	0.8270708254441621	0.9139997514770173	0.8965900228257363	0.9106302157429271	0.9271849496149278	0.8921523255429572	0.936203026989699	0.9391244973825962	0.9373703173806546	0.915487875581287	0.9463549556475013	0.9454499935455353	0.9433054314777973	0.9518988687671118	0.9554422402284933	0.9434653328869897	0.9521353847109717	0.9580661669526476	0.9610672601040834	0.9667954378219279	0.9665936368467941	0.9682442279665567	0.9678812147518684	0.9644581938251223	0.9759566542499153	0.9753876417935388	0.9786427504193878	0.9756896857668188	0.9797007974139582	0.9749066704915935	0.9749525203150783	0.9799374822392726	0.9818195777351247
train_loss
tensor(0.4350, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3114, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1752, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1617, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1492, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1195, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1005, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0911, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0843, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0760, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0680, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.499542236328125	0.808837890625	0.776031494140625	0.773956298828125	0.806243896484375	0.7808837890625	0.80938720703125	0.735748291015625	0.8184814453125	0.767669677734375	0.711212158203125	0.82684326171875	0.787994384765625	0.81219482421875	0.77862548828125	0.823944091796875	0.8226318359375	0.72802734375	0.806884765625	0.822967529296875	0.7939453125	0.82562255859375	0.8204345703125	0.83160400390625	0.8026123046875	0.821014404296875	0.813934326171875	0.82958984375	0.809722900390625	0.79327392578125	0.769073486328125	0.807586669921875	0.743896484375	0.836944580078125	0.819000244140625	0.851654052734375	0.847015380859375	0.81439208984375	0.79241943359375	0.8187255859375	0.75531005859375	0.836578369140625	0.83221435546875	0.85546875	0.844757080078125	0.844757080078125	0.824676513671875	0.764404296875	0.821197509765625	0.80218505859375	0.825958251953125	0.84893798828125	0.72918701171875	0.790985107421875	0.822601318359375	0.815643310546875	0.824066162109375	0.82769775390625	0.80859375	0.83905029296875	0.83209228515625	0.81402587890625	0.804931640625	0.769561767578125	0.854766845703125	0.832855224609375	0.808349609375	0.76422119140625	0.7469482421875	0.826873779296875	0.831146240234375	0.8240966796875	0.85174560546875	0.824005126953125	0.833984375	0.85107421875	0.808807373046875	0.84686279296875	0.7957763671875	0.80419921875	0.8587646484375	0.827362060546875	0.769195556640625	0.834808349609375	0.848480224609375	0.823516845703125	0.79852294921875	0.796142578125	0.825775146484375	0.833221435546875	0.814483642578125	0.837005615234375	0.796783447265625	0.858489990234375	0.830078125	0.850494384765625	0.82135009765625	0.84674072265625	0.851318359375	0.787017822265625	0.840362548828125	0.7357177734375	0.8408203125	0.808746337890625	0.811126708984375	0.845123291015625	0.841094970703125	0.826904296875	0.847320556640625	0.817291259765625	0.85565185546875	0.813323974609375	0.828582763671875	0.8458251953125	0.8060302734375	0.82318115234375	0.82623291015625	0.84619140625	0.82550048828125	0.8192138671875	0.80108642578125	0.83258056640625	0.83355712890625	0.850372314453125	0.795074462890625	0.823455810546875	0.809539794921875	0.83941650390625	0.80462646484375	0.849212646484375	0.831939697265625	0.827972412109375	0.8511962890625	0.7940673828125	0.824310302734375	0.82574462890625	0.8179931640625	0.8270263671875	0.796966552734375	0.8089599609375	0.857635498046875	0.8463134765625	0.824615478515625	0.81414794921875	0.801055908203125	0.813385009765625	0.79620361328125	0.812408447265625	0.807281494140625	0.817169189453125	0.853973388671875	0.813751220703125	0.790191650390625	0.829132080078125	0.830535888671875	0.838043212890625	0.83984375	0.83367919921875	0.84130859375	0.789276123046875	0.828033447265625
valid_f1
0.6662596414107496	0.8121513824746597	0.7841914899873556	0.7816783093111681	0.8077982623437169	0.7582654366709313	0.8030895334174023	0.6681994098938575	0.8072585871678548	0.743971750462418	0.6266324718879464	0.8192533129459735	0.7594612374917766	0.8214679431389614	0.7417034610454352	0.8205096294452568	0.8288272368498557	0.6475520050620897	0.7913892002373574	0.8195364753460881	0.7663991143094382	0.8170583338669398	0.8064218976181077	0.8315217391304348	0.7751981092729042	0.8123139940478096	0.814697747925721	0.8175521139645822	0.7894647982441331	0.759103840682788	0.7208058148544442	0.7794760588996538	0.6665077094261643	0.8275951082572359	0.7973762426975505	0.8516766850761297	0.8391980753809142	0.7868059450364554	0.7540675392291561	0.8060344827586207	0.6910688140556369	0.8222052524984229	0.8208069878104426	0.851340322681901	0.8410362176181995	0.8370647961308094	0.8055245252361125	0.7046897712493306	0.8011269135467228	0.7694879089615931	0.8089127156977718	0.8415492957746479	0.6432419393744472	0.7472227348219229	0.799143084205798	0.7899147974265345	0.8028183466155898	0.8079983676800653	0.7780608634111819	0.8244925124792013	0.8152327221438646	0.7854074230579619	0.7741183122482154	0.7151103565365026	0.846952886316128	0.8179975409563686	0.7780918727915195	0.6994943601711396	0.6740566037735849	0.8026439380761872	0.813709976095081	0.8004569687738005	0.8414904724614983	0.7992480941274759	0.8168103448275862	0.8402514076207935	0.7748913082533865	0.8350861049033784	0.7574659321542476	0.7725790443782787	0.8517236960143535	0.8039915456844877	0.7131424236677413	0.8216768242464174	0.83578634033405	0.8008128681155926	0.7622956722114208	0.7551319648093842	0.799761495563116	0.814298820890958	0.7867840482620743	0.8194204956554079	0.7576694930674334	0.8502115838098007	0.8109466250169768	0.8429858017371238	0.7937861068056925	0.8323653114360104	0.8413752686071498	0.7401809314619708	0.8272171758876962	0.6491654513044888	0.8259244426645308	0.7749649897662394	0.7801655241004511	0.8273985647723021	0.8261145433294373	0.8008426966292135	0.830665087155187	0.7887363703729843	0.8525744919586087	0.788023703087639	0.8054718614718614	0.8339141297915708	0.77207200745894	0.7983152325257589	0.8016995193982029	0.8329577091342967	0.8002515195975687	0.7914671923401858	0.7688652482269503	0.8120074018230417	0.8133214676889375	0.8389554935128921	0.7576424730212582	0.800138193124892	0.7758180969144006	0.8261300555114988	0.770191686409649	0.8349644276695949	0.8096637058030622	0.8046032791431246	0.837520826391203	0.7503145119514542	0.8007889546351085	0.8036181042784427	0.791599692501223	0.8021226085742215	0.7558263295041656	0.7755467909645034	0.8475041678925174	0.8343203053033293	0.801478462123044	0.7826397316011136	0.7671203515164505	0.7861813350117137	0.7549357798165137	0.7804878048780488	0.7712702379658807	0.790853552103334	0.8428313351946133	0.7838804490243989	0.7451154858562266	0.8080364795830904	0.809691901710134	0.8195204897126339	0.824387632177754	0.8238070606491659	0.8250807319698601	0.7449676823638043	0.8051454061343754
valid_loss
tensor(0.4092, device='cuda:0')	tensor(0.3929, device='cuda:0')	tensor(0.4465, device='cuda:0')	tensor(0.5954, device='cuda:0')	tensor(0.5357, device='cuda:0')	tensor(0.4379, device='cuda:0')	tensor(0.3962, device='cuda:0')	tensor(0.3341, device='cuda:0')	tensor(0.3693, device='cuda:0')	tensor(0.3827, device='cuda:0')	tensor(0.4815, device='cuda:0')	tensor(0.4654, device='cuda:0')	tensor(0.5408, device='cuda:0')	tensor(0.5056, device='cuda:0')	tensor(0.5549, device='cuda:0')	tensor(0.6309, device='cuda:0')	tensor(0.5778, device='cuda:0')	tensor(0.6638, device='cuda:0')	tensor(0.8958, device='cuda:0')	tensor(0.6352, device='cuda:0')
Best model metrics: train, valid, test: acc, f1
0.9423828125, 0.9433054314777973
0.8587646484375, 0.8517236960143535
0.81231689453125, 0.789801080046483
Model saved, path ./models/resnet_11-1559491145.pth
experiment validation
train set
Evaluation results
[[121387.   9685.]
 [  5419. 125653.]]
#############################
Accuracy
0.9423828125
------------------------
Recall
0.9586563110351562
------------------------
Specificity
0.9261093139648438
------------------------
Precision
0.9284384282315388
------------------------
Fall_out
0.07389068603515625
------------------------
F1
0.9433054314777973
------------------------
#############################
valid set
Evaluation results
[[14848.  1551.]
 [ 3077. 13292.]]
#############################
Accuracy
0.8587646484375
------------------------
Recall
0.8120227258842935
------------------------
Specificity
0.9054210622598939
------------------------
Precision
0.8955062992656471
------------------------
Fall_out
0.0945789377401061
------------------------
F1
0.8517236960143535
------------------------
#############################
test set
Evaluation results
[[15064.  1327.]
 [ 4823. 11554.]]
#############################
Accuracy
0.81231689453125
------------------------
Recall
0.7055016181229773
------------------------
Specificity
0.9190409370996279
------------------------
Precision
0.8969800481329089
------------------------
Fall_out
0.08095906290037215
------------------------
F1
0.789801080046483
------------------------
#############################
AUC: 0.9042447444349246
Experiment end
########################################
----------------------------------------
Starting experiment resnet_12-1559491145
Experiment parameters Experiment[name: resnet_12-1559491145, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 0.0001, weight_decay: 0, batch_size: 32, num_epochs: 20), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.500457763671875, 0.0
train metrics acc, f1
0.5, 0.0
Epoch 1/20
----------
eval metrics, batch: 1024 acc, f1
0.75494384765625, 0.7055804062477085
eval metrics, batch: 2048 acc, f1
0.804656982421875, 0.8217041308041558
eval metrics, batch: 3072 acc, f1
0.8089599609375, 0.820228591120556
eval metrics, batch: 4096 acc, f1
0.807952880859375, 0.8014137397835212
train metrics, batch: 4096  acc, f1 
0.8556747436523438, 0.8582401606666467
eval metrics, batch: 5120 acc, f1
0.7867431640625, 0.7657862984314251
eval metrics, batch: 6144 acc, f1
0.804656982421875, 0.794305729618561
eval metrics, batch: 7168 acc, f1
0.754547119140625, 0.7053306466385785
Epoch loss - train: tensor(0.3670, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4194, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8189697265625, 0.8107090433339715
train metrics acc, f1 
0.8839874267578125, 0.8861996707079779
Epoch 2/20
----------
eval metrics, batch: 1024 acc, f1
0.7811279296875, 0.7664452259997395
eval metrics, batch: 2048 acc, f1
0.81915283203125, 0.8078594124894625
eval metrics, batch: 3072 acc, f1
0.82501220703125, 0.8132247557003257
eval metrics, batch: 4096 acc, f1
0.772491455078125, 0.7295483402865953
train metrics, batch: 4096  acc, f1 
0.8867301940917969, 0.880231043203627
eval metrics, batch: 5120 acc, f1
0.82135009765625, 0.8168220789786594
eval metrics, batch: 6144 acc, f1
0.771820068359375, 0.7265679283232767
eval metrics, batch: 7168 acc, f1
0.8134765625, 0.8044410315479619
Epoch loss - train: tensor(0.2863, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3853, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.827117919921875, 0.8322227158300015
train metrics acc, f1 
0.88201904296875, 0.8907330860272037
Epoch 3/20
----------
eval metrics, batch: 1024 acc, f1
0.785797119140625, 0.7535030728709394
eval metrics, batch: 2048 acc, f1
0.78741455078125, 0.747773191396915
eval metrics, batch: 3072 acc, f1
0.7666015625, 0.7207128250073035
eval metrics, batch: 4096 acc, f1
0.795196533203125, 0.7694527465732248
train metrics, batch: 4096  acc, f1 
0.9135513305664062, 0.9130838325649896
eval metrics, batch: 5120 acc, f1
0.7911376953125, 0.757700205338809
eval metrics, batch: 6144 acc, f1
0.795318603515625, 0.7625420428394406
eval metrics, batch: 7168 acc, f1
0.83807373046875, 0.834011136832885
Epoch loss - train: tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4532, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.807281494140625, 0.7798500958689211
train metrics acc, f1 
0.9271888732910156, 0.9259582523556269
Epoch 4/20
----------
eval metrics, batch: 1024 acc, f1
0.81298828125, 0.7958694203864091
eval metrics, batch: 2048 acc, f1
0.817169189453125, 0.8124236826450422
eval metrics, batch: 3072 acc, f1
0.823486328125, 0.8046077967704884
eval metrics, batch: 4096 acc, f1
0.75347900390625, 0.6884929816443005
train metrics, batch: 4096  acc, f1 
0.918212890625, 0.9133366209366436
eval metrics, batch: 5120 acc, f1
0.76678466796875, 0.7100910470409711
eval metrics, batch: 6144 acc, f1
0.7828369140625, 0.7404814004376368
eval metrics, batch: 7168 acc, f1
0.78759765625, 0.745985401459854
Epoch loss - train: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.7254, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.727752685546875, 0.6356544823361242
train metrics acc, f1 
0.8961715698242188, 0.8858391564395306
Epoch 5/20
----------
eval metrics, batch: 1024 acc, f1
0.7835693359375, 0.7454780361757106
eval metrics, batch: 2048 acc, f1
0.768310546875, 0.7148223273983924
eval metrics, batch: 3072 acc, f1
0.833160400390625, 0.8213223518645619
eval metrics, batch: 4096 acc, f1
0.802734375, 0.7727784026996626
train metrics, batch: 4096  acc, f1 
0.9456405639648438, 0.9450922065611923
eval metrics, batch: 5120 acc, f1
0.78057861328125, 0.733999260081391
eval metrics, batch: 6144 acc, f1
0.7755126953125, 0.7267053053945609
eval metrics, batch: 7168 acc, f1
0.80718994140625, 0.7867701653729329
Epoch loss - train: tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5385, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.79376220703125, 0.7578645646721606
train metrics acc, f1 
0.94696044921875, 0.9459682120234718
Epoch 6/20
----------
eval metrics, batch: 1024 acc, f1
0.804718017578125, 0.7745163677367067
eval metrics, batch: 2048 acc, f1
0.811187744140625, 0.7843273956844564
eval metrics, batch: 3072 acc, f1
0.840087890625, 0.8291712851274695
eval metrics, batch: 4096 acc, f1
0.824981689453125, 0.8196143805240147
train metrics, batch: 4096  acc, f1 
0.9281883239746094, 0.931493888126699
eval metrics, batch: 5120 acc, f1
0.79742431640625, 0.7616345877621373
eval metrics, batch: 6144 acc, f1
0.789825439453125, 0.7493540051679587
eval metrics, batch: 7168 acc, f1
0.786346435546875, 0.7421077835488268
Epoch loss - train: tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4233, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.828460693359375, 0.8157351253892804
train metrics acc, f1 
0.9497795104980469, 0.95062983060763
Epoch 7/20
----------
eval metrics, batch: 1024 acc, f1
0.791412353515625, 0.7569432097009352
eval metrics, batch: 2048 acc, f1
0.7923583984375, 0.7591163350562912
eval metrics, batch: 3072 acc, f1
0.827178955078125, 0.8153630465260344
eval metrics, batch: 4096 acc, f1
0.75592041015625, 0.6939384662482779
train metrics, batch: 4096  acc, f1 
0.9474754333496094, 0.9455506036531595
eval metrics, batch: 5120 acc, f1
0.804046630859375, 0.7718762212669201
eval metrics, batch: 6144 acc, f1
0.800933837890625, 0.7717395107953949
eval metrics, batch: 7168 acc, f1
0.82928466796875, 0.8157808074820523
Epoch loss - train: tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4396, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.832061767578125, 0.8233556960806343
train metrics acc, f1 
0.9515838623046875, 0.9529221501802697
Epoch 8/20
----------
eval metrics, batch: 1024 acc, f1
0.794281005859375, 0.758689815643458
eval metrics, batch: 2048 acc, f1
0.8070068359375, 0.7812067533905341
eval metrics, batch: 3072 acc, f1
0.803497314453125, 0.7711716834286932
eval metrics, batch: 4096 acc, f1
0.79541015625, 0.7611685073031706
train metrics, batch: 4096  acc, f1 
0.9661788940429688, 0.9658498255128689
eval metrics, batch: 5120 acc, f1
0.820587158203125, 0.8015661389948358
eval metrics, batch: 6144 acc, f1
0.775604248046875, 0.7265627905247108
eval metrics, batch: 7168 acc, f1
0.7718505859375, 0.7256312389900176
Epoch loss - train: tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4774, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.819061279296875, 0.8036819972848581
train metrics acc, f1 
0.9604263305664062, 0.9611466494883972
Epoch 9/20
----------
eval metrics, batch: 1024 acc, f1
0.806640625, 0.7830582756967747
eval metrics, batch: 2048 acc, f1
0.783660888671875, 0.7368694554767826
eval metrics, batch: 3072 acc, f1
0.80523681640625, 0.783675683004542
eval metrics, batch: 4096 acc, f1
0.79339599609375, 0.7552068267283772
train metrics, batch: 4096  acc, f1 
0.9666366577148438, 0.9660797393732548
eval metrics, batch: 5120 acc, f1
0.796112060546875, 0.7636633768438926
eval metrics, batch: 6144 acc, f1
0.79498291015625, 0.7563116656993616
eval metrics, batch: 7168 acc, f1
0.81768798828125, 0.8040283427371736
Epoch loss - train: tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5546, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8184814453125, 0.7949813870122708
train metrics acc, f1 
0.9735145568847656, 0.9734849208137453
Epoch 10/20
----------
eval metrics, batch: 1024 acc, f1
0.79156494140625, 0.7529837251356238
eval metrics, batch: 2048 acc, f1
0.804290771484375, 0.7802487749717301
eval metrics, batch: 3072 acc, f1
0.803863525390625, 0.7797992256826669
eval metrics, batch: 4096 acc, f1
0.79962158203125, 0.7664674918196045
train metrics, batch: 4096  acc, f1 
0.9778938293457031, 0.9777651586366723
eval metrics, batch: 5120 acc, f1
0.778228759765625, 0.7355435059499982
eval metrics, batch: 6144 acc, f1
0.772857666015625, 0.7262898540065458
eval metrics, batch: 7168 acc, f1
0.790496826171875, 0.7557721726137536
Epoch loss - train: tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6564, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.797088623046875, 0.763641534250471
train metrics acc, f1 
0.9763755798339844, 0.9761804943903198
Epoch 11/20
----------
eval metrics, batch: 1024 acc, f1
0.79937744140625, 0.7703486341088521
eval metrics, batch: 2048 acc, f1
0.80828857421875, 0.7828101230811783
eval metrics, batch: 3072 acc, f1
0.789154052734375, 0.75276435856146
eval metrics, batch: 4096 acc, f1
0.823822021484375, 0.8095410906931477
train metrics, batch: 4096  acc, f1 
0.9678497314453125, 0.9684034520765695
eval metrics, batch: 5120 acc, f1
0.809967041015625, 0.7834764769289614
eval metrics, batch: 6144 acc, f1
0.8011474609375, 0.7775198033324229
eval metrics, batch: 7168 acc, f1
0.798431396484375, 0.7640650116092159
Epoch loss - train: tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6501, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.814117431640625, 0.7949503450597543
train metrics acc, f1 
0.9799728393554688, 0.9801428204003207
Epoch 12/20
----------
eval metrics, batch: 1024 acc, f1
0.805694580078125, 0.7801526190393978
eval metrics, batch: 2048 acc, f1
0.7882080078125, 0.7550300035298271
eval metrics, batch: 3072 acc, f1
0.803009033203125, 0.7741822634248732
eval metrics, batch: 4096 acc, f1
0.796661376953125, 0.7655111736758754
train metrics, batch: 4096  acc, f1 
0.9776687622070312, 0.9775762079506017
eval metrics, batch: 5120 acc, f1
0.79193115234375, 0.7594892055876957
eval metrics, batch: 6144 acc, f1
0.776763916015625, 0.7301435053676172
eval metrics, batch: 7168 acc, f1
0.80755615234375, 0.7816028260718986
Epoch loss - train: tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8105, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.78277587890625, 0.7407299482771181
train metrics acc, f1 
0.9789657592773438, 0.9786873840445269
Epoch 13/20
----------
eval metrics, batch: 1024 acc, f1
0.80596923828125, 0.7739779594738713
eval metrics, batch: 2048 acc, f1
0.805694580078125, 0.7774787683919897
eval metrics, batch: 3072 acc, f1
0.773895263671875, 0.721246096542383
eval metrics, batch: 4096 acc, f1
0.812652587890625, 0.7875263904752016
train metrics, batch: 4096  acc, f1 
0.984619140625, 0.9846240676052901
eval metrics, batch: 5120 acc, f1
0.769805908203125, 0.7157553604401402
eval metrics, batch: 6144 acc, f1
0.795166015625, 0.7629273806159932
eval metrics, batch: 7168 acc, f1
0.761199951171875, 0.7008220225578283
Epoch loss - train: tensor(0.0601, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8809, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.799102783203125, 0.7666182153366186
train metrics acc, f1 
0.9850845336914062, 0.9849970838321516
Epoch 14/20
----------
eval metrics, batch: 1024 acc, f1
0.802734375, 0.769554367201426
eval metrics, batch: 2048 acc, f1
0.828369140625, 0.8151945320715037
eval metrics, batch: 3072 acc, f1
0.795013427734375, 0.7617324678088752
eval metrics, batch: 4096 acc, f1
0.819122314453125, 0.8013007475946227
train metrics, batch: 4096  acc, f1 
0.9872283935546875, 0.9873066424021838
eval metrics, batch: 5120 acc, f1
0.795623779296875, 0.7618675105785301
eval metrics, batch: 6144 acc, f1
0.805694580078125, 0.7834869248818308
eval metrics, batch: 7168 acc, f1
0.804840087890625, 0.775353918572382
Epoch loss - train: tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.7368, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.818756103515625, 0.7990798064887175
train metrics acc, f1 
0.9851837158203125, 0.9852647712700978
Epoch 15/20
----------
eval metrics, batch: 1024 acc, f1
0.818603515625, 0.7983444157959018
eval metrics, batch: 2048 acc, f1
0.814849853515625, 0.7960466601674119
eval metrics, batch: 3072 acc, f1
0.814178466796875, 0.79140831078072
eval metrics, batch: 4096 acc, f1
0.77618408203125, 0.7276643148904567
train metrics, batch: 4096  acc, f1 
0.9860877990722656, 0.9859316836075376
eval metrics, batch: 5120 acc, f1
0.79425048828125, 0.7595749233292918
eval metrics, batch: 6144 acc, f1
0.806549072265625, 0.7785192690681667
eval metrics, batch: 7168 acc, f1
0.797271728515625, 0.7648412333179936
Epoch loss - train: tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.2563, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.742889404296875, 0.6683984728618098
train metrics acc, f1 
0.9774360656738281, 0.9769477495313553
Epoch 16/20
----------
eval metrics, batch: 1024 acc, f1
0.81591796875, 0.79125138427464
eval metrics, batch: 2048 acc, f1
0.8046875, 0.7774222716839396
eval metrics, batch: 3072 acc, f1
0.816925048828125, 0.7987115391068014
eval metrics, batch: 4096 acc, f1
0.8079833984375, 0.78665400786654
train metrics, batch: 4096  acc, f1 
0.9884109497070312, 0.9884910292156625
eval metrics, batch: 5120 acc, f1
0.802215576171875, 0.7710298533827945
eval metrics, batch: 6144 acc, f1
0.7991943359375, 0.76415770609319
eval metrics, batch: 7168 acc, f1
0.793914794921875, 0.7581217092302733
Epoch loss - train: tensor(0.0426, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.7651, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.825164794921875, 0.8123423629991156
train metrics acc, f1 
0.9873046875, 0.9874102488443002
Epoch 17/20
----------
eval metrics, batch: 1024 acc, f1
0.815643310546875, 0.7927260250471779
eval metrics, batch: 2048 acc, f1
0.807769775390625, 0.7817016115058049
eval metrics, batch: 3072 acc, f1
0.811676025390625, 0.7872582480091013
eval metrics, batch: 4096 acc, f1
0.7972412109375, 0.7693055555555556
train metrics, batch: 4096  acc, f1 
0.9865188598632812, 0.986564576711933
eval metrics, batch: 5120 acc, f1
0.789337158203125, 0.7498278548907331
eval metrics, batch: 6144 acc, f1
0.808837890625, 0.7820155902004454
eval metrics, batch: 7168 acc, f1
0.817230224609375, 0.7956879200354792
Epoch loss - train: tensor(0.0396, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.9273, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.80633544921875, 0.7783908367090375
train metrics acc, f1 
0.9937744140625, 0.9937765032490314
Epoch 18/20
----------
eval metrics, batch: 1024 acc, f1
0.797210693359375, 0.7642028316951137
eval metrics, batch: 2048 acc, f1
0.79925537109375, 0.7647689886997568
eval metrics, batch: 3072 acc, f1
0.79791259765625, 0.7648604502521128
eval metrics, batch: 4096 acc, f1
0.82427978515625, 0.8105173094642623
train metrics, batch: 4096  acc, f1 
0.9880104064941406, 0.9881102347311279
eval metrics, batch: 5120 acc, f1
0.80389404296875, 0.7774776646582173
eval metrics, batch: 6144 acc, f1
0.8033447265625, 0.7728266234224072
eval metrics, batch: 7168 acc, f1
0.806884765625, 0.7792352777002511
Epoch loss - train: tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.9488, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.823211669921875, 0.8049297908879685
train metrics acc, f1 
0.9901885986328125, 0.9902305617806815
Epoch 19/20
----------
eval metrics, batch: 1024 acc, f1
0.810089111328125, 0.7854211923726768
eval metrics, batch: 2048 acc, f1
0.807708740234375, 0.7815262993654867
eval metrics, batch: 3072 acc, f1
0.819732666015625, 0.7978370238543413
eval metrics, batch: 4096 acc, f1
0.83245849609375, 0.8170853601652562
train metrics, batch: 4096  acc, f1 
0.9898033142089844, 0.9898543628517097
eval metrics, batch: 5120 acc, f1
0.789306640625, 0.7521361384361313
eval metrics, batch: 6144 acc, f1
0.8145751953125, 0.7905116535650255
eval metrics, batch: 7168 acc, f1
0.763458251953125, 0.7041038366100401
Epoch loss - train: tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.4860, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.766204833984375, 0.7122196761954848
train metrics acc, f1 
0.9827651977539062, 0.9825108774754967
Epoch 20/20
----------
eval metrics, batch: 1024 acc, f1
0.8104248046875, 0.7826604156462109
eval metrics, batch: 2048 acc, f1
0.802490234375, 0.772112676056338
eval metrics, batch: 3072 acc, f1
0.822021484375, 0.8143148242485991
eval metrics, batch: 4096 acc, f1
0.782806396484375, 0.7396378269617706
train metrics, batch: 4096  acc, f1 
0.9811973571777344, 0.9809522705403619
eval metrics, batch: 5120 acc, f1
0.76959228515625, 0.7191847057948375
eval metrics, batch: 6144 acc, f1
0.776397705078125, 0.7293813481071099
eval metrics, batch: 7168 acc, f1
0.769561767578125, 0.7168410394870064
Epoch loss - train: tensor(0.0308, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.9685, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.818817138671875, 0.7987662271633393
train metrics acc, f1 
0.9928855895996094, 0.9929017009275365
Training time 507m 6s
train_acc
0.5	0.8556747436523438	0.8839874267578125	0.8867301940917969	0.88201904296875	0.9135513305664062	0.9271888732910156	0.918212890625	0.8961715698242188	0.9456405639648438	0.94696044921875	0.9281883239746094	0.9497795104980469	0.9474754333496094	0.9515838623046875	0.9661788940429688	0.9604263305664062	0.9666366577148438	0.9735145568847656	0.9778938293457031	0.9763755798339844	0.9678497314453125	0.9799728393554688	0.9776687622070312	0.9789657592773438	0.984619140625	0.9850845336914062	0.9872283935546875	0.9851837158203125	0.9860877990722656	0.9774360656738281	0.9884109497070312	0.9873046875	0.9865188598632812	0.9937744140625	0.9880104064941406	0.9901885986328125	0.9898033142089844	0.9827651977539062	0.9811973571777344	0.9928855895996094
train_f1
0.0	0.8582401606666467	0.8861996707079779	0.880231043203627	0.8907330860272037	0.9130838325649896	0.9259582523556269	0.9133366209366436	0.8858391564395306	0.9450922065611923	0.9459682120234718	0.931493888126699	0.95062983060763	0.9455506036531595	0.9529221501802697	0.9658498255128689	0.9611466494883972	0.9660797393732548	0.9734849208137453	0.9777651586366723	0.9761804943903198	0.9684034520765695	0.9801428204003207	0.9775762079506017	0.9786873840445269	0.9846240676052901	0.9849970838321516	0.9873066424021838	0.9852647712700978	0.9859316836075376	0.9769477495313553	0.9884910292156625	0.9874102488443002	0.986564576711933	0.9937765032490314	0.9881102347311279	0.9902305617806815	0.9898543628517097	0.9825108774754967	0.9809522705403619	0.9929017009275365
train_loss
tensor(0.3670, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2863, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1214, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1062, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0916, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0797, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0695, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0601, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0531, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0478, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0426, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0396, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0357, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0335, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0308, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.500457763671875	0.75494384765625	0.804656982421875	0.8089599609375	0.807952880859375	0.7867431640625	0.804656982421875	0.754547119140625	0.8189697265625	0.7811279296875	0.81915283203125	0.82501220703125	0.772491455078125	0.82135009765625	0.771820068359375	0.8134765625	0.827117919921875	0.785797119140625	0.78741455078125	0.7666015625	0.795196533203125	0.7911376953125	0.795318603515625	0.83807373046875	0.807281494140625	0.81298828125	0.817169189453125	0.823486328125	0.75347900390625	0.76678466796875	0.7828369140625	0.78759765625	0.727752685546875	0.7835693359375	0.768310546875	0.833160400390625	0.802734375	0.78057861328125	0.7755126953125	0.80718994140625	0.79376220703125	0.804718017578125	0.811187744140625	0.840087890625	0.824981689453125	0.79742431640625	0.789825439453125	0.786346435546875	0.828460693359375	0.791412353515625	0.7923583984375	0.827178955078125	0.75592041015625	0.804046630859375	0.800933837890625	0.82928466796875	0.832061767578125	0.794281005859375	0.8070068359375	0.803497314453125	0.79541015625	0.820587158203125	0.775604248046875	0.7718505859375	0.819061279296875	0.806640625	0.783660888671875	0.80523681640625	0.79339599609375	0.796112060546875	0.79498291015625	0.81768798828125	0.8184814453125	0.79156494140625	0.804290771484375	0.803863525390625	0.79962158203125	0.778228759765625	0.772857666015625	0.790496826171875	0.797088623046875	0.79937744140625	0.80828857421875	0.789154052734375	0.823822021484375	0.809967041015625	0.8011474609375	0.798431396484375	0.814117431640625	0.805694580078125	0.7882080078125	0.803009033203125	0.796661376953125	0.79193115234375	0.776763916015625	0.80755615234375	0.78277587890625	0.80596923828125	0.805694580078125	0.773895263671875	0.812652587890625	0.769805908203125	0.795166015625	0.761199951171875	0.799102783203125	0.802734375	0.828369140625	0.795013427734375	0.819122314453125	0.795623779296875	0.805694580078125	0.804840087890625	0.818756103515625	0.818603515625	0.814849853515625	0.814178466796875	0.77618408203125	0.79425048828125	0.806549072265625	0.797271728515625	0.742889404296875	0.81591796875	0.8046875	0.816925048828125	0.8079833984375	0.802215576171875	0.7991943359375	0.793914794921875	0.825164794921875	0.815643310546875	0.807769775390625	0.811676025390625	0.7972412109375	0.789337158203125	0.808837890625	0.817230224609375	0.80633544921875	0.797210693359375	0.79925537109375	0.79791259765625	0.82427978515625	0.80389404296875	0.8033447265625	0.806884765625	0.823211669921875	0.810089111328125	0.807708740234375	0.819732666015625	0.83245849609375	0.789306640625	0.8145751953125	0.763458251953125	0.766204833984375	0.8104248046875	0.802490234375	0.822021484375	0.782806396484375	0.76959228515625	0.776397705078125	0.769561767578125	0.818817138671875
valid_f1
0.0	0.7055804062477085	0.8217041308041558	0.820228591120556	0.8014137397835212	0.7657862984314251	0.794305729618561	0.7053306466385785	0.8107090433339715	0.7664452259997395	0.8078594124894625	0.8132247557003257	0.7295483402865953	0.8168220789786594	0.7265679283232767	0.8044410315479619	0.8322227158300015	0.7535030728709394	0.747773191396915	0.7207128250073035	0.7694527465732248	0.757700205338809	0.7625420428394406	0.834011136832885	0.7798500958689211	0.7958694203864091	0.8124236826450422	0.8046077967704884	0.6884929816443005	0.7100910470409711	0.7404814004376368	0.745985401459854	0.6356544823361242	0.7454780361757106	0.7148223273983924	0.8213223518645619	0.7727784026996626	0.733999260081391	0.7267053053945609	0.7867701653729329	0.7578645646721606	0.7745163677367067	0.7843273956844564	0.8291712851274695	0.8196143805240147	0.7616345877621373	0.7493540051679587	0.7421077835488268	0.8157351253892804	0.7569432097009352	0.7591163350562912	0.8153630465260344	0.6939384662482779	0.7718762212669201	0.7717395107953949	0.8157808074820523	0.8233556960806343	0.758689815643458	0.7812067533905341	0.7711716834286932	0.7611685073031706	0.8015661389948358	0.7265627905247108	0.7256312389900176	0.8036819972848581	0.7830582756967747	0.7368694554767826	0.783675683004542	0.7552068267283772	0.7636633768438926	0.7563116656993616	0.8040283427371736	0.7949813870122708	0.7529837251356238	0.7802487749717301	0.7797992256826669	0.7664674918196045	0.7355435059499982	0.7262898540065458	0.7557721726137536	0.763641534250471	0.7703486341088521	0.7828101230811783	0.75276435856146	0.8095410906931477	0.7834764769289614	0.7775198033324229	0.7640650116092159	0.7949503450597543	0.7801526190393978	0.7550300035298271	0.7741822634248732	0.7655111736758754	0.7594892055876957	0.7301435053676172	0.7816028260718986	0.7407299482771181	0.7739779594738713	0.7774787683919897	0.721246096542383	0.7875263904752016	0.7157553604401402	0.7629273806159932	0.7008220225578283	0.7666182153366186	0.769554367201426	0.8151945320715037	0.7617324678088752	0.8013007475946227	0.7618675105785301	0.7834869248818308	0.775353918572382	0.7990798064887175	0.7983444157959018	0.7960466601674119	0.79140831078072	0.7276643148904567	0.7595749233292918	0.7785192690681667	0.7648412333179936	0.6683984728618098	0.79125138427464	0.7774222716839396	0.7987115391068014	0.78665400786654	0.7710298533827945	0.76415770609319	0.7581217092302733	0.8123423629991156	0.7927260250471779	0.7817016115058049	0.7872582480091013	0.7693055555555556	0.7498278548907331	0.7820155902004454	0.7956879200354792	0.7783908367090375	0.7642028316951137	0.7647689886997568	0.7648604502521128	0.8105173094642623	0.7774776646582173	0.7728266234224072	0.7792352777002511	0.8049297908879685	0.7854211923726768	0.7815262993654867	0.7978370238543413	0.8170853601652562	0.7521361384361313	0.7905116535650255	0.7041038366100401	0.7122196761954848	0.7826604156462109	0.772112676056338	0.8143148242485991	0.7396378269617706	0.7191847057948375	0.7293813481071099	0.7168410394870064	0.7987662271633393
valid_loss
tensor(0.4194, device='cuda:0')	tensor(0.3853, device='cuda:0')	tensor(0.4532, device='cuda:0')	tensor(0.7254, device='cuda:0')	tensor(0.5385, device='cuda:0')	tensor(0.4233, device='cuda:0')	tensor(0.4396, device='cuda:0')	tensor(0.4774, device='cuda:0')	tensor(0.5546, device='cuda:0')	tensor(0.6564, device='cuda:0')	tensor(0.6501, device='cuda:0')	tensor(0.8105, device='cuda:0')	tensor(0.8809, device='cuda:0')	tensor(0.7368, device='cuda:0')	tensor(1.2563, device='cuda:0')	tensor(0.7651, device='cuda:0')	tensor(0.9273, device='cuda:0')	tensor(0.9488, device='cuda:0')	tensor(1.4860, device='cuda:0')	tensor(0.9685, device='cuda:0')
Best model metrics: train, valid, test: acc, f1
0.88201904296875, 0.8907330860272037
0.827117919921875, 0.8322227158300015
0.785308837890625, 0.782742966554461
Model saved, path ./models/resnet_12-1559491145.pth
experiment validation
train set
Evaluation results
[[105155.  25917.]
 [  5011. 126061.]]
#############################
Accuracy
0.88201904296875
------------------------
Recall
0.9617691040039062
------------------------
Specificity
0.8022689819335938
------------------------
Precision
0.8294687388964193
------------------------
Fall_out
0.19773101806640625
------------------------
F1
0.8907330860272037
------------------------
#############################
valid set
Evaluation results
[[13053.  3346.]
 [ 2319. 14050.]]
#############################
Accuracy
0.827117919921875
------------------------
Recall
0.8583297696866027
------------------------
Specificity
0.7959631684858833
------------------------
Precision
0.8076569326281904
------------------------
Fall_out
0.20403683151411672
------------------------
F1
0.8322227158300015
------------------------
#############################
test set
Evaluation results
[[13060.  3331.]
 [ 3704. 12673.]]
#############################
Accuracy
0.785308837890625
------------------------
Recall
0.77382915063809
------------------------
Specificity
0.7967787200292844
------------------------
Precision
0.7918645338665333
------------------------
Fall_out
0.20322127997071562
------------------------
F1
0.782742966554461
------------------------
#############################
AUC: 0.8743620415916296
Experiment end
########################################
----------------------------------------
Starting experiment resnet_13-1559491145
Experiment parameters Experiment[name: resnet_13-1559491145, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 1e-05, weight_decay: 0, batch_size: 32, num_epochs: 20), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.5, 0.6664630918936525
train metrics acc, f1
0.5006904602050781, 0.6669736791888763
Epoch 1/20
----------
eval metrics, batch: 1024 acc, f1
0.78082275390625, 0.7697191227395151
eval metrics, batch: 2048 acc, f1
0.7957763671875, 0.7967316687929045
eval metrics, batch: 3072 acc, f1
0.780029296875, 0.7696094099597264
eval metrics, batch: 4096 acc, f1
0.7802734375, 0.7580157289776165
train metrics, batch: 4096  acc, f1 
0.831939697265625, 0.8237210009522972
eval metrics, batch: 5120 acc, f1
0.795745849609375, 0.787800006340953
eval metrics, batch: 6144 acc, f1
0.795867919921875, 0.7845940810871735
eval metrics, batch: 7168 acc, f1
0.784210205078125, 0.7582481452357346
Epoch loss - train: tensor(0.3936, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4132, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.814727783203125, 0.8145863237943988
train metrics acc, f1 
0.8598785400390625, 0.865902453271028
Epoch 2/20
----------
eval metrics, batch: 1024 acc, f1
0.772003173828125, 0.7407613033068462
eval metrics, batch: 2048 acc, f1
0.79107666015625, 0.7736260829310231
eval metrics, batch: 3072 acc, f1
0.805938720703125, 0.7913234666754175
eval metrics, batch: 4096 acc, f1
0.79730224609375, 0.7803571428571429
train metrics, batch: 4096  acc, f1 
0.8735771179199219, 0.8725782328356831
eval metrics, batch: 5120 acc, f1
0.79144287109375, 0.7786917098445596
eval metrics, batch: 6144 acc, f1
0.78594970703125, 0.7584378013500482
eval metrics, batch: 7168 acc, f1
0.79736328125, 0.79262960649594
Epoch loss - train: tensor(0.3312, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4262, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.799835205078125, 0.7933717670037489
train metrics acc, f1 
0.8853034973144531, 0.8897905922284901
Epoch 3/20
----------
eval metrics, batch: 1024 acc, f1
0.782012939453125, 0.7581349676632919
eval metrics, batch: 2048 acc, f1
0.7984619140625, 0.7763175721446959
eval metrics, batch: 3072 acc, f1
0.79388427734375, 0.7732491774659236
eval metrics, batch: 4096 acc, f1
0.795684814453125, 0.7865182870444182
train metrics, batch: 4096  acc, f1 
0.8922386169433594, 0.8959593987897716
eval metrics, batch: 5120 acc, f1
0.77972412109375, 0.7464699683877766
eval metrics, batch: 6144 acc, f1
0.75421142578125, 0.7026068975703419
eval metrics, batch: 7168 acc, f1
0.81256103515625, 0.8118836140888208
Epoch loss - train: tensor(0.2875, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5312, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7744140625, 0.74162880111849
train metrics acc, f1 
0.9060745239257812, 0.9047821614472554
Epoch 4/20
----------
eval metrics, batch: 1024 acc, f1
0.789520263671875, 0.7729980581246092
eval metrics, batch: 2048 acc, f1
0.8072509765625, 0.8093915982617094
eval metrics, batch: 3072 acc, f1
0.804443359375, 0.7969066937119675
eval metrics, batch: 4096 acc, f1
0.7659912109375, 0.7304176627759809
train metrics, batch: 4096  acc, f1 
0.91424560546875, 0.9133284497050546
eval metrics, batch: 5120 acc, f1
0.76806640625, 0.7296720495126983
eval metrics, batch: 6144 acc, f1
0.7606201171875, 0.7154052681227777
eval metrics, batch: 7168 acc, f1
0.75518798828125, 0.7071407710280374
Epoch loss - train: tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.7175, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7412109375, 0.6737457679285934
train metrics acc, f1 
0.8999366760253906, 0.8926898515388172
Epoch 5/20
----------
eval metrics, batch: 1024 acc, f1
0.77032470703125, 0.7427536231884058
eval metrics, batch: 2048 acc, f1
0.769134521484375, 0.7282784382744872
eval metrics, batch: 3072 acc, f1
0.775970458984375, 0.7401875774199257
eval metrics, batch: 4096 acc, f1
0.781158447265625, 0.7585115339282708
train metrics, batch: 4096  acc, f1 
0.9374618530273438, 0.9381880976080597
eval metrics, batch: 5120 acc, f1
0.781829833984375, 0.7620093877958654
eval metrics, batch: 6144 acc, f1
0.769073486328125, 0.7310084959653051
eval metrics, batch: 7168 acc, f1
0.78729248046875, 0.771220376813497
Epoch loss - train: tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6977, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.732757568359375, 0.6618788370207344
train metrics acc, f1 
0.927276611328125, 0.9234162214277106
Epoch 6/20
----------
eval metrics, batch: 1024 acc, f1
0.77069091796875, 0.7382428760537867
eval metrics, batch: 2048 acc, f1
0.773345947265625, 0.7388445444635887
eval metrics, batch: 3072 acc, f1
0.80535888671875, 0.8156221091581869
eval metrics, batch: 4096 acc, f1
0.797088623046875, 0.7957861113670567
train metrics, batch: 4096  acc, f1 
0.9307327270507812, 0.9341060515887416
eval metrics, batch: 5120 acc, f1
0.7720947265625, 0.7321953668507495
eval metrics, batch: 6144 acc, f1
0.7828369140625, 0.7602102709260008
eval metrics, batch: 7168 acc, f1
0.743927001953125, 0.6821229685191499
Epoch loss - train: tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.7038, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.754364013671875, 0.7036996134732192
train metrics acc, f1 
0.9460601806640625, 0.9444479366376466
Epoch 7/20
----------
eval metrics, batch: 1024 acc, f1
0.77392578125, 0.7379554297842236
eval metrics, batch: 2048 acc, f1
0.7635498046875, 0.7271830985915493
eval metrics, batch: 3072 acc, f1
0.74835205078125, 0.691484585453457
eval metrics, batch: 4096 acc, f1
0.771575927734375, 0.7439887813387146
train metrics, batch: 4096  acc, f1 
0.9648666381835938, 0.9651176002726963
eval metrics, batch: 5120 acc, f1
0.76708984375, 0.7300891215164804
eval metrics, batch: 6144 acc, f1
0.795654296875, 0.7928986762340715
eval metrics, batch: 7168 acc, f1
0.78564453125, 0.7803215112278726
Epoch loss - train: tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6690, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.76641845703125, 0.7489833398924308
train metrics acc, f1 
0.9614944458007812, 0.9623717642848623
Epoch 8/20
----------
eval metrics, batch: 1024 acc, f1
0.762115478515625, 0.7283309518000907
eval metrics, batch: 2048 acc, f1
0.77227783203125, 0.7372905224616251
eval metrics, batch: 3072 acc, f1
0.79010009765625, 0.7850625
eval metrics, batch: 4096 acc, f1
0.77386474609375, 0.7492216055232165
train metrics, batch: 4096  acc, f1 
0.9736328125, 0.9739268200678989
eval metrics, batch: 5120 acc, f1
0.77557373046875, 0.7539645366343258
eval metrics, batch: 6144 acc, f1
0.76348876953125, 0.7244738339021616
eval metrics, batch: 7168 acc, f1
0.739654541015625, 0.6922993688007214
Epoch loss - train: tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.9064, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.753021240234375, 0.7046889253785805
train metrics acc, f1 
0.97491455078125, 0.9745441876669376
Epoch 9/20
----------
eval metrics, batch: 1024 acc, f1
0.75592041015625, 0.7173851590106007
eval metrics, batch: 2048 acc, f1
0.732330322265625, 0.6670209938878554
eval metrics, batch: 3072 acc, f1
0.769561767578125, 0.732603845745246
eval metrics, batch: 4096 acc, f1
0.724151611328125, 0.6428260955466867
train metrics, batch: 4096  acc, f1 
0.9492340087890625, 0.9468109767308015
eval metrics, batch: 5120 acc, f1
0.78472900390625, 0.7801259273112648
eval metrics, batch: 6144 acc, f1
0.77197265625, 0.7443547283426851
eval metrics, batch: 7168 acc, f1
0.780181884765625, 0.7638747746271103
Epoch loss - train: tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.0521, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.75946044921875, 0.7141095393543707
train metrics acc, f1 
0.982757568359375, 0.9825506879352677
Epoch 10/20
----------
eval metrics, batch: 1024 acc, f1
0.769775390625, 0.7500165683610577
eval metrics, batch: 2048 acc, f1
0.764434814453125, 0.7358406625372164
eval metrics, batch: 3072 acc, f1
0.780426025390625, 0.7588564533967892
eval metrics, batch: 4096 acc, f1
0.77630615234375, 0.7546197107659347
train metrics, batch: 4096  acc, f1 
0.9844131469726562, 0.9845213201200109
eval metrics, batch: 5120 acc, f1
0.742919921875, 0.6812471621008022
eval metrics, batch: 6144 acc, f1
0.76324462890625, 0.735510705032047
eval metrics, batch: 7168 acc, f1
0.769805908203125, 0.7318997689710325
Epoch loss - train: tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.9424, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7889404296875, 0.7695588431294149
train metrics acc, f1 
0.989715576171875, 0.9897592512402094
Epoch 11/20
----------
eval metrics, batch: 1024 acc, f1
0.76019287109375, 0.7266402282056634
eval metrics, batch: 2048 acc, f1
0.76434326171875, 0.7367200818274804
eval metrics, batch: 3072 acc, f1
0.7459716796875, 0.6921142180795976
eval metrics, batch: 4096 acc, f1
0.79296875, 0.7830092118730808
train metrics, batch: 4096  acc, f1 
0.9808006286621094, 0.9810587956359585
eval metrics, batch: 5120 acc, f1
0.7635498046875, 0.7195598668017953
eval metrics, batch: 6144 acc, f1
0.7474365234375, 0.6897585844954266
eval metrics, batch: 7168 acc, f1
0.7724609375, 0.7433920704845814
Epoch loss - train: tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.4422, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.74945068359375, 0.6978284873021715
train metrics acc, f1 
0.9879150390625, 0.9878062862289555
Epoch 12/20
----------
eval metrics, batch: 1024 acc, f1
0.769073486328125, 0.7394911694839398
eval metrics, batch: 2048 acc, f1
0.78924560546875, 0.780747983998984
eval metrics, batch: 3072 acc, f1
0.756011962890625, 0.7100003627262504
eval metrics, batch: 4096 acc, f1
0.765899658203125, 0.7305300874697017
train metrics, batch: 4096  acc, f1 
0.9923820495605469, 0.9923731176266151
eval metrics, batch: 5120 acc, f1
0.75775146484375, 0.714234286125711
eval metrics, batch: 6144 acc, f1
0.7379150390625, 0.6753610040069554
eval metrics, batch: 7168 acc, f1
0.77313232421875, 0.7517697342059569
Epoch loss - train: tensor(0.0561, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.3766, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.762451171875, 0.7217615098655991
train metrics acc, f1 
0.9869766235351562, 0.9869189388017839
Epoch 13/20
----------
eval metrics, batch: 1024 acc, f1
0.76995849609375, 0.7385725185544842
eval metrics, batch: 2048 acc, f1
0.7838134765625, 0.771483870967742
eval metrics, batch: 3072 acc, f1
0.746368408203125, 0.6978147838417628
eval metrics, batch: 4096 acc, f1
0.787841796875, 0.7706367535466843
train metrics, batch: 4096  acc, f1 
0.9877853393554688, 0.987866891999424
eval metrics, batch: 5120 acc, f1
0.758636474609375, 0.7152270190472761
eval metrics, batch: 6144 acc, f1
0.773345947265625, 0.7503948916148546
eval metrics, batch: 7168 acc, f1
0.763671875, 0.7234088149153511
Epoch loss - train: tensor(0.0506, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.4358, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7425537109375, 0.6897160511990584
train metrics acc, f1 
0.989959716796875, 0.9898864920114046
Epoch 14/20
----------
eval metrics, batch: 1024 acc, f1
0.77557373046875, 0.747111416781293
eval metrics, batch: 2048 acc, f1
0.779052734375, 0.7674269193703823
eval metrics, batch: 3072 acc, f1
0.75567626953125, 0.7076821965824449
eval metrics, batch: 4096 acc, f1
0.77130126953125, 0.7578049253441924
train metrics, batch: 4096  acc, f1 
0.9822731018066406, 0.9825225191342122
eval metrics, batch: 5120 acc, f1
0.793304443359375, 0.7914267237397222
eval metrics, batch: 6144 acc, f1
0.744476318359375, 0.6971899750461105
eval metrics, batch: 7168 acc, f1
0.7811279296875, 0.7615057196062782
Epoch loss - train: tensor(0.0468, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.0804, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.787017822265625, 0.7687004938189772
train metrics acc, f1 
0.99420166015625, 0.9942178061139092
Epoch 15/20
----------
eval metrics, batch: 1024 acc, f1
0.7681884765625, 0.7401477832512315
eval metrics, batch: 2048 acc, f1
0.743011474609375, 0.6814691530809094
eval metrics, batch: 3072 acc, f1
0.78375244140625, 0.7691555903049258
eval metrics, batch: 4096 acc, f1
0.7769775390625, 0.7568538727708278
train metrics, batch: 4096  acc, f1 
0.9867897033691406, 0.9869076198937639
eval metrics, batch: 5120 acc, f1
0.788360595703125, 0.7788231542018816
eval metrics, batch: 6144 acc, f1
0.73028564453125, 0.6581044487427467
eval metrics, batch: 7168 acc, f1
0.7764892578125, 0.7465042226221792
Epoch loss - train: tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.2257, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.768798828125, 0.7375277161862528
train metrics acc, f1 
0.9962387084960938, 0.9962404581607985
Epoch 16/20
----------
eval metrics, batch: 1024 acc, f1
0.766082763671875, 0.7299439805517387
eval metrics, batch: 2048 acc, f1
0.75469970703125, 0.7069204404579597
eval metrics, batch: 3072 acc, f1
0.7613525390625, 0.7376191115286539
eval metrics, batch: 4096 acc, f1
0.7384033203125, 0.6816932788711474
train metrics, batch: 4096  acc, f1 
0.9893417358398438, 0.989248966838796
eval metrics, batch: 5120 acc, f1
0.766632080078125, 0.7281066666666667
eval metrics, batch: 6144 acc, f1
0.77398681640625, 0.7469937141295436
eval metrics, batch: 7168 acc, f1
0.77252197265625, 0.7388776010649478
Epoch loss - train: tensor(0.0390, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1282, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.79058837890625, 0.776015145580363
train metrics acc, f1 
0.9939537048339844, 0.9939756517508619
Epoch 17/20
----------
eval metrics, batch: 1024 acc, f1
0.7607421875, 0.7221631582677723
eval metrics, batch: 2048 acc, f1
0.747802734375, 0.6944013016788699
eval metrics, batch: 3072 acc, f1
0.761505126953125, 0.7238027920127231
eval metrics, batch: 4096 acc, f1
0.7767333984375, 0.7517306909189629
train metrics, batch: 4096  acc, f1 
0.9884147644042969, 0.9884203743456196
eval metrics, batch: 5120 acc, f1
0.792633056640625, 0.7860718445990618
eval metrics, batch: 6144 acc, f1
0.779205322265625, 0.7540872166139833
eval metrics, batch: 7168 acc, f1
0.775848388671875, 0.7541751731985675
Epoch loss - train: tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.4225, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.755859375, 0.7124991015596924
train metrics acc, f1 
0.9951934814453125, 0.9951821602275855
Epoch 18/20
----------
eval metrics, batch: 1024 acc, f1
0.75830078125, 0.7185100938299688
eval metrics, batch: 2048 acc, f1
0.767974853515625, 0.7385758002957054
eval metrics, batch: 3072 acc, f1
0.78094482421875, 0.7565294077742352
eval metrics, batch: 4096 acc, f1
0.761322021484375, 0.7261266939804601
train metrics, batch: 4096  acc, f1 
0.9945945739746094, 0.994591128228814
eval metrics, batch: 5120 acc, f1
0.7928466796875, 0.785081053698075
eval metrics, batch: 6144 acc, f1
0.744415283203125, 0.7013088911872749
eval metrics, batch: 7168 acc, f1
0.7791748046875, 0.7536429252349176
Epoch loss - train: tensor(0.0346, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1356, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.79296875, 0.7784165142409197
train metrics acc, f1 
0.9892234802246094, 0.9892874342551828
Epoch 19/20
----------
eval metrics, batch: 1024 acc, f1
0.7606201171875, 0.7242494551079238
eval metrics, batch: 2048 acc, f1
0.78118896484375, 0.7595895922746781
eval metrics, batch: 3072 acc, f1
0.78375244140625, 0.7607859023698602
eval metrics, batch: 4096 acc, f1
0.773681640625, 0.7410614525139665
train metrics, batch: 4096  acc, f1 
0.9954872131347656, 0.9954779151774622
eval metrics, batch: 5120 acc, f1
0.78643798828125, 0.7673537234042553
eval metrics, batch: 6144 acc, f1
0.760772705078125, 0.7262441068622315
eval metrics, batch: 7168 acc, f1
0.796630859375, 0.7915024091108191
Epoch loss - train: tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.4269, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.771881103515625, 0.7373229785290086
train metrics acc, f1 
0.9967727661132812, 0.9967665988900949
Epoch 20/20
----------
eval metrics, batch: 1024 acc, f1
0.763427734375, 0.7296505545093116
eval metrics, batch: 2048 acc, f1
0.7490234375, 0.6923997606223818
eval metrics, batch: 3072 acc, f1
0.7755126953125, 0.7542265285666555
eval metrics, batch: 4096 acc, f1
0.76873779296875, 0.7314480119072932
train metrics, batch: 4096  acc, f1 
0.9941864013671875, 0.9941647202971244
eval metrics, batch: 5120 acc, f1
0.762359619140625, 0.7209660658616118
eval metrics, batch: 6144 acc, f1
0.787353515625, 0.7647058823529411
eval metrics, batch: 7168 acc, f1
0.7579345703125, 0.7136875541438059
Epoch loss - train: tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.4551, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.773956298828125, 0.7423204035484432
train metrics acc, f1 
0.9968948364257812, 0.9968915636885759
Training time 505m 31s
train_acc
0.5006904602050781	0.831939697265625	0.8598785400390625	0.8735771179199219	0.8853034973144531	0.8922386169433594	0.9060745239257812	0.91424560546875	0.8999366760253906	0.9374618530273438	0.927276611328125	0.9307327270507812	0.9460601806640625	0.9648666381835938	0.9614944458007812	0.9736328125	0.97491455078125	0.9492340087890625	0.982757568359375	0.9844131469726562	0.989715576171875	0.9808006286621094	0.9879150390625	0.9923820495605469	0.9869766235351562	0.9877853393554688	0.989959716796875	0.9822731018066406	0.99420166015625	0.9867897033691406	0.9962387084960938	0.9893417358398438	0.9939537048339844	0.9884147644042969	0.9951934814453125	0.9945945739746094	0.9892234802246094	0.9954872131347656	0.9967727661132812	0.9941864013671875	0.9968948364257812
train_f1
0.6669736791888763	0.8237210009522972	0.865902453271028	0.8725782328356831	0.8897905922284901	0.8959593987897716	0.9047821614472554	0.9133284497050546	0.8926898515388172	0.9381880976080597	0.9234162214277106	0.9341060515887416	0.9444479366376466	0.9651176002726963	0.9623717642848623	0.9739268200678989	0.9745441876669376	0.9468109767308015	0.9825506879352677	0.9845213201200109	0.9897592512402094	0.9810587956359585	0.9878062862289555	0.9923731176266151	0.9869189388017839	0.987866891999424	0.9898864920114046	0.9825225191342122	0.9942178061139092	0.9869076198937639	0.9962404581607985	0.989248966838796	0.9939756517508619	0.9884203743456196	0.9951821602275855	0.994591128228814	0.9892874342551828	0.9954779151774622	0.9967665988900949	0.9941647202971244	0.9968915636885759
train_loss
tensor(0.3936, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3312, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2875, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2148, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1828, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1466, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1152, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0933, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0761, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0637, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0561, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0506, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0468, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0424, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0390, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0370, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0346, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0336, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.5	0.78082275390625	0.7957763671875	0.780029296875	0.7802734375	0.795745849609375	0.795867919921875	0.784210205078125	0.814727783203125	0.772003173828125	0.79107666015625	0.805938720703125	0.79730224609375	0.79144287109375	0.78594970703125	0.79736328125	0.799835205078125	0.782012939453125	0.7984619140625	0.79388427734375	0.795684814453125	0.77972412109375	0.75421142578125	0.81256103515625	0.7744140625	0.789520263671875	0.8072509765625	0.804443359375	0.7659912109375	0.76806640625	0.7606201171875	0.75518798828125	0.7412109375	0.77032470703125	0.769134521484375	0.775970458984375	0.781158447265625	0.781829833984375	0.769073486328125	0.78729248046875	0.732757568359375	0.77069091796875	0.773345947265625	0.80535888671875	0.797088623046875	0.7720947265625	0.7828369140625	0.743927001953125	0.754364013671875	0.77392578125	0.7635498046875	0.74835205078125	0.771575927734375	0.76708984375	0.795654296875	0.78564453125	0.76641845703125	0.762115478515625	0.77227783203125	0.79010009765625	0.77386474609375	0.77557373046875	0.76348876953125	0.739654541015625	0.753021240234375	0.75592041015625	0.732330322265625	0.769561767578125	0.724151611328125	0.78472900390625	0.77197265625	0.780181884765625	0.75946044921875	0.769775390625	0.764434814453125	0.780426025390625	0.77630615234375	0.742919921875	0.76324462890625	0.769805908203125	0.7889404296875	0.76019287109375	0.76434326171875	0.7459716796875	0.79296875	0.7635498046875	0.7474365234375	0.7724609375	0.74945068359375	0.769073486328125	0.78924560546875	0.756011962890625	0.765899658203125	0.75775146484375	0.7379150390625	0.77313232421875	0.762451171875	0.76995849609375	0.7838134765625	0.746368408203125	0.787841796875	0.758636474609375	0.773345947265625	0.763671875	0.7425537109375	0.77557373046875	0.779052734375	0.75567626953125	0.77130126953125	0.793304443359375	0.744476318359375	0.7811279296875	0.787017822265625	0.7681884765625	0.743011474609375	0.78375244140625	0.7769775390625	0.788360595703125	0.73028564453125	0.7764892578125	0.768798828125	0.766082763671875	0.75469970703125	0.7613525390625	0.7384033203125	0.766632080078125	0.77398681640625	0.77252197265625	0.79058837890625	0.7607421875	0.747802734375	0.761505126953125	0.7767333984375	0.792633056640625	0.779205322265625	0.775848388671875	0.755859375	0.75830078125	0.767974853515625	0.78094482421875	0.761322021484375	0.7928466796875	0.744415283203125	0.7791748046875	0.79296875	0.7606201171875	0.78118896484375	0.78375244140625	0.773681640625	0.78643798828125	0.760772705078125	0.796630859375	0.771881103515625	0.763427734375	0.7490234375	0.7755126953125	0.76873779296875	0.762359619140625	0.787353515625	0.7579345703125	0.773956298828125
valid_f1
0.6664630918936525	0.7697191227395151	0.7967316687929045	0.7696094099597264	0.7580157289776165	0.787800006340953	0.7845940810871735	0.7582481452357346	0.8145863237943988	0.7407613033068462	0.7736260829310231	0.7913234666754175	0.7803571428571429	0.7786917098445596	0.7584378013500482	0.79262960649594	0.7933717670037489	0.7581349676632919	0.7763175721446959	0.7732491774659236	0.7865182870444182	0.7464699683877766	0.7026068975703419	0.8118836140888208	0.74162880111849	0.7729980581246092	0.8093915982617094	0.7969066937119675	0.7304176627759809	0.7296720495126983	0.7154052681227777	0.7071407710280374	0.6737457679285934	0.7427536231884058	0.7282784382744872	0.7401875774199257	0.7585115339282708	0.7620093877958654	0.7310084959653051	0.771220376813497	0.6618788370207344	0.7382428760537867	0.7388445444635887	0.8156221091581869	0.7957861113670567	0.7321953668507495	0.7602102709260008	0.6821229685191499	0.7036996134732192	0.7379554297842236	0.7271830985915493	0.691484585453457	0.7439887813387146	0.7300891215164804	0.7928986762340715	0.7803215112278726	0.7489833398924308	0.7283309518000907	0.7372905224616251	0.7850625	0.7492216055232165	0.7539645366343258	0.7244738339021616	0.6922993688007214	0.7046889253785805	0.7173851590106007	0.6670209938878554	0.732603845745246	0.6428260955466867	0.7801259273112648	0.7443547283426851	0.7638747746271103	0.7141095393543707	0.7500165683610577	0.7358406625372164	0.7588564533967892	0.7546197107659347	0.6812471621008022	0.735510705032047	0.7318997689710325	0.7695588431294149	0.7266402282056634	0.7367200818274804	0.6921142180795976	0.7830092118730808	0.7195598668017953	0.6897585844954266	0.7433920704845814	0.6978284873021715	0.7394911694839398	0.780747983998984	0.7100003627262504	0.7305300874697017	0.714234286125711	0.6753610040069554	0.7517697342059569	0.7217615098655991	0.7385725185544842	0.771483870967742	0.6978147838417628	0.7706367535466843	0.7152270190472761	0.7503948916148546	0.7234088149153511	0.6897160511990584	0.747111416781293	0.7674269193703823	0.7076821965824449	0.7578049253441924	0.7914267237397222	0.6971899750461105	0.7615057196062782	0.7687004938189772	0.7401477832512315	0.6814691530809094	0.7691555903049258	0.7568538727708278	0.7788231542018816	0.6581044487427467	0.7465042226221792	0.7375277161862528	0.7299439805517387	0.7069204404579597	0.7376191115286539	0.6816932788711474	0.7281066666666667	0.7469937141295436	0.7388776010649478	0.776015145580363	0.7221631582677723	0.6944013016788699	0.7238027920127231	0.7517306909189629	0.7860718445990618	0.7540872166139833	0.7541751731985675	0.7124991015596924	0.7185100938299688	0.7385758002957054	0.7565294077742352	0.7261266939804601	0.785081053698075	0.7013088911872749	0.7536429252349176	0.7784165142409197	0.7242494551079238	0.7595895922746781	0.7607859023698602	0.7410614525139665	0.7673537234042553	0.7262441068622315	0.7915024091108191	0.7373229785290086	0.7296505545093116	0.6923997606223818	0.7542265285666555	0.7314480119072932	0.7209660658616118	0.7647058823529411	0.7136875541438059	0.7423204035484432
valid_loss
tensor(0.4132, device='cuda:0')	tensor(0.4262, device='cuda:0')	tensor(0.5312, device='cuda:0')	tensor(0.7175, device='cuda:0')	tensor(0.6977, device='cuda:0')	tensor(0.7038, device='cuda:0')	tensor(0.6690, device='cuda:0')	tensor(0.9064, device='cuda:0')	tensor(1.0521, device='cuda:0')	tensor(0.9424, device='cuda:0')	tensor(1.4422, device='cuda:0')	tensor(1.3766, device='cuda:0')	tensor(1.4358, device='cuda:0')	tensor(1.0804, device='cuda:0')	tensor(1.2257, device='cuda:0')	tensor(1.1282, device='cuda:0')	tensor(1.4225, device='cuda:0')	tensor(1.1356, device='cuda:0')	tensor(1.4269, device='cuda:0')	tensor(1.4551, device='cuda:0')
Best model metrics: train, valid, test: acc, f1
0.8598785400390625, 0.865902453271028
0.814727783203125, 0.8145863237943988
0.7891845703125, 0.7856788284934226
Model saved, path ./models/resnet_13-1559491145.pth
experiment validation
train set
Evaluation results
[[106818.  24254.]
 [ 12478. 118594.]]
#############################
Accuracy
0.8598785400390625
------------------------
Recall
0.9048004150390625
------------------------
Specificity
0.8149566650390625
------------------------
Precision
0.8302111335125448
------------------------
Fall_out
0.1850433349609375
------------------------
F1
0.865902453271028
------------------------
#############################
valid set
Evaluation results
[[13361.  3038.]
 [ 3033. 13336.]]
#############################
Accuracy
0.814727783203125
------------------------
Recall
0.8147107337039526
------------------------
Specificity
0.8147448015122873
------------------------
Precision
0.8144619518749237
------------------------
Fall_out
0.18525519848771266
------------------------
F1
0.8145863237943988
------------------------
#############################
test set
Evaluation results
[[13198.  3193.]
 [ 3715. 12662.]]
#############################
Accuracy
0.7891845703125
------------------------
Recall
0.7731574769493802
------------------------
Specificity
0.8051979744982002
------------------------
Precision
0.7986124251024913
------------------------
Fall_out
0.19480202550179976
------------------------
F1
0.7856788284934226
------------------------
#############################
AUC: 0.8719719098010048
Experiment end
########################################
----------------------------------------
Starting experiment resnet_14-1559491145
Experiment parameters Experiment[name: resnet_14-1559491145, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 1e-06, weight_decay: 0, batch_size: 32, num_epochs: 20), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-06
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.499542236328125, 0.6662596414107496
train metrics acc, f1
0.5, 0.6666666666666666
Epoch 1/20
----------
eval metrics, batch: 1024 acc, f1
0.74853515625, 0.7449074360720699
eval metrics, batch: 2048 acc, f1
0.748443603515625, 0.7300121188300416
eval metrics, batch: 3072 acc, f1
0.763458251953125, 0.7568771368526709
eval metrics, batch: 4096 acc, f1
0.766265869140625, 0.7531186539019438
train metrics, batch: 4096  acc, f1 
0.8043365478515625, 0.8008093141024147
eval metrics, batch: 5120 acc, f1
0.761260986328125, 0.7402118686281672
eval metrics, batch: 6144 acc, f1
0.77783203125, 0.7796610169491526
eval metrics, batch: 7168 acc, f1
0.773468017578125, 0.7652063893721335
Epoch loss - train: tensor(0.4500, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4691, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.768829345703125, 0.7514519145585196
train metrics acc, f1 
0.8153228759765625, 0.8099462956565434
Epoch 2/20
----------
eval metrics, batch: 1024 acc, f1
0.76544189453125, 0.753716995642143
eval metrics, batch: 2048 acc, f1
0.771728515625, 0.7606859482979268
eval metrics, batch: 3072 acc, f1
0.76953125, 0.7606187396982376
eval metrics, batch: 4096 acc, f1
0.776641845703125, 0.7683494223769584
train metrics, batch: 4096  acc, f1 
0.8211288452148438, 0.8219101080920947
eval metrics, batch: 5120 acc, f1
0.776763916015625, 0.7710700090758301
eval metrics, batch: 6144 acc, f1
0.777984619140625, 0.7663101088946709
eval metrics, batch: 7168 acc, f1
0.76824951171875, 0.7471027041428
Epoch loss - train: tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4616, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7783203125, 0.7682638933197218
train metrics acc, f1 
0.8276329040527344, 0.8273252903388528
Epoch 3/20
----------
eval metrics, batch: 1024 acc, f1
0.7586669921875, 0.7434799532892176
eval metrics, batch: 2048 acc, f1
0.77691650390625, 0.7715910511186101
eval metrics, batch: 3072 acc, f1
0.773193359375, 0.7576310983563788
eval metrics, batch: 4096 acc, f1
0.7757568359375, 0.7617689015691869
train metrics, batch: 4096  acc, f1 
0.8296890258789062, 0.8274297288104147
eval metrics, batch: 5120 acc, f1
0.782318115234375, 0.7753598085220295
eval metrics, batch: 6144 acc, f1
0.773681640625, 0.7541766109785203
eval metrics, batch: 7168 acc, f1
0.777923583984375, 0.7644450199074224
Epoch loss - train: tensor(0.3947, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4818, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.769378662109375, 0.7453240319482358
train metrics acc, f1 
0.8337745666503906, 0.827204701459689
Epoch 4/20
----------
eval metrics, batch: 1024 acc, f1
0.78399658203125, 0.7790472622838235
eval metrics, batch: 2048 acc, f1
0.779388427734375, 0.7701503926743187
eval metrics, batch: 3072 acc, f1
0.779693603515625, 0.7717023497043104
eval metrics, batch: 4096 acc, f1
0.766815185546875, 0.7410795974382434
train metrics, batch: 4096  acc, f1 
0.8365020751953125, 0.8301995927325743
eval metrics, batch: 5120 acc, f1
0.779937744140625, 0.7657473280706883
eval metrics, batch: 6144 acc, f1
0.783294677734375, 0.7753914281195635
eval metrics, batch: 7168 acc, f1
0.78741455078125, 0.7822036018009004
Epoch loss - train: tensor(0.3779, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4667, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.779510498046875, 0.7636803715696857
train metrics acc, f1 
0.8462066650390625, 0.844968275331667
Epoch 5/20
----------
eval metrics, batch: 1024 acc, f1
0.78570556640625, 0.7789321244175796
eval metrics, batch: 2048 acc, f1
0.778717041015625, 0.7629849965678424
eval metrics, batch: 3072 acc, f1
0.7877197265625, 0.7836930157348094
eval metrics, batch: 4096 acc, f1
0.783721923828125, 0.7818512020192693
train metrics, batch: 4096  acc, f1 
0.847015380859375, 0.8531354827369007
eval metrics, batch: 5120 acc, f1
0.773345947265625, 0.7505457965270547
eval metrics, batch: 6144 acc, f1
0.77532958984375, 0.7569494882799603
eval metrics, batch: 7168 acc, f1
0.7867431640625, 0.7884859858344936
Epoch loss - train: tensor(0.3631, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4604, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.77899169921875, 0.7613838550247117
train metrics acc, f1 
0.8549728393554688, 0.8540923081646594
Epoch 6/20
----------
eval metrics, batch: 1024 acc, f1
0.7713623046875, 0.7515585621435203
eval metrics, batch: 2048 acc, f1
0.78045654296875, 0.7654385392892077
eval metrics, batch: 3072 acc, f1
0.776611328125, 0.7577763070814031
eval metrics, batch: 4096 acc, f1
0.779510498046875, 0.7628426062694896
train metrics, batch: 4096  acc, f1 
0.8584098815917969, 0.8576905823578803
eval metrics, batch: 5120 acc, f1
0.78045654296875, 0.7689342840624398
eval metrics, batch: 6144 acc, f1
0.78240966796875, 0.7678583056586573
eval metrics, batch: 7168 acc, f1
0.788604736328125, 0.7843332606868209
Epoch loss - train: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4551, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7822265625, 0.7698806836504354
train metrics acc, f1 
0.8637275695800781, 0.8654698556520888
Epoch 7/20
----------
eval metrics, batch: 1024 acc, f1
0.774932861328125, 0.7552679608428737
eval metrics, batch: 2048 acc, f1
0.779205322265625, 0.7617008662428774
eval metrics, batch: 3072 acc, f1
0.76495361328125, 0.7329588794119687
eval metrics, batch: 4096 acc, f1
0.765289306640625, 0.7368709158712238
train metrics, batch: 4096  acc, f1 
0.8619499206542969, 0.8582319043832193
eval metrics, batch: 5120 acc, f1
0.777069091796875, 0.7566379051870606
eval metrics, batch: 6144 acc, f1
0.7802734375, 0.7689196995956095
eval metrics, batch: 7168 acc, f1
0.786468505859375, 0.7878732757313931
Epoch loss - train: tensor(0.3353, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4705, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.780059814453125, 0.7695308752518307
train metrics acc, f1 
0.8696212768554688, 0.8726317358574942
Epoch 8/20
----------
eval metrics, batch: 1024 acc, f1
0.78228759765625, 0.768796992481203
eval metrics, batch: 2048 acc, f1
0.781646728515625, 0.7664588569376897
eval metrics, batch: 3072 acc, f1
0.768951416015625, 0.7411535437108961
eval metrics, batch: 4096 acc, f1
0.775238037109375, 0.7577382322949903
train metrics, batch: 4096  acc, f1 
0.8731269836425781, 0.8737650349756518
eval metrics, batch: 5120 acc, f1
0.770599365234375, 0.7464156799244341
eval metrics, batch: 6144 acc, f1
0.779571533203125, 0.7666160457526899
eval metrics, batch: 7168 acc, f1
0.776031494140625, 0.758609347761734
Epoch loss - train: tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4818, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.774810791015625, 0.7581844994265116
train metrics acc, f1 
0.8770637512207031, 0.8783018832299262
Epoch 9/20
----------
eval metrics, batch: 1024 acc, f1
0.779510498046875, 0.7629048666032225
eval metrics, batch: 2048 acc, f1
0.775146484375, 0.7554596747427813
eval metrics, batch: 3072 acc, f1
0.7822265625, 0.7690913797566657
eval metrics, batch: 4096 acc, f1
0.776275634765625, 0.7572114588508031
train metrics, batch: 4096  acc, f1 
0.8777618408203125, 0.8781170599601381
eval metrics, batch: 5120 acc, f1
0.77593994140625, 0.7566134058211231
eval metrics, batch: 6144 acc, f1
0.77587890625, 0.7543976991505585
eval metrics, batch: 7168 acc, f1
0.783721923828125, 0.7871452169995495
Epoch loss - train: tensor(0.3117, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4591, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.786773681640625, 0.7815948235441218
train metrics acc, f1 
0.8778724670410156, 0.8824900438620639
Epoch 10/20
----------
eval metrics, batch: 1024 acc, f1
0.780517578125, 0.7667661175249708
eval metrics, batch: 2048 acc, f1
0.78265380859375, 0.7703469624661421
eval metrics, batch: 3072 acc, f1
0.77740478515625, 0.7632279426085827
eval metrics, batch: 4096 acc, f1
0.76971435546875, 0.749385586183992
train metrics, batch: 4096  acc, f1 
0.8832168579101562, 0.8838909832894647
eval metrics, batch: 5120 acc, f1
0.77685546875, 0.7564290473017988
eval metrics, batch: 6144 acc, f1
0.766845703125, 0.7373487348734874
eval metrics, batch: 7168 acc, f1
0.773162841796875, 0.7525385358058395
Epoch loss - train: tensor(0.3010, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5220, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.768646240234375, 0.7512876874118303
train metrics acc, f1 
0.8832206726074219, 0.8852977432734712
Epoch 11/20
----------
eval metrics, batch: 1024 acc, f1
0.778778076171875, 0.7584391349261889
eval metrics, batch: 2048 acc, f1
0.766082763671875, 0.7376347766558274
eval metrics, batch: 3072 acc, f1
0.7816162109375, 0.7683092663342614
eval metrics, batch: 4096 acc, f1
0.774200439453125, 0.7541615443399674
train metrics, batch: 4096  acc, f1 
0.8888130187988281, 0.8893343812528713
eval metrics, batch: 5120 acc, f1
0.780517578125, 0.7702530028111424
eval metrics, batch: 6144 acc, f1
0.784149169921875, 0.7844451894066377
eval metrics, batch: 7168 acc, f1
0.775604248046875, 0.7566923662353993
Epoch loss - train: tensor(0.2900, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4926, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.77825927734375, 0.765279751905931
train metrics acc, f1 
0.8917808532714844, 0.8943682162604956
Epoch 12/20
----------
eval metrics, batch: 1024 acc, f1
0.773529052734375, 0.7561688845079678
eval metrics, batch: 2048 acc, f1
0.779327392578125, 0.7642552081635314
eval metrics, batch: 3072 acc, f1
0.781402587890625, 0.7735162993644671
eval metrics, batch: 4096 acc, f1
0.783660888671875, 0.7831513260530422
train metrics, batch: 4096  acc, f1 
0.8831520080566406, 0.8896899679848459
eval metrics, batch: 5120 acc, f1
0.77142333984375, 0.7479472338134339
eval metrics, batch: 6144 acc, f1
0.76275634765625, 0.7364924411904278
eval metrics, batch: 7168 acc, f1
0.778564453125, 0.7668230606080082
Epoch loss - train: tensor(0.2805, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4984, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.78277587890625, 0.7684751496226906
train metrics acc, f1 
0.8961753845214844, 0.8978965572866452
Epoch 13/20
----------
eval metrics, batch: 1024 acc, f1
0.780364990234375, 0.7677712884385789
eval metrics, batch: 2048 acc, f1
0.7674560546875, 0.7362591720891596
eval metrics, batch: 3072 acc, f1
0.76910400390625, 0.7466514867398875
eval metrics, batch: 4096 acc, f1
0.776123046875, 0.760574412532637
train metrics, batch: 4096  acc, f1 
0.8979759216308594, 0.9001228625097561
eval metrics, batch: 5120 acc, f1
0.7738037109375, 0.7533608412085718
eval metrics, batch: 6144 acc, f1
0.780548095703125, 0.7800177429716418
eval metrics, batch: 7168 acc, f1
0.771270751953125, 0.7481941878044683
Epoch loss - train: tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5477, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.76788330078125, 0.7391453460456822
train metrics acc, f1 
0.9028244018554688, 0.9014507331037951
Epoch 14/20
----------
eval metrics, batch: 1024 acc, f1
0.77880859375, 0.7597135658400742
eval metrics, batch: 2048 acc, f1
0.773406982421875, 0.7569637655068574
eval metrics, batch: 3072 acc, f1
0.76885986328125, 0.7431497558328811
eval metrics, batch: 4096 acc, f1
0.768310546875, 0.744738080828458
train metrics, batch: 4096  acc, f1 
0.9050636291503906, 0.9052533797288603
eval metrics, batch: 5120 acc, f1
0.77764892578125, 0.7577148177706837
eval metrics, batch: 6144 acc, f1
0.77813720703125, 0.7657558963783992
eval metrics, batch: 7168 acc, f1
0.7603759765625, 0.7264302139223747
Epoch loss - train: tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5685, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.769256591796875, 0.7424113378530304
train metrics acc, f1 
0.9073753356933594, 0.9066700491614872
Epoch 15/20
----------
eval metrics, batch: 1024 acc, f1
0.77825927734375, 0.7663214768122467
eval metrics, batch: 2048 acc, f1
0.775665283203125, 0.7563877381938691
eval metrics, batch: 3072 acc, f1
0.785369873046875, 0.7793845478214498
eval metrics, batch: 4096 acc, f1
0.75, 0.7057893980749892
train metrics, batch: 4096  acc, f1 
0.9017715454101562, 0.8978450259453798
eval metrics, batch: 5120 acc, f1
0.77801513671875, 0.7709986147840322
eval metrics, batch: 6144 acc, f1
0.758087158203125, 0.7251291653663442
eval metrics, batch: 7168 acc, f1
0.77392578125, 0.753641503159295
Epoch loss - train: tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6207, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.75408935546875, 0.7136257018977895
train metrics acc, f1 
0.9070549011230469, 0.9037971784717315
Epoch 16/20
----------
eval metrics, batch: 1024 acc, f1
0.764251708984375, 0.7381622207911059
eval metrics, batch: 2048 acc, f1
0.753173828125, 0.7141443415565137
eval metrics, batch: 3072 acc, f1
0.7659912109375, 0.7382220401474805
eval metrics, batch: 4096 acc, f1
0.772064208984375, 0.7565753022846528
train metrics, batch: 4096  acc, f1 
0.9120368957519531, 0.9139367971604629
eval metrics, batch: 5120 acc, f1
0.771453857421875, 0.7499248672655023
eval metrics, batch: 6144 acc, f1
0.778289794921875, 0.7670055482505372
eval metrics, batch: 7168 acc, f1
0.76654052734375, 0.7415191242059738
Epoch loss - train: tensor(0.2395, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5503, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.77557373046875, 0.7602842427798422
train metrics acc, f1 
0.9185104370117188, 0.9200595754872317
Epoch 17/20
----------
eval metrics, batch: 1024 acc, f1
0.778472900390625, 0.7628630230962726
eval metrics, batch: 2048 acc, f1
0.77239990234375, 0.7603624445729709
eval metrics, batch: 3072 acc, f1
0.772186279296875, 0.7491009309985548
eval metrics, batch: 4096 acc, f1
0.780853271484375, 0.768377253814147
train metrics, batch: 4096  acc, f1 
0.9166450500488281, 0.9184046124489819
eval metrics, batch: 5120 acc, f1
0.769134521484375, 0.7443306634222178
eval metrics, batch: 6144 acc, f1
0.7725830078125, 0.7500167728950017
eval metrics, batch: 7168 acc, f1
0.755859375, 0.7172745264348318
Epoch loss - train: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6265, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.76300048828125, 0.7382717713669452
train metrics acc, f1 
0.9213523864746094, 0.9218819267886982
Epoch 18/20
----------
eval metrics, batch: 1024 acc, f1
0.7650146484375, 0.7373985403451333
eval metrics, batch: 2048 acc, f1
0.76495361328125, 0.7337711717939854
eval metrics, batch: 3072 acc, f1
0.77313232421875, 0.7564379791625713
eval metrics, batch: 4096 acc, f1
0.770660400390625, 0.7462777271346095
train metrics, batch: 4096  acc, f1 
0.9225921630859375, 0.9223884707178264
eval metrics, batch: 5120 acc, f1
0.7567138671875, 0.7239803337718994
eval metrics, batch: 6144 acc, f1
0.759613037109375, 0.7302859099469269
eval metrics, batch: 7168 acc, f1
0.777557373046875, 0.7628282302411089
Epoch loss - train: tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6316, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.771148681640625, 0.748634062950424
train metrics acc, f1 
0.9249916076660156, 0.9254112943300749
Epoch 19/20
----------
eval metrics, batch: 1024 acc, f1
0.7686767578125, 0.7446951835634894
eval metrics, batch: 2048 acc, f1
0.758148193359375, 0.7267335609116927
eval metrics, batch: 3072 acc, f1
0.773101806640625, 0.753620306856215
eval metrics, batch: 4096 acc, f1
0.777557373046875, 0.7635207474937546
train metrics, batch: 4096  acc, f1 
0.9259719848632812, 0.9275738779288055
eval metrics, batch: 5120 acc, f1
0.77593994140625, 0.7693081128636964
eval metrics, batch: 6144 acc, f1
0.775726318359375, 0.7637357338048545
eval metrics, batch: 7168 acc, f1
0.7664794921875, 0.7406804934255117
Epoch loss - train: tensor(0.2122, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6151, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.76922607421875, 0.7472762515874607
train metrics acc, f1 
0.9328651428222656, 0.9331951609290955
Epoch 20/20
----------
eval metrics, batch: 1024 acc, f1
0.769744873046875, 0.7482734461014914
eval metrics, batch: 2048 acc, f1
0.763336181640625, 0.7311306036126617
eval metrics, batch: 3072 acc, f1
0.780670166015625, 0.7701851437342117
eval metrics, batch: 4096 acc, f1
0.77789306640625, 0.7642065703362924
train metrics, batch: 4096  acc, f1 
0.9313926696777344, 0.9328865321536389
eval metrics, batch: 5120 acc, f1
0.7552490234375, 0.7186359809149593
eval metrics, batch: 6144 acc, f1
0.742584228515625, 0.6941069809610154
eval metrics, batch: 7168 acc, f1
0.745391845703125, 0.6999892121255709
Epoch loss - train: tensor(0.2013, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6078, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.775054931640625, 0.7594085582792048
train metrics acc, f1 
0.9363632202148438, 0.9375687671684019
Training time 506m 16s
train_acc
0.5	0.8043365478515625	0.8153228759765625	0.8211288452148438	0.8276329040527344	0.8296890258789062	0.8337745666503906	0.8365020751953125	0.8462066650390625	0.847015380859375	0.8549728393554688	0.8584098815917969	0.8637275695800781	0.8619499206542969	0.8696212768554688	0.8731269836425781	0.8770637512207031	0.8777618408203125	0.8778724670410156	0.8832168579101562	0.8832206726074219	0.8888130187988281	0.8917808532714844	0.8831520080566406	0.8961753845214844	0.8979759216308594	0.9028244018554688	0.9050636291503906	0.9073753356933594	0.9017715454101562	0.9070549011230469	0.9120368957519531	0.9185104370117188	0.9166450500488281	0.9213523864746094	0.9225921630859375	0.9249916076660156	0.9259719848632812	0.9328651428222656	0.9313926696777344	0.9363632202148438
train_f1
0.6666666666666666	0.8008093141024147	0.8099462956565434	0.8219101080920947	0.8273252903388528	0.8274297288104147	0.827204701459689	0.8301995927325743	0.844968275331667	0.8531354827369007	0.8540923081646594	0.8576905823578803	0.8654698556520888	0.8582319043832193	0.8726317358574942	0.8737650349756518	0.8783018832299262	0.8781170599601381	0.8824900438620639	0.8838909832894647	0.8852977432734712	0.8893343812528713	0.8943682162604956	0.8896899679848459	0.8978965572866452	0.9001228625097561	0.9014507331037951	0.9052533797288603	0.9066700491614872	0.8978450259453798	0.9037971784717315	0.9139367971604629	0.9200595754872317	0.9184046124489819	0.9218819267886982	0.9223884707178264	0.9254112943300749	0.9275738779288055	0.9331951609290955	0.9328865321536389	0.9375687671684019
train_loss
tensor(0.4500, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3947, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3779, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3631, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3353, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3117, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3010, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2900, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2805, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2395, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2218, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2122, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2013, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.499542236328125	0.74853515625	0.748443603515625	0.763458251953125	0.766265869140625	0.761260986328125	0.77783203125	0.773468017578125	0.768829345703125	0.76544189453125	0.771728515625	0.76953125	0.776641845703125	0.776763916015625	0.777984619140625	0.76824951171875	0.7783203125	0.7586669921875	0.77691650390625	0.773193359375	0.7757568359375	0.782318115234375	0.773681640625	0.777923583984375	0.769378662109375	0.78399658203125	0.779388427734375	0.779693603515625	0.766815185546875	0.779937744140625	0.783294677734375	0.78741455078125	0.779510498046875	0.78570556640625	0.778717041015625	0.7877197265625	0.783721923828125	0.773345947265625	0.77532958984375	0.7867431640625	0.77899169921875	0.7713623046875	0.78045654296875	0.776611328125	0.779510498046875	0.78045654296875	0.78240966796875	0.788604736328125	0.7822265625	0.774932861328125	0.779205322265625	0.76495361328125	0.765289306640625	0.777069091796875	0.7802734375	0.786468505859375	0.780059814453125	0.78228759765625	0.781646728515625	0.768951416015625	0.775238037109375	0.770599365234375	0.779571533203125	0.776031494140625	0.774810791015625	0.779510498046875	0.775146484375	0.7822265625	0.776275634765625	0.77593994140625	0.77587890625	0.783721923828125	0.786773681640625	0.780517578125	0.78265380859375	0.77740478515625	0.76971435546875	0.77685546875	0.766845703125	0.773162841796875	0.768646240234375	0.778778076171875	0.766082763671875	0.7816162109375	0.774200439453125	0.780517578125	0.784149169921875	0.775604248046875	0.77825927734375	0.773529052734375	0.779327392578125	0.781402587890625	0.783660888671875	0.77142333984375	0.76275634765625	0.778564453125	0.78277587890625	0.780364990234375	0.7674560546875	0.76910400390625	0.776123046875	0.7738037109375	0.780548095703125	0.771270751953125	0.76788330078125	0.77880859375	0.773406982421875	0.76885986328125	0.768310546875	0.77764892578125	0.77813720703125	0.7603759765625	0.769256591796875	0.77825927734375	0.775665283203125	0.785369873046875	0.75	0.77801513671875	0.758087158203125	0.77392578125	0.75408935546875	0.764251708984375	0.753173828125	0.7659912109375	0.772064208984375	0.771453857421875	0.778289794921875	0.76654052734375	0.77557373046875	0.778472900390625	0.77239990234375	0.772186279296875	0.780853271484375	0.769134521484375	0.7725830078125	0.755859375	0.76300048828125	0.7650146484375	0.76495361328125	0.77313232421875	0.770660400390625	0.7567138671875	0.759613037109375	0.777557373046875	0.771148681640625	0.7686767578125	0.758148193359375	0.773101806640625	0.777557373046875	0.77593994140625	0.775726318359375	0.7664794921875	0.76922607421875	0.769744873046875	0.763336181640625	0.780670166015625	0.77789306640625	0.7552490234375	0.742584228515625	0.745391845703125	0.775054931640625
valid_f1
0.6662596414107496	0.7449074360720699	0.7300121188300416	0.7568771368526709	0.7531186539019438	0.7402118686281672	0.7796610169491526	0.7652063893721335	0.7514519145585196	0.753716995642143	0.7606859482979268	0.7606187396982376	0.7683494223769584	0.7710700090758301	0.7663101088946709	0.7471027041428	0.7682638933197218	0.7434799532892176	0.7715910511186101	0.7576310983563788	0.7617689015691869	0.7753598085220295	0.7541766109785203	0.7644450199074224	0.7453240319482358	0.7790472622838235	0.7701503926743187	0.7717023497043104	0.7410795974382434	0.7657473280706883	0.7753914281195635	0.7822036018009004	0.7636803715696857	0.7789321244175796	0.7629849965678424	0.7836930157348094	0.7818512020192693	0.7505457965270547	0.7569494882799603	0.7884859858344936	0.7613838550247117	0.7515585621435203	0.7654385392892077	0.7577763070814031	0.7628426062694896	0.7689342840624398	0.7678583056586573	0.7843332606868209	0.7698806836504354	0.7552679608428737	0.7617008662428774	0.7329588794119687	0.7368709158712238	0.7566379051870606	0.7689196995956095	0.7878732757313931	0.7695308752518307	0.768796992481203	0.7664588569376897	0.7411535437108961	0.7577382322949903	0.7464156799244341	0.7666160457526899	0.758609347761734	0.7581844994265116	0.7629048666032225	0.7554596747427813	0.7690913797566657	0.7572114588508031	0.7566134058211231	0.7543976991505585	0.7871452169995495	0.7815948235441218	0.7667661175249708	0.7703469624661421	0.7632279426085827	0.749385586183992	0.7564290473017988	0.7373487348734874	0.7525385358058395	0.7512876874118303	0.7584391349261889	0.7376347766558274	0.7683092663342614	0.7541615443399674	0.7702530028111424	0.7844451894066377	0.7566923662353993	0.765279751905931	0.7561688845079678	0.7642552081635314	0.7735162993644671	0.7831513260530422	0.7479472338134339	0.7364924411904278	0.7668230606080082	0.7684751496226906	0.7677712884385789	0.7362591720891596	0.7466514867398875	0.760574412532637	0.7533608412085718	0.7800177429716418	0.7481941878044683	0.7391453460456822	0.7597135658400742	0.7569637655068574	0.7431497558328811	0.744738080828458	0.7577148177706837	0.7657558963783992	0.7264302139223747	0.7424113378530304	0.7663214768122467	0.7563877381938691	0.7793845478214498	0.7057893980749892	0.7709986147840322	0.7251291653663442	0.753641503159295	0.7136257018977895	0.7381622207911059	0.7141443415565137	0.7382220401474805	0.7565753022846528	0.7499248672655023	0.7670055482505372	0.7415191242059738	0.7602842427798422	0.7628630230962726	0.7603624445729709	0.7491009309985548	0.768377253814147	0.7443306634222178	0.7500167728950017	0.7172745264348318	0.7382717713669452	0.7373985403451333	0.7337711717939854	0.7564379791625713	0.7462777271346095	0.7239803337718994	0.7302859099469269	0.7628282302411089	0.748634062950424	0.7446951835634894	0.7267335609116927	0.753620306856215	0.7635207474937546	0.7693081128636964	0.7637357338048545	0.7406804934255117	0.7472762515874607	0.7482734461014914	0.7311306036126617	0.7701851437342117	0.7642065703362924	0.7186359809149593	0.6941069809610154	0.6999892121255709	0.7594085582792048
valid_loss
tensor(0.4691, device='cuda:0')	tensor(0.4616, device='cuda:0')	tensor(0.4818, device='cuda:0')	tensor(0.4667, device='cuda:0')	tensor(0.4604, device='cuda:0')	tensor(0.4551, device='cuda:0')	tensor(0.4705, device='cuda:0')	tensor(0.4818, device='cuda:0')	tensor(0.4591, device='cuda:0')	tensor(0.5220, device='cuda:0')	tensor(0.4926, device='cuda:0')	tensor(0.4984, device='cuda:0')	tensor(0.5477, device='cuda:0')	tensor(0.5685, device='cuda:0')	tensor(0.6207, device='cuda:0')	tensor(0.5503, device='cuda:0')	tensor(0.6265, device='cuda:0')	tensor(0.6316, device='cuda:0')	tensor(0.6151, device='cuda:0')	tensor(0.6078, device='cuda:0')
Best model metrics: train, valid, test: acc, f1
0.8778724670410156, 0.8824900438620639
0.786773681640625, 0.7815948235441218
0.76129150390625, 0.7492144918243027
Model saved, path ./models/resnet_14-1559491145.pth
experiment validation
train set
Evaluation results
[[109914.  21158.]
 [ 10857. 120215.]]
#############################
Accuracy
0.8778724670410156
------------------------
Recall
0.9171676635742188
------------------------
Specificity
0.8385772705078125
------------------------
Precision
0.8503391736753129
------------------------
Fall_out
0.1614227294921875
------------------------
F1
0.8824900438620639
------------------------
#############################
valid set
Evaluation results
[[13279.  3120.]
 [ 3867. 12502.]]
#############################
Accuracy
0.786773681640625
------------------------
Recall
0.7637607673040503
------------------------
Specificity
0.8097444966156473
------------------------
Precision
0.8002816540775829
------------------------
Fall_out
0.1902555033843527
------------------------
F1
0.7815948235441218
------------------------
#############################
test set
Evaluation results
[[13262.  3129.]
 [ 4693. 11684.]]
#############################
Accuracy
0.76129150390625
------------------------
Recall
0.7134395798986384
------------------------
Specificity
0.8091025562808859
------------------------
Precision
0.7887666239114292
------------------------
Fall_out
0.19089744371911416
------------------------
F1
0.7492144918243027
------------------------
#############################
AUC: 0.8381587623424059
Experiment end
########################################
----------------------------------------
Starting experiment alexnet_11-1559491145
Experiment parameters Experiment[name: alexnet_11-1559491145, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 0.001, weight_decay: 0, batch_size: 32, num_epochs: 20), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.500457763671875, 0.0
train metrics acc, f1
0.5, 0.0
Epoch 1/20
----------
eval metrics, batch: 1024 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 2048 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 3072 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 4096 acc, f1
0.500457763671875, 0.0
train metrics, batch: 4096  acc, f1 
0.5, 0.0
eval metrics, batch: 5120 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 6144 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 7168 acc, f1
0.500457763671875, 0.0
Epoch loss - train: tensor(0.6936, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.500457763671875, 0.0
train metrics acc, f1 
0.5, 0.0
Epoch 2/20
----------
eval metrics, batch: 1024 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 2048 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 3072 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 4096 acc, f1
0.499542236328125, 0.6662596414107496
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 6144 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 7168 acc, f1
0.500457763671875, 0.0
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6933, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.499542236328125, 0.6662596414107496
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 3/20
----------
eval metrics, batch: 1024 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 2048 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 3072 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 4096 acc, f1
0.500457763671875, 0.0
train metrics, batch: 4096  acc, f1 
0.5, 0.0
eval metrics, batch: 5120 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 6144 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 7168 acc, f1
0.499542236328125, 0.6662596414107496
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.500457763671875, 0.0
train metrics acc, f1 
0.5, 0.0
Epoch 4/20
----------
eval metrics, batch: 1024 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 2048 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 3072 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 4096 acc, f1
0.500457763671875, 0.0
train metrics, batch: 4096  acc, f1 
0.5, 0.0
eval metrics, batch: 5120 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 6144 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 7168 acc, f1
0.499542236328125, 0.6662596414107496
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.499542236328125, 0.6662596414107496
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 5/20
----------
eval metrics, batch: 1024 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 2048 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 3072 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 4096 acc, f1
0.499542236328125, 0.6662596414107496
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 6144 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 7168 acc, f1
0.500457763671875, 0.0
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.500457763671875, 0.0
train metrics acc, f1 
0.5, 0.0
Epoch 6/20
----------
eval metrics, batch: 1024 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 2048 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 3072 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 4096 acc, f1
0.499542236328125, 0.6662596414107496
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 6144 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 7168 acc, f1
0.500457763671875, 0.0
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.500457763671875, 0.0
train metrics acc, f1 
0.5, 0.0
Epoch 7/20
----------
eval metrics, batch: 1024 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 2048 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 3072 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 4096 acc, f1
0.500457763671875, 0.0
train metrics, batch: 4096  acc, f1 
0.5, 0.0
eval metrics, batch: 5120 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 6144 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 7168 acc, f1
0.500457763671875, 0.0
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6931, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.499542236328125, 0.6662596414107496
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 8/20
----------
eval metrics, batch: 1024 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 2048 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 3072 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 4096 acc, f1
0.499542236328125, 0.6662596414107496
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 6144 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 7168 acc, f1
0.499542236328125, 0.6662596414107496
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.500457763671875, 0.0
train metrics acc, f1 
0.5, 0.0
Epoch 9/20
----------
eval metrics, batch: 1024 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 2048 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 3072 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 4096 acc, f1
0.500457763671875, 0.0
train metrics, batch: 4096  acc, f1 
0.5, 0.0
eval metrics, batch: 5120 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 6144 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 7168 acc, f1
0.499542236328125, 0.6662596414107496
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.500457763671875, 0.0
train metrics acc, f1 
0.5, 0.0
Epoch 10/20
----------
eval metrics, batch: 1024 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 2048 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 3072 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 4096 acc, f1
0.499542236328125, 0.6662596414107496
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 6144 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 7168 acc, f1
0.500457763671875, 0.0
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.499542236328125, 0.6662596414107496
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 11/20
----------
eval metrics, batch: 1024 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 2048 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 3072 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 4096 acc, f1
0.500457763671875, 0.0
train metrics, batch: 4096  acc, f1 
0.5, 0.0
eval metrics, batch: 5120 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 6144 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 7168 acc, f1
0.499542236328125, 0.6662596414107496
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6931, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.499542236328125, 0.6662596414107496
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 12/20
----------
eval metrics, batch: 1024 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 2048 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 3072 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 4096 acc, f1
0.500457763671875, 0.0
train metrics, batch: 4096  acc, f1 
0.5, 0.0
eval metrics, batch: 5120 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 6144 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 7168 acc, f1
0.499542236328125, 0.6662596414107496
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.499542236328125, 0.6662596414107496
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 13/20
----------
eval metrics, batch: 1024 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 2048 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 3072 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 4096 acc, f1
0.500457763671875, 0.0
train metrics, batch: 4096  acc, f1 
0.5, 0.0
eval metrics, batch: 5120 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 6144 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 7168 acc, f1
0.500457763671875, 0.0
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.499542236328125, 0.6662596414107496
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 14/20
----------
eval metrics, batch: 1024 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 2048 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 3072 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 4096 acc, f1
0.500457763671875, 0.0
train metrics, batch: 4096  acc, f1 
0.5, 0.0
eval metrics, batch: 5120 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 6144 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 7168 acc, f1
0.499542236328125, 0.6662596414107496
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.499542236328125, 0.6662596414107496
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 15/20
----------
eval metrics, batch: 1024 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 2048 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 3072 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 4096 acc, f1
0.499542236328125, 0.6662596414107496
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 6144 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 7168 acc, f1
0.499542236328125, 0.6662596414107496
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6933, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.499542236328125, 0.6662596414107496
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 16/20
----------
eval metrics, batch: 1024 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 2048 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 3072 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 4096 acc, f1
0.500457763671875, 0.0
train metrics, batch: 4096  acc, f1 
0.5, 0.0
eval metrics, batch: 5120 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 6144 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 7168 acc, f1
0.500457763671875, 0.0
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.499542236328125, 0.6662596414107496
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 17/20
----------
eval metrics, batch: 1024 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 2048 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 3072 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 4096 acc, f1
0.499542236328125, 0.6662596414107496
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 6144 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 7168 acc, f1
0.499542236328125, 0.6662596414107496
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.500457763671875, 0.0
train metrics acc, f1 
0.5, 0.0
Epoch 18/20
----------
eval metrics, batch: 1024 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 2048 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 3072 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 4096 acc, f1
0.500457763671875, 0.0
train metrics, batch: 4096  acc, f1 
0.5, 0.0
eval metrics, batch: 5120 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 6144 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 7168 acc, f1
0.499542236328125, 0.6662596414107496
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.499542236328125, 0.6662596414107496
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 19/20
----------
eval metrics, batch: 1024 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 2048 acc, f1
0.499542236328125, 0.6662596414107496
eval metrics, batch: 3072 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 4096 acc, f1
0.500457763671875, 0.0
train metrics, batch: 4096  acc, f1 
0.5, 0.0
eval metrics, batch: 5120 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 6144 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 7168 acc, f1
0.499542236328125, 0.6662596414107496
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.499542236328125, 0.6662596414107496
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 20/20
----------
eval metrics, batch: 1024 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 2048 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 3072 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 4096 acc, f1
0.499542236328125, 0.6662596414107496
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 6144 acc, f1
0.500457763671875, 0.0
eval metrics, batch: 7168 acc, f1
0.500457763671875, 0.0
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.499542236328125, 0.6662596414107496
train metrics acc, f1 
0.5, 0.6666666666666666
Training time 454m 46s
train_acc
0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5	0.5
train_f1
0.0	0.0	0.0	0.6666666666666666	0.6666666666666666	0.0	0.0	0.0	0.6666666666666666	0.6666666666666666	0.0	0.6666666666666666	0.0	0.0	0.6666666666666666	0.6666666666666666	0.0	0.0	0.0	0.6666666666666666	0.6666666666666666	0.0	0.6666666666666666	0.0	0.6666666666666666	0.0	0.6666666666666666	0.0	0.6666666666666666	0.6666666666666666	0.6666666666666666	0.0	0.6666666666666666	0.6666666666666666	0.0	0.0	0.6666666666666666	0.0	0.6666666666666666	0.6666666666666666	0.6666666666666666
train_loss
tensor(0.6936, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.500457763671875	0.499542236328125	0.499542236328125	0.499542236328125	0.500457763671875	0.500457763671875	0.500457763671875	0.500457763671875	0.500457763671875	0.500457763671875	0.499542236328125	0.500457763671875	0.499542236328125	0.499542236328125	0.499542236328125	0.500457763671875	0.499542236328125	0.499542236328125	0.499542236328125	0.500457763671875	0.500457763671875	0.500457763671875	0.499542236328125	0.499542236328125	0.500457763671875	0.499542236328125	0.499542236328125	0.499542236328125	0.500457763671875	0.500457763671875	0.499542236328125	0.499542236328125	0.499542236328125	0.499542236328125	0.499542236328125	0.499542236328125	0.499542236328125	0.500457763671875	0.499542236328125	0.500457763671875	0.500457763671875	0.499542236328125	0.500457763671875	0.500457763671875	0.499542236328125	0.500457763671875	0.500457763671875	0.500457763671875	0.500457763671875	0.499542236328125	0.500457763671875	0.499542236328125	0.500457763671875	0.500457763671875	0.500457763671875	0.500457763671875	0.499542236328125	0.499542236328125	0.499542236328125	0.500457763671875	0.499542236328125	0.500457763671875	0.500457763671875	0.499542236328125	0.500457763671875	0.500457763671875	0.500457763671875	0.500457763671875	0.500457763671875	0.499542236328125	0.499542236328125	0.499542236328125	0.500457763671875	0.499542236328125	0.499542236328125	0.500457763671875	0.499542236328125	0.499542236328125	0.499542236328125	0.500457763671875	0.499542236328125	0.499542236328125	0.499542236328125	0.499542236328125	0.500457763671875	0.500457763671875	0.499542236328125	0.499542236328125	0.499542236328125	0.500457763671875	0.499542236328125	0.500457763671875	0.500457763671875	0.500457763671875	0.500457763671875	0.499542236328125	0.499542236328125	0.499542236328125	0.499542236328125	0.500457763671875	0.500457763671875	0.500457763671875	0.499542236328125	0.500457763671875	0.499542236328125	0.499542236328125	0.499542236328125	0.499542236328125	0.500457763671875	0.500457763671875	0.500457763671875	0.499542236328125	0.499542236328125	0.499542236328125	0.500457763671875	0.499542236328125	0.499542236328125	0.500457763671875	0.500457763671875	0.499542236328125	0.499542236328125	0.500457763671875	0.499542236328125	0.500457763671875	0.500457763671875	0.500457763671875	0.500457763671875	0.500457763671875	0.499542236328125	0.500457763671875	0.499542236328125	0.499542236328125	0.499542236328125	0.500457763671875	0.499542236328125	0.499542236328125	0.500457763671875	0.500457763671875	0.500457763671875	0.500457763671875	0.500457763671875	0.499542236328125	0.500457763671875	0.499542236328125	0.499542236328125	0.499542236328125	0.499542236328125	0.500457763671875	0.500457763671875	0.500457763671875	0.500457763671875	0.499542236328125	0.499542236328125	0.500457763671875	0.500457763671875	0.500457763671875	0.499542236328125	0.500457763671875	0.500457763671875	0.500457763671875	0.499542236328125
valid_f1
0.0	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.0	0.0	0.0	0.0	0.0	0.0	0.6662596414107496	0.0	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.0	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.0	0.0	0.0	0.6662596414107496	0.6662596414107496	0.0	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.0	0.0	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.0	0.6662596414107496	0.0	0.0	0.6662596414107496	0.0	0.0	0.6662596414107496	0.0	0.0	0.0	0.0	0.6662596414107496	0.0	0.6662596414107496	0.0	0.0	0.0	0.0	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.0	0.6662596414107496	0.0	0.0	0.6662596414107496	0.0	0.0	0.0	0.0	0.0	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.0	0.6662596414107496	0.6662596414107496	0.0	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.0	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.0	0.0	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.0	0.6662596414107496	0.0	0.0	0.0	0.0	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.0	0.0	0.0	0.6662596414107496	0.0	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.0	0.0	0.0	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.0	0.6662596414107496	0.6662596414107496	0.0	0.0	0.6662596414107496	0.6662596414107496	0.0	0.6662596414107496	0.0	0.0	0.0	0.0	0.0	0.6662596414107496	0.0	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.0	0.6662596414107496	0.6662596414107496	0.0	0.0	0.0	0.0	0.0	0.6662596414107496	0.0	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.6662596414107496	0.0	0.0	0.0	0.0	0.6662596414107496	0.6662596414107496	0.0	0.0	0.0	0.6662596414107496	0.0	0.0	0.0	0.6662596414107496
valid_loss
tensor(0.6932, device='cuda:0')	tensor(0.6933, device='cuda:0')	tensor(0.6932, device='cuda:0')	tensor(0.6932, device='cuda:0')	tensor(0.6932, device='cuda:0')	tensor(0.6932, device='cuda:0')	tensor(0.6931, device='cuda:0')	tensor(0.6932, device='cuda:0')	tensor(0.6932, device='cuda:0')	tensor(0.6932, device='cuda:0')	tensor(0.6931, device='cuda:0')	tensor(0.6932, device='cuda:0')	tensor(0.6932, device='cuda:0')	tensor(0.6932, device='cuda:0')	tensor(0.6933, device='cuda:0')	tensor(0.6932, device='cuda:0')	tensor(0.6932, device='cuda:0')	tensor(0.6932, device='cuda:0')	tensor(0.6932, device='cuda:0')	tensor(0.6932, device='cuda:0')
Best model metrics: train, valid, test: acc, f1
0.5, 0.6666666666666666
0.499542236328125, 0.6662596414107496
0.499786376953125, 0.666476752467189
Model saved, path ./models/alexnet_11-1559491145.pth
experiment validation
train set
Evaluation results
[[     0. 131072.]
 [     0. 131072.]]
#############################
Accuracy
0.5
------------------------
Recall
1.0
------------------------
Specificity
0.0
------------------------
Precision
0.5
------------------------
Fall_out
1.0
------------------------
F1
0.6666666666666666
------------------------
#############################
valid set
Evaluation results
[[    0. 16399.]
 [    0. 16369.]]
#############################
Accuracy
0.499542236328125
------------------------
Recall
1.0
------------------------
Specificity
0.0
------------------------
Precision
0.499542236328125
------------------------
Fall_out
1.0
------------------------
F1
0.6662596414107496
------------------------
#############################
test set
Evaluation results
[[    0. 16391.]
 [    0. 16377.]]
#############################
Accuracy
0.499786376953125
------------------------
Recall
1.0
------------------------
Specificity
0.0
------------------------
Precision
0.499786376953125
------------------------
Fall_out
1.0
------------------------
F1
0.666476752467189
------------------------
#############################
AUC: 0.5
Experiment end
########################################
----------------------------------------
Starting experiment alexnet_12-1559491146
Experiment parameters Experiment[name: alexnet_12-1559491146, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 0.0001, weight_decay: 0, batch_size: 32, num_epochs: 20), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.499542236328125, 0.6662596414107496
train metrics acc, f1
0.5, 0.6666666666666666
Epoch 1/20
----------
eval metrics, batch: 1024 acc, f1
0.795562744140625, 0.8048588656820764
eval metrics, batch: 2048 acc, f1
0.785980224609375, 0.7880692635459793
eval metrics, batch: 3072 acc, f1
0.8006591796875, 0.8164343525179856
eval metrics, batch: 4096 acc, f1
0.787353515625, 0.7690114698667374
train metrics, batch: 4096  acc, f1 
0.8280372619628906, 0.8229133521109055
eval metrics, batch: 5120 acc, f1
0.793731689453125, 0.7743916686137722
eval metrics, batch: 6144 acc, f1
0.799468994140625, 0.7984541299880379
eval metrics, batch: 7168 acc, f1
0.714019775390625, 0.6352703070875335
Epoch loss - train: tensor(0.4173, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3975, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.812591552734375, 0.8168669668684579
train metrics acc, f1 
0.8441200256347656, 0.8531834856122474
Epoch 2/20
----------
eval metrics, batch: 1024 acc, f1
0.773834228515625, 0.7950327737367592
eval metrics, batch: 2048 acc, f1
0.814849853515625, 0.8127642502237448
eval metrics, batch: 3072 acc, f1
0.7744140625, 0.7447690076652165
eval metrics, batch: 4096 acc, f1
0.756378173828125, 0.7107084616778402
