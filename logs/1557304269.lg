----------------------------------------
Starting experiment alexnet_1
Experiment parameters Experiment[name: alexnet_1, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 1e-05, weight_decay: 0, batch_size: 32, num_epochs: 10), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc 0.48601766190075696, f1 0.6224710424710425
train metrics acc 0.49529266357421875, f1 0.6543242777194275
Epoch 1/10
----------
eval metrics, batch: 1024, acc 0.8045886075949367, f1 0.8086982424784034
eval metrics, batch: 2048, acc 0.8113236003861004, f1 0.7982062780269058
eval metrics, batch: 3072, acc 0.8303006329113924, f1 0.8231713117093122
eval metrics, batch: 4096, acc 0.7686188412408759, f1 0.7424381883390992
train metrics, batch 4096, acc 0.8940620422363281, f1 0.8888791078638107
eval metrics, batch: 5120, acc 0.8235031011450382, f1 0.812529693092199
eval metrics, batch: 6144, acc 0.81183638996139, f1 0.7996016448213826
eval metrics, batch: 7168, acc 0.8351282671829623, f1 0.8289820509602108
Epoch loss - train: 0.282830148935318
Epoch loss - valid: 0.3901022672653198
Epoch 2/10
----------
eval metrics, batch: 1024, acc 0.8055129716981132, f1 0.7904849620478293
eval metrics, batch: 2048, acc 0.7988207547169811, f1 0.780296200901481
eval metrics, batch: 3072, acc 0.7915410482374768, f1 0.7721555083805963
eval metrics, batch: 4096, acc 0.8034609895337773, f1 0.787800963081862
train metrics, batch 4096, acc 0.931610107421875, f1 0.9323062981422746
eval metrics, batch: 5120, acc 0.8144990592662277, f1 0.8020702634880803
eval metrics, batch: 6144, acc 0.7940697674418604, f1 0.7733265071035453
eval metrics, batch: 7168, acc 0.779319606087735, f1 0.7598051157125457
Epoch loss - train: 0.18959759175777435
Epoch loss - valid: 0.46108075976371765
Epoch 3/10
----------
eval metrics, batch: 1024, acc 0.781051497277677, f1 0.7609523514659896
eval metrics, batch: 2048, acc 0.7885662431941923, f1 0.7715546295728904
eval metrics, batch: 3072, acc 0.7282165271966528, f1 0.701787610111618
eval metrics, batch: 4096, acc 0.7526152860802733, f1 0.7324211984759266
train metrics, batch 4096, acc 0.9511032104492188, f1 0.9502089839804845
eval metrics, batch: 5120, acc 0.7428746797608882, f1 0.7196275280081478
eval metrics, batch: 6144, acc 0.82989443378119, f1 0.8212867855567458
eval metrics, batch: 7168, acc 0.7394578313253012, f1 0.7112713834416164
Epoch loss - train: 0.14985710382461548
Epoch loss - valid: 0.5608954429626465
Epoch 4/10
----------
eval metrics, batch: 1024, acc 0.7964473083941606, f1 0.7815416628415802
eval metrics, batch: 2048, acc 0.7256802373158756, f1 0.7033216251348287
eval metrics, batch: 3072, acc 0.765817223198594, f1 0.7448692634476156
eval metrics, batch: 4096, acc 0.797307426199262, f1 0.7816527437036117
train metrics, batch 4096, acc 0.9618797302246094, f1 0.9622025621919715
eval metrics, batch: 5120, acc 0.7411506762468301, f1 0.71862167982771
eval metrics, batch: 6144, acc 0.7921745630174793, f1 0.7740443221954802
eval metrics, batch: 7168, acc 0.794683257918552, f1 0.7807308970099668
Epoch loss - train: 0.12062900513410568
Epoch loss - valid: 0.5353747010231018
Epoch 5/10
----------
eval metrics, batch: 1024, acc 0.7789936823104693, f1 0.7602496634438869
eval metrics, batch: 2048, acc 0.7424282962328768, f1 0.7198929267653991
eval metrics, batch: 3072, acc 0.7445934256055363, f1 0.7197769604935342
eval metrics, batch: 4096, acc 0.7491009154315605, f1 0.724256669760757
train metrics, batch 4096, acc 0.9729690551757812, f1 0.9728203751294542
eval metrics, batch: 5120, acc 0.709241365131579, f1 0.6783968163729391
eval metrics, batch: 6144, acc 0.7746994101633394, f1 0.7533144968485112
eval metrics, batch: 7168, acc 0.7509014423076923, f1 0.7260162845897304
Epoch loss - train: 0.09760808944702148
Epoch loss - valid: 0.5091502666473389
Epoch 6/10
----------
eval metrics, batch: 1024, acc 0.8055716604823747, f1 0.792821178142279
eval metrics, batch: 2048, acc 0.8052005159474672, f1 0.7899345620080296
eval metrics, batch: 3072, acc 0.7652661219081273, f1 0.7460350646635405
eval metrics, batch: 4096, acc 0.8132708728652751, f1 0.8003550370886958
train metrics, batch 4096, acc 0.9714317321777344, f1 0.9719129146586157
eval metrics, batch: 5120, acc 0.7901205936920223, f1 0.7726701833710123
eval metrics, batch: 6144, acc 0.7526431718061674, f1 0.7280871670702179
eval metrics, batch: 7168, acc 0.7517981691368788, f1 0.7277346084877465
Epoch loss - train: 0.07717112451791763
Epoch loss - valid: 0.9289774298667908
Epoch 7/10
----------
eval metrics, batch: 1024, acc 0.755036731967943, f1 0.7290634329506632
eval metrics, batch: 2048, acc 0.753248898678414, f1 0.7281936188280965
eval metrics, batch: 3072, acc 0.7672719220549159, f1 0.7474923418823953
eval metrics, batch: 4096, acc 0.7704530276046304, f1 0.7500075764463436
train metrics, batch 4096, acc 0.9831504821777344, f1 0.9831201537797174
eval metrics, batch: 5120, acc 0.6789111024844721, f1 0.6478633388324198
eval metrics, batch: 6144, acc 0.7517209353146853, f1 0.7275234583445753
eval metrics, batch: 7168, acc 0.7234075770191507, f1 0.6968573547025609
Epoch loss - train: 0.06172603741288185
Epoch loss - valid: 0.7810903787612915
Epoch 8/10
----------
eval metrics, batch: 1024, acc 0.7692989478499542, f1 0.7461700588253799
eval metrics, batch: 2048, acc 0.7054090531561462, f1 0.6705752597666453
eval metrics, batch: 3072, acc 0.7108090049342105, f1 0.6820737392287046
eval metrics, batch: 4096, acc 0.7445237576285963, f1 0.718281508186871
train metrics, batch 4096, acc 0.98748779296875, f1 0.9874981895243976
eval metrics, batch: 5120, acc 0.7989130434782609, f1 0.7862717384624839
eval metrics, batch: 6144, acc 0.73057716568545, f1 0.7055748628543528
eval metrics, batch: 7168, acc 0.7844631483166515, f1 0.7661071340409775
Epoch loss - train: 0.04915595427155495
Epoch loss - valid: 0.7851136326789856
Epoch 9/10
----------
eval metrics, batch: 1024, acc 0.742837982832618, f1 0.718583966888778
eval metrics, batch: 2048, acc 0.7626771479185119, f1 0.7400400218300891
eval metrics, batch: 3072, acc 0.684775137470542, f1 0.6538347486184122
eval metrics, batch: 4096, acc 0.7088289581624282, f1 0.6797496193537472
train metrics, batch 4096, acc 0.9914779663085938, f1 0.9914467739712391
eval metrics, batch: 5120, acc 0.7503312720848057, f1 0.7235265346050379
eval metrics, batch: 6144, acc 0.7118113090306545, f1 0.6811423988083303
eval metrics, batch: 7168, acc 0.7632984581497797, f1 0.7429818529701935
Epoch loss - train: 0.039421502500772476
Epoch loss - valid: 0.9985658526420593
Epoch 10/10
----------
eval metrics, batch: 1024, acc 0.7343341325196164, f1 0.7017404337319916
eval metrics, batch: 2048, acc 0.7786272321428571, f1 0.76222728362503
eval metrics, batch: 3072, acc 0.7308433219178082, f1 0.701377345048682
eval metrics, batch: 4096, acc 0.7451649912587412, f1 0.718997560167475
train metrics, batch 4096, acc 0.9920883178710938, f1 0.9920720472772031
eval metrics, batch: 5120, acc 0.7697427797833934, f1 0.7489853646537942
eval metrics, batch: 6144, acc 0.7358485556499575, f1 0.710843723660883
eval metrics, batch: 7168, acc 0.7448761742100769, f1 0.7228021340756206
Epoch loss - train: 0.032363686710596085
Epoch loss - valid: 1.013100266456604
Training time 84m 49s
Experiment end
########################################
----------------------------------------
Starting experiment alexnet_1
Experiment parameters Experiment[name: alexnet_1, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 0.001, weight_decay: 0, batch_size: 32, num_epochs: 10), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc 0.44818115234375, f1 0.22261392949269132
train metrics acc 0.4727134704589844, f1 0.2693814122385551
Epoch 1/10
----------
