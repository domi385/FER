----------------------------------------
Starting experiment resnet_2
Experiment parameters Experiment[name: resnet_2, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 0.001, weight_decay: 0, batch_size: 32, num_epochs: 10), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.339691162109375, 0.2937624441035349
train metrics acc, f1
0.3499717712402344, 0.3082269359585913
Epoch 1/10
----------
eval metrics, batch: 1024 acc, f1
0.6906939338235294, 0.677974211143274
eval metrics, batch: 2048 acc, f1
0.4233929514255544, 0.34687050292485094
eval metrics, batch: 3072 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 4096 acc, f1
0.46516750580945004, 0.5970492221837215
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 6144 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 7168 acc, f1
0.46981754658385094, 0.599648235682093
Epoch loss - train: tensor(0.6519, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6933, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.46516750580945004, 0.5970492221837215
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 2/10
----------
eval metrics, batch: 1024 acc, f1
0.5002597980997625, 0.4429274750734351
eval metrics, batch: 2048 acc, f1
0.723968505859375, 0.6932546545935497
eval metrics, batch: 3072 acc, f1
0.783538818359375, 0.776675797361544
eval metrics, batch: 4096 acc, f1
0.7871411483253589, 0.7689261134917543
train metrics, batch: 4096  acc, f1 
0.8507347106933594, 0.8459518513415091
eval metrics, batch: 5120 acc, f1
0.6154933697347894, 0.5443147677374625
eval metrics, batch: 6144 acc, f1
0.79547119140625, 0.7891922496225465
eval metrics, batch: 7168 acc, f1
0.7296220930232559, 0.6836717341767847
Epoch loss - train: tensor(0.4177, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4197, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8159079844206426, 0.8089192091466111
train metrics acc, f1 
0.8673820495605469, 0.8686343489153312
Epoch 3/10
----------
eval metrics, batch: 1024 acc, f1
0.7332780393835616, 0.7058858238678272
eval metrics, batch: 2048 acc, f1
0.8046271718146718, 0.7956588951635801
eval metrics, batch: 3072 acc, f1
0.810418648905804, 0.7993454179254783
eval metrics, batch: 4096 acc, f1
0.8248843719571568, 0.8294865337323338
train metrics, batch: 4096  acc, f1 
0.8646049499511719, 0.8738865181195081
eval metrics, batch: 5120 acc, f1
0.8200956937799043, 0.8333610326297712
eval metrics, batch: 6144 acc, f1
0.847117718446602, 0.8518943067924639
eval metrics, batch: 7168 acc, f1
0.7743301594331267, 0.755803156917363
Epoch loss - train: tensor(0.3058, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3676, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8317628816793893, 0.8261860751694393
train metrics acc, f1 
0.9061813354492188, 0.9084956134149881
Epoch 4/10
----------
eval metrics, batch: 1024 acc, f1
0.7982700892857143, 0.7860313702278781
eval metrics, batch: 2048 acc, f1
0.7959848816827344, 0.7864820706853556
eval metrics, batch: 3072 acc, f1
0.8235970561177552, 0.8158684431640859
eval metrics, batch: 4096 acc, f1
0.7194686756542427, 0.7018070702281228
train metrics, batch: 4096  acc, f1 
0.9010047912597656, 0.8946233590098632
eval metrics, batch: 5120 acc, f1
0.8406856796116505, 0.8470211216314639
eval metrics, batch: 6144 acc, f1
0.8018440812720848, 0.7920625724217845
eval metrics, batch: 7168 acc, f1
0.7466473178542834, 0.7364805079893821
Epoch loss - train: tensor(0.2409, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3120, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8438662790697674, 0.8399630523524328
train metrics acc, f1 
0.9246406555175781, 0.9256674129400034
Epoch 5/10
----------
eval metrics, batch: 1024 acc, f1
0.7825641295206055, 0.7754525961512363
eval metrics, batch: 2048 acc, f1
0.8247788112522686, 0.8174432002836293
eval metrics, batch: 3072 acc, f1
0.8128375337533753, 0.8035313570331877
eval metrics, batch: 4096 acc, f1
0.7726848006644518, 0.7644685886402753
train metrics, batch: 4096  acc, f1 
0.9300994873046875, 0.9286931751850381
eval metrics, batch: 5120 acc, f1
0.8230217889908257, 0.8149746725414381
eval metrics, batch: 6144 acc, f1
0.7920694200351494, 0.7797172281375458
eval metrics, batch: 7168 acc, f1
0.7851496627318718, 0.7774927686514217
Epoch loss - train: tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3901, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7676538785834739, 0.7555715711276195
train metrics acc, f1 
0.9392509460449219, 0.938372412512045
Epoch 6/10
----------
eval metrics, batch: 1024 acc, f1
0.85625, 0.8520900321543409
eval metrics, batch: 2048 acc, f1
0.6737039378612717, 0.657988781861643
eval metrics, batch: 3072 acc, f1
0.7000501093294461, 0.6925931977870632
eval metrics, batch: 4096 acc, f1
0.7091681985294118, 0.7030476503296342
train metrics, batch: 4096  acc, f1 
0.9376258850097656, 0.935237665213069
eval metrics, batch: 5120 acc, f1
0.770139467110741, 0.7611528686530038
eval metrics, batch: 6144 acc, f1
0.8748496150144369, 0.873767557564542
eval metrics, batch: 7168 acc, f1
0.8403393190298507, 0.8343665890464814
Epoch loss - train: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3663, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8551792589027911, 0.8505540209193333
train metrics acc, f1 
0.9325752258300781, 0.9340310306088553
Epoch 7/10
----------
eval metrics, batch: 1024 acc, f1
0.7245195930670686, 0.7187439892286979
eval metrics, batch: 2048 acc, f1
0.6499455428954424, 0.6413288409125051
eval metrics, batch: 3072 acc, f1
0.7663810483870968, 0.7611317254174397
eval metrics, batch: 4096 acc, f1
0.8150805353901996, 0.8062628123235984
train metrics, batch: 4096  acc, f1 
0.9433670043945312, 0.9436404774197467
eval metrics, batch: 5120 acc, f1
0.6538974017321786, 0.6484074277737828
eval metrics, batch: 6144 acc, f1
0.6517150395778364, 0.6473976376309529
eval metrics, batch: 7168 acc, f1
0.7327086553323029, 0.7242375921865657
Epoch loss - train: tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3870, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7279411764705882, 0.720247446975648
train metrics acc, f1 
0.9527320861816406, 0.9516658150030621
Epoch 8/10
----------
eval metrics, batch: 1024 acc, f1
0.7819991438356164, 0.7708532538387985
eval metrics, batch: 2048 acc, f1
0.8093529151943463, 0.8015973339462192
eval metrics, batch: 3072 acc, f1
0.7459835423197492, 0.739606346655955
eval metrics, batch: 4096 acc, f1
0.8524070945945946, 0.8511453865109063
train metrics, batch: 4096  acc, f1 
0.9329948425292969, 0.9359523644571175
eval metrics, batch: 5120 acc, f1
0.8303242870285189, 0.8223252453489073
eval metrics, batch: 6144 acc, f1
0.8002125108979947, 0.7914094723367942
eval metrics, batch: 7168 acc, f1
0.7154897604327666, 0.701012613252798
Epoch loss - train: tensor(0.1436, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3195, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.849684633027523, 0.8469509881192165
train metrics acc, f1 
0.9552688598632812, 0.9559096685893049
Epoch 9/10
----------
eval metrics, batch: 1024 acc, f1
0.7389749408050513, 0.7284808989917131
eval metrics, batch: 2048 acc, f1
0.7282662569389373, 0.7133258385840152
eval metrics, batch: 3072 acc, f1
0.7514295746388443, 0.7420152536637427
eval metrics, batch: 4096 acc, f1
0.6595601045296168, 0.6460158956592623
train metrics, batch: 4096  acc, f1 
0.9516258239746094, 0.9498058494531724
eval metrics, batch: 5120 acc, f1
0.7597819282136895, 0.7456709657819879
eval metrics, batch: 6144 acc, f1
0.7131818181818181, 0.7102713623215023
eval metrics, batch: 7168 acc, f1
0.852970825426945, 0.849467261633731
Epoch loss - train: tensor(0.1273, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3770, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8004703719723183, 0.7933824146908155
train metrics acc, f1 
0.9626235961914062, 0.9627075292881774
Epoch 10/10
----------
eval metrics, batch: 1024 acc, f1
0.7649825246710527, 0.7554224278569709
eval metrics, batch: 2048 acc, f1
0.820943671454219, 0.8138144269754689
eval metrics, batch: 3072 acc, f1
0.8034239130434783, 0.7963859491105607
eval metrics, batch: 4096 acc, f1
0.7616130024610336, 0.7509841201831668
train metrics, batch: 4096  acc, f1 
0.9667472839355469, 0.966385550066905
eval metrics, batch: 5120 acc, f1
0.7740285773026315, 0.7668814125507039
eval metrics, batch: 6144 acc, f1
0.7485840620031796, 0.7395187234590143
eval metrics, batch: 7168 acc, f1
0.7874060934891486, 0.7815716123499142
Epoch loss - train: tensor(0.1130, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4671, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8018408683974932, 0.789653431532682
train metrics acc, f1 
0.9660453796386719, 0.9662839631968303
Training time 256m 17s
Experiment end
########################################
----------------------------------------
Starting experiment resnet_3
Experiment parameters Experiment[name: resnet_3, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 0.0001, weight_decay: 0, batch_size: 32, num_epochs: 10), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.53118896484375, 0.6443816843372379
train metrics acc, f1
0.52178955078125, 0.6326489945905396
Epoch 1/10
----------
eval metrics, batch: 1024 acc, f1
0.7933657130657558, 0.7858742844500982
eval metrics, batch: 2048 acc, f1
0.8390710072595281, 0.8350818052366976
eval metrics, batch: 3072 acc, f1
0.7885593220338983, 0.7806472883125446
eval metrics, batch: 4096 acc, f1
0.7557932692307693, 0.754974554400521
train metrics, batch: 4096  acc, f1 
0.9458236694335938, 0.944731127559717
eval metrics, batch: 5120 acc, f1
0.7588261471518988, 0.754399657594602
eval metrics, batch: 6144 acc, f1
0.7935862214708369, 0.7888564634673584
eval metrics, batch: 7168 acc, f1
0.8011667351973685, 0.8008750482563377
Epoch loss - train: tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3803, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7119147605432452, 0.7121655098533711
train metrics acc, f1 
0.9539756774902344, 0.9529422318604297
Epoch 2/10
----------
eval metrics, batch: 1024 acc, f1
0.798017026578073, 0.7964212839428662
eval metrics, batch: 2048 acc, f1
0.6537616124751161, 0.6489055238976387
eval metrics, batch: 3072 acc, f1
0.840712196219622, 0.8379267908760482
eval metrics, batch: 4096 acc, f1
0.7360197368421053, 0.7337866976281306
train metrics, batch: 4096  acc, f1 
0.9631195068359375, 0.962713851565031
eval metrics, batch: 5120 acc, f1
0.8618451824134705, 0.8601526898265964
eval metrics, batch: 6144 acc, f1
0.8756522770398482, 0.8768281938325991
eval metrics, batch: 7168 acc, f1
0.7669290958268934, 0.7681886964667451
Epoch loss - train: tensor(0.1402, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3988, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.6944820582261341, 0.6992167972004666
train metrics acc, f1 
0.9666900634765625, 0.9661122193158798
Epoch 3/10
----------
eval metrics, batch: 1024 acc, f1
0.7943631492168178, 0.7922328075381332
eval metrics, batch: 2048 acc, f1
0.7289540816326531, 0.730939676223207
eval metrics, batch: 3072 acc, f1
0.7395441729323309, 0.7386044756761856
eval metrics, batch: 4096 acc, f1
0.6954341570751523, 0.7006591944103641
train metrics, batch: 4096  acc, f1 
0.9661865234375, 0.9655279696347459
eval metrics, batch: 5120 acc, f1
0.7006497524752475, 0.6984974958263773
eval metrics, batch: 6144 acc, f1
0.6261524277811924, 0.6276400367309458
eval metrics, batch: 7168 acc, f1
0.7299528301886793, 0.7318742682157975
Epoch loss - train: tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5440, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.6663396860986547, 0.6727147766323024
train metrics acc, f1 
0.9657516479492188, 0.9648522526190514
Epoch 4/10
----------
eval metrics, batch: 1024 acc, f1
0.7051189617880317, 0.70095507928529
eval metrics, batch: 2048 acc, f1
0.6304111743559018, 0.6386320780623547
eval metrics, batch: 3072 acc, f1
0.8559623194945848, 0.8556488312275644
eval metrics, batch: 4096 acc, f1
0.7659275755228505, 0.7670328611352029
train metrics, batch: 4096  acc, f1 
0.9749755859375, 0.9749574352748956
eval metrics, batch: 5120 acc, f1
0.7114288182446441, 0.7171105559554558
eval metrics, batch: 6144 acc, f1
0.7901673640167364, 0.7859239101435356
eval metrics, batch: 7168 acc, f1
0.7262727272727273, 0.7269553389254138
Epoch loss - train: tensor(0.0955, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4229, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7145505718370264, 0.7152185055601363
train metrics acc, f1 
0.9802589416503906, 0.9801104590160155
Epoch 5/10
----------
eval metrics, batch: 1024 acc, f1
0.7562452143950995, 0.7557718587422982
eval metrics, batch: 2048 acc, f1
0.7405611279333838, 0.7379012021126592
eval metrics, batch: 3072 acc, f1
0.733909090909091, 0.736531797110581
eval metrics, batch: 4096 acc, f1
0.6094783523752255, 0.6091257899488414
train metrics, batch: 4096  acc, f1 
0.9587898254394531, 0.9571827748161947
eval metrics, batch: 5120 acc, f1
0.814698093220339, 0.8145065083110203
eval metrics, batch: 6144 acc, f1
0.7470327807083648, 0.7478166964034182
eval metrics, batch: 7168 acc, f1
0.6728137516688919, 0.67386150966937
Epoch loss - train: tensor(0.0796, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3571, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7988249594813615, 0.7997580157289776
train metrics acc, f1 
0.9792861938476562, 0.9793339676498573
Epoch 6/10
----------
eval metrics, batch: 1024 acc, f1
0.7303004017531045, 0.7309697839105586
eval metrics, batch: 2048 acc, f1
0.7736024237685692, 0.7748128706133955
eval metrics, batch: 3072 acc, f1
0.7538487606506584, 0.7513874287949539
eval metrics, batch: 4096 acc, f1
0.7102471949509116, 0.7125527196834645
train metrics, batch: 4096  acc, f1 
0.979888916015625, 0.9796270104415435
eval metrics, batch: 5120 acc, f1
0.7261947863866763, 0.7276614899842448
eval metrics, batch: 6144 acc, f1
0.7235157435508346, 0.7153562623575073
eval metrics, batch: 7168 acc, f1
0.8203738012205755, 0.8172418572418573
Epoch loss - train: tensor(0.0675, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4619, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7564388071262587, 0.7552896541660586
train metrics acc, f1 
0.9874420166015625, 0.9874543639149092
Epoch 7/10
----------
eval metrics, batch: 1024 acc, f1
0.7674767621998451, 0.7691420331651045
eval metrics, batch: 2048 acc, f1
0.7319815396700707, 0.7200512820512821
eval metrics, batch: 3072 acc, f1
0.7440055762081784, 0.7456367162249515
eval metrics, batch: 4096 acc, f1
0.7701460651828299, 0.7687154747919114
train metrics, batch: 4096  acc, f1 
0.9868621826171875, 0.9869323700825644
eval metrics, batch: 5120 acc, f1
0.7144427494615937, 0.7139871924502865
eval metrics, batch: 6144 acc, f1
0.7097242380261248, 0.7063950821176255
eval metrics, batch: 7168 acc, f1
0.7732576069078947, 0.7668278760009514
Epoch loss - train: tensor(0.0563, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5645, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.724349710982659, 0.7261183649661237
train metrics acc, f1 
0.9903526306152344, 0.9903075596435758
Epoch 8/10
----------
eval metrics, batch: 1024 acc, f1
0.7573084677419355, 0.7495318352059925
eval metrics, batch: 2048 acc, f1
0.8223553445229682, 0.8174312707464465
eval metrics, batch: 3072 acc, f1
0.6405185758513932, 0.6455121355518242
eval metrics, batch: 4096 acc, f1
0.8467641037306642, 0.8445316331535067
train metrics, batch: 4096  acc, f1 
0.9787979125976562, 0.9791413345342641
eval metrics, batch: 5120 acc, f1
0.7914997892074199, 0.7860021094193688
eval metrics, batch: 6144 acc, f1
0.6925851877607788, 0.6920766216804528
eval metrics, batch: 7168 acc, f1
0.6124292312276519, 0.61572834536625
Epoch loss - train: tensor(0.0466, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4826, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8059067131647777, 0.7985294117647059
train metrics acc, f1 
0.9878768920898438, 0.9879667704144611
Epoch 9/10
----------
eval metrics, batch: 1024 acc, f1
0.740157666163142, 0.7384973514810328
eval metrics, batch: 2048 acc, f1
0.7014908667621776, 0.6980914215852747
eval metrics, batch: 3072 acc, f1
0.7745766932270917, 0.7729085664116393
eval metrics, batch: 4096 acc, f1
0.7699701195219123, 0.7665521075507935
train metrics, batch: 4096  acc, f1 
0.9928550720214844, 0.9928552082975712
eval metrics, batch: 5120 acc, f1
0.7536086017282011, 0.7490812729681758
eval metrics, batch: 6144 acc, f1
0.7299808254200146, 0.7314703411954325
eval metrics, batch: 7168 acc, f1
0.7910428630024611, 0.789591884147758
Epoch loss - train: tensor(0.0400, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6621, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.6847086971121558, 0.6881836484775524
train metrics acc, f1 
0.9926910400390625, 0.9926474538547143
Epoch 10/10
----------
eval metrics, batch: 1024 acc, f1
0.7691069991954947, 0.764367816091954
eval metrics, batch: 2048 acc, f1
0.7048104956268222, 0.6986046511627907
eval metrics, batch: 3072 acc, f1
0.6546953715365239, 0.6612482866464604
eval metrics, batch: 4096 acc, f1
0.7304172767203514, 0.7312166415765704
train metrics, batch: 4096  acc, f1 
0.9919090270996094, 0.9918720372790294
eval metrics, batch: 5120 acc, f1
0.8438616071428572, 0.8419655464558035
eval metrics, batch: 6144 acc, f1
0.6635452961672473, 0.6518702118071203
eval metrics, batch: 7168 acc, f1
0.7489056420233463, 0.7444876141453637
Epoch loss - train: tensor(0.0354, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6982, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.717783273381295, 0.7184857930972618
train metrics acc, f1 
0.9959449768066406, 0.9959391367131839
Training time 241m 0s
Experiment end
########################################
----------------------------------------
Starting experiment resnet_4
Experiment parameters Experiment[name: resnet_4, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 1e-05, weight_decay: 0, batch_size: 32, num_epochs: 10), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.507781982421875, 0.5693305919735121
train metrics acc, f1
0.5084915161132812, 0.5653438225292816
Epoch 1/10
----------
eval metrics, batch: 1024 acc, f1
0.568634033203125, 0.6059490953695186
eval metrics, batch: 2048 acc, f1
0.6392822265625, 0.6718125277654375
eval metrics, batch: 3072 acc, f1
0.694244384765625, 0.7049156186493093
eval metrics, batch: 4096 acc, f1
0.72906494140625, 0.7385747938751472
train metrics, batch: 4096  acc, f1 
0.7207527160644531, 0.7265350950924027
eval metrics, batch: 5120 acc, f1
0.74945068359375, 0.7536901476059042
eval metrics, batch: 6144 acc, f1
0.76239013671875, 0.7610483672968328
eval metrics, batch: 7168 acc, f1
0.7706298828125, 0.7706858677080791
Epoch loss - train: tensor(0.5873, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5044, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.77569580078125, 0.7725162488393686
train metrics acc, f1 
0.7715950012207031, 0.7690034451761747
Epoch 2/10
----------
eval metrics, batch: 1024 acc, f1
0.776275634765625, 0.7699356660913228
eval metrics, batch: 2048 acc, f1
0.77923583984375, 0.7730296184738956
eval metrics, batch: 3072 acc, f1
0.78173828125, 0.7728369965696862
eval metrics, batch: 4096 acc, f1
0.782257080078125, 0.7714239948742592
train metrics, batch: 4096  acc, f1 
0.786346435546875, 0.7787539305070552
eval metrics, batch: 5120 acc, f1
0.783447265625, 0.7762361251261353
eval metrics, batch: 6144 acc, f1
0.785247802734375, 0.7770773275889378
eval metrics, batch: 7168 acc, f1
0.787200927734375, 0.7801910285912429
Epoch loss - train: tensor(0.4771, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4628, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7857229795520935, 0.7734234234234234
train metrics acc, f1 
0.7945556640625, 0.7860547892963834
Epoch 3/10
----------
eval metrics, batch: 1024 acc, f1
0.790130615234375, 0.7801681424415817
eval metrics, batch: 2048 acc, f1
0.790557861328125, 0.7811054763499505
eval metrics, batch: 3072 acc, f1
0.79315185546875, 0.7850982878883956
eval metrics, batch: 4096 acc, f1
0.7915652385589095, 0.7829393497686798
train metrics, batch: 4096  acc, f1 
0.7987213134765625, 0.793556767585079
eval metrics, batch: 5120 acc, f1
0.7925998052580331, 0.784044103668969
eval metrics, batch: 6144 acc, f1
0.7936952288218111, 0.786966631056369
eval metrics, batch: 7168 acc, f1
0.7931475170399221, 0.7850910470409712
Epoch loss - train: tensor(0.4485, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4473, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7928432327166505, 0.7843249065450167
train metrics acc, f1 
0.8026847839355469, 0.7983202779261593
Epoch 4/10
----------
eval metrics, batch: 1024 acc, f1
0.793243408203125, 0.7842974943487535
eval metrics, batch: 2048 acc, f1
0.791534423828125, 0.779510022271715
eval metrics, batch: 3072 acc, f1
0.794036865234375, 0.7851799980902059
eval metrics, batch: 4096 acc, f1
0.793182373046875, 0.7822930386456359
train metrics, batch: 4096  acc, f1 
0.8045463562011719, 0.7988347120741576
eval metrics, batch: 5120 acc, f1
0.79345703125, 0.7831742166976357
eval metrics, batch: 6144 acc, f1
0.7935791015625, 0.7836073965064944
eval metrics, batch: 7168 acc, f1
0.79296875, 0.7817667117030175
Epoch loss - train: tensor(0.4353, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4426, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.793365478515625, 0.7817707158281497
train metrics acc, f1 
0.8071937561035156, 0.8014050914920453
Epoch 5/10
----------
eval metrics, batch: 1024 acc, f1
0.79779052734375, 0.7893699535889122
eval metrics, batch: 2048 acc, f1
0.7972412109375, 0.7860914359304572
eval metrics, batch: 3072 acc, f1
0.798675537109375, 0.7885915718634834
eval metrics, batch: 4096 acc, f1
0.79827880859375, 0.7886423226961693
train metrics, batch: 4096  acc, f1 
0.8096809387207031, 0.8052266454290277
eval metrics, batch: 5120 acc, f1
0.79833984375, 0.7871819645732689
eval metrics, batch: 6144 acc, f1
0.7962512171372931, 0.7846945337620579
eval metrics, batch: 7168 acc, f1
0.7965250730282376, 0.7854048329642823
Epoch loss - train: tensor(0.4269, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4367, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.798919677734375, 0.7886583058023543
train metrics acc, f1 
0.8112678527832031, 0.8065561720213169
Epoch 6/10
----------
eval metrics, batch: 1024 acc, f1
0.795928955078125, 0.7828261504985223
eval metrics, batch: 2048 acc, f1
0.796295166015625, 0.7848093104226442
eval metrics, batch: 3072 acc, f1
0.7978515625, 0.7882082107686404
eval metrics, batch: 4096 acc, f1
0.797393798828125, 0.7856381776500597
train metrics, batch: 4096  acc, f1 
0.8124046325683594, 0.8071195202403505
eval metrics, batch: 5120 acc, f1
0.79766845703125, 0.787213556710957
eval metrics, batch: 6144 acc, f1
0.797088623046875, 0.7858546168958742
eval metrics, batch: 7168 acc, f1
0.7978515625, 0.7876514714368148
Epoch loss - train: tensor(0.4206, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4328, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7943567961165049, 0.7828399333589645
train metrics acc, f1 
0.8131599426269531, 0.8078327977808903
Epoch 7/10
----------
eval metrics, batch: 1024 acc, f1
0.7767175572519084, 0.7544596012591815
eval metrics, batch: 2048 acc, f1
0.7913228155339805, 0.7793107873965218
eval metrics, batch: 3072 acc, f1
0.7917172330097088, 0.7795793867394445
eval metrics, batch: 4096 acc, f1
0.7927184466019418, 0.7820733652312599
train metrics, batch: 4096  acc, f1 
0.8121490478515625, 0.8079616890511176
eval metrics, batch: 5120 acc, f1
0.7926881067961165, 0.7814209398291802
eval metrics, batch: 6144 acc, f1
0.792627427184466, 0.7815945039143634
eval metrics, batch: 7168 acc, f1
0.7924757281553398, 0.7799227799227799
Epoch loss - train: tensor(0.4203, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4368, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7926881067961165, 0.7805927495745433
train metrics acc, f1 
0.8127021789550781, 0.8072863720037523
Epoch 8/10
----------
eval metrics, batch: 1024 acc, f1
0.7927823758519961, 0.7809866855341867
eval metrics, batch: 2048 acc, f1
0.7949427945472249, 0.7858391330600312
eval metrics, batch: 3072 acc, f1
0.7940603700097371, 0.784855998474156
eval metrics, batch: 4096 acc, f1
0.7933300876338851, 0.7819582664526484
train metrics, batch: 4096  acc, f1 
0.815032958984375, 0.810666229334083
eval metrics, batch: 5120 acc, f1
0.7932692307692307, 0.7837545356165255
eval metrics, batch: 6144 acc, f1
0.7934213729308666, 0.7825084094185488
eval metrics, batch: 7168 acc, f1
0.7935126582278481, 0.7814914992272025
Epoch loss - train: tensor(0.4149, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4334, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.793482229795521, 0.7811139420130938
train metrics acc, f1 
0.8159637451171875, 0.8109812955954144
Epoch 9/10
----------
eval metrics, batch: 1024 acc, f1
0.7960990749756572, 0.7896141408433016
eval metrics, batch: 2048 acc, f1
0.7909305421103582, 0.7799815351310051
eval metrics, batch: 3072 acc, f1
0.7905372700871249, 0.7794061424748312
eval metrics, batch: 4096 acc, f1
0.7906885285575992, 0.7796707320956596
train metrics, batch: 4096  acc, f1 
0.8159523010253906, 0.8119457902470777
eval metrics, batch: 5120 acc, f1
0.7905070183930301, 0.7795217931166226
eval metrics, batch: 6144 acc, f1
0.7911725556631172, 0.7808223527544055
eval metrics, batch: 7168 acc, f1
0.7907490319457889, 0.7787338856722433
Epoch loss - train: tensor(0.4121, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4324, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7905070183930301, 0.7774528392839927
train metrics acc, f1 
0.8170166015625, 0.8113798120404231
Epoch 10/10
----------
eval metrics, batch: 1024 acc, f1
0.7943264563106797, 0.7851278962883134
eval metrics, batch: 2048 acc, f1
0.7896356177606177, 0.7760292889716744
eval metrics, batch: 3072 acc, f1
0.7897562741312741, 0.7760282776349614
eval metrics, batch: 4096 acc, f1
0.7896054536679536, 0.7764494727733086
train metrics, batch: 4096  acc, f1 
0.8175315856933594, 0.8121389212902415
eval metrics, batch: 5120 acc, f1
0.7898166023166023, 0.7772236076475478
eval metrics, batch: 6144 acc, f1
0.7899372586872587, 0.7780327659845732
eval metrics, batch: 7168 acc, f1
0.7904500482625483, 0.7793131929222656
Epoch loss - train: tensor(0.4089, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4316, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7899372586872587, 0.7772660397876288
train metrics acc, f1 
0.8187294006347656, 0.8140018240103961
Training time 200m 29s
Experiment end
########################################
----------------------------------------
Starting experiment resnet_5
Experiment parameters Experiment[name: resnet_5, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 0.001, weight_decay: 0, batch_size: 32, num_epochs: 10), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.493560791015625, 0.6166108351622964
train metrics acc, f1
0.4734649658203125, 0.5970197186717194
Epoch 1/10
----------
eval metrics, batch: 1024 acc, f1
0.798126220703125, 0.7912261322392299
eval metrics, batch: 2048 acc, f1
0.7884708737864078, 0.7717391304347826
eval metrics, batch: 3072 acc, f1
0.792083740234375, 0.7855591577224513
eval metrics, batch: 4096 acc, f1
0.7841073147256978, 0.7669177815300688
train metrics, batch: 4096  acc, f1 
0.8226661682128906, 0.8155446129916714
eval metrics, batch: 5120 acc, f1
0.7890549370764763, 0.7743292663192983
eval metrics, batch: 6144 acc, f1
0.791778564453125, 0.7852173639311235
eval metrics, batch: 7168 acc, f1
0.7740223128598849, 0.7510160922578727
Epoch loss - train: tensor(0.4114, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4472, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7891845703125, 0.7865265760197775
train metrics acc, f1 
0.8189659118652344, 0.823842524712232
Epoch 2/10
----------
eval metrics, batch: 1024 acc, f1
0.7686366889312977, 0.7396745512497903
eval metrics, batch: 2048 acc, f1
0.79931640625, 0.7912646013204673
eval metrics, batch: 3072 acc, f1
0.7872526544401545, 0.7746141309558048
eval metrics, batch: 4096 acc, f1
0.7933252427184466, 0.7829052202179871
train metrics, batch: 4096  acc, f1 
0.8237113952636719, 0.8212615692842031
eval metrics, batch: 5120 acc, f1
0.7809793070259865, 0.7620883429168844
eval metrics, batch: 6144 acc, f1
0.7920825219084713, 0.784305060134474
eval metrics, batch: 7168 acc, f1
0.784617718446602, 0.7751132511800298
Epoch loss - train: tensor(0.4045, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4417, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7835254854368932, 0.7652574436584965
train metrics acc, f1 
0.8222427368164062, 0.8149698221092757
Epoch 3/10
----------
eval metrics, batch: 1024 acc, f1
0.7802033492822966, 0.7605083088954057
eval metrics, batch: 2048 acc, f1
0.794647216796875, 0.787386647287434
eval metrics, batch: 3072 acc, f1
0.7831805019305019, 0.7631787032156035
eval metrics, batch: 4096 acc, f1
0.788299560546875, 0.791224004574593
train metrics, batch: 4096  acc, f1 
0.8159370422363281, 0.8247247418149058
eval metrics, batch: 5120 acc, f1
0.796661376953125, 0.7856798224452378
eval metrics, batch: 6144 acc, f1
0.7569962686567164, 0.7257533886037637
eval metrics, batch: 7168 acc, f1
0.7873786407766991, 0.7728951973556291
Epoch loss - train: tensor(0.4031, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4396, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7868768151016456, 0.7688724123224304
train metrics acc, f1 
0.8230171203613281, 0.8153807585325964
Epoch 4/10
----------
eval metrics, batch: 1024 acc, f1
0.7868628640776699, 0.77935864819875
eval metrics, batch: 2048 acc, f1
0.792633056640625, 0.7998704090949253
eval metrics, batch: 3072 acc, f1
0.7565372889305816, 0.7239488117001828
eval metrics, batch: 4096 acc, f1
0.791961669921875, 0.7986412642150347
train metrics, batch: 4096  acc, f1 
0.8137779235839844, 0.8254322444527884
eval metrics, batch: 5120 acc, f1
0.7922346640701071, 0.7805912596401028
eval metrics, batch: 6144 acc, f1
0.79364013671875, 0.7848689233901757
eval metrics, batch: 7168 acc, f1
0.7874515972894482, 0.7750096067631612
Epoch loss - train: tensor(0.4030, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4391, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.795989990234375, 0.7957968048385619
train metrics acc, f1 
0.8203010559082031, 0.8262138322087486
Epoch 5/10
----------
eval metrics, batch: 1024 acc, f1
0.7876028557599225, 0.7741499662238235
eval metrics, batch: 2048 acc, f1
0.798583984375, 0.7985470972468103
eval metrics, batch: 3072 acc, f1
0.7832827669902913, 0.7660563979956113
eval metrics, batch: 4096 acc, f1
0.79046630859375, 0.7853435878196711
train metrics, batch: 4096  acc, f1 
0.8224678039550781, 0.8258212290084621
eval metrics, batch: 5120 acc, f1
0.7919912366114897, 0.7833692483204462
eval metrics, batch: 6144 acc, f1
0.775415062560154, 0.752822006686749
eval metrics, batch: 7168 acc, f1
0.7897148058252427, 0.7761955503890988
Epoch loss - train: tensor(0.4039, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4394, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7871531158714703, 0.767042994638159
train metrics acc, f1 
0.8235321044921875, 0.8152378822251334
Epoch 6/10
----------
eval metrics, batch: 1024 acc, f1
0.794577653359299, 0.7847875290892282
eval metrics, batch: 2048 acc, f1
0.79052734375, 0.7791079358949604
eval metrics, batch: 3072 acc, f1
0.796783447265625, 0.7909065218073916
eval metrics, batch: 4096 acc, f1
0.7931170886075949, 0.7816985069834644
train metrics, batch: 4096  acc, f1 
0.8233528137207031, 0.8199075172384289
eval metrics, batch: 5120 acc, f1
0.7964033592989289, 0.7876344939219856
eval metrics, batch: 6144 acc, f1
0.7817326254826255, 0.760904044409199
eval metrics, batch: 7168 acc, f1
0.7922936893203884, 0.7786328655500226
Epoch loss - train: tensor(0.4031, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4319, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.794769287109375, 0.7849445172843849
train metrics acc, f1 
0.8253250122070312, 0.8241024577254323
Epoch 7/10
----------
eval metrics, batch: 1024 acc, f1
0.734648114075437, 0.6928452579034942
eval metrics, batch: 2048 acc, f1
0.792022705078125, 0.7849954254345837
eval metrics, batch: 3072 acc, f1
0.793487548828125, 0.7839468727052138
eval metrics, batch: 4096 acc, f1
0.7800503838771593, 0.7593989895676136
train metrics, batch: 4096  acc, f1 
0.8212394714355469, 0.8114055740014086
eval metrics, batch: 5120 acc, f1
0.79205322265625, 0.7995764456732749
eval metrics, batch: 6144 acc, f1
0.787274829600779, 0.7685022682870294
eval metrics, batch: 7168 acc, f1
0.794036865234375, 0.7954042501591536
Epoch loss - train: tensor(0.4034, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4355, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7916260954235638, 0.7812839348450974
train metrics acc, f1 
0.825164794921875, 0.824146478095048
Epoch 8/10
----------
eval metrics, batch: 1024 acc, f1
0.79986572265625, 0.7956372701776254
eval metrics, batch: 2048 acc, f1
0.7807673745173745, 0.7634268602304537
eval metrics, batch: 3072 acc, f1
0.784253640776699, 0.767134951042997
eval metrics, batch: 4096 acc, f1
0.7785653957528957, 0.757490667635691
train metrics, batch: 4096  acc, f1 
0.8239593505859375, 0.8155629271412014
eval metrics, batch: 5120 acc, f1
0.793060302734375, 0.7885892439594699
eval metrics, batch: 6144 acc, f1
0.7623339658444023, 0.7300464740351587
eval metrics, batch: 7168 acc, f1
0.7910783836416748, 0.777077922077922
Epoch loss - train: tensor(0.4029, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4442, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.794097900390625, 0.7971985932850402
train metrics acc, f1 
0.817474365234375, 0.8262776478789375
Epoch 9/10
----------
eval metrics, batch: 1024 acc, f1
0.78546142578125, 0.7913575117231555
eval metrics, batch: 2048 acc, f1
0.794647216796875, 0.7874672309781751
eval metrics, batch: 3072 acc, f1
0.78741455078125, 0.7908233739715332
eval metrics, batch: 4096 acc, f1
0.7840029041626331, 0.7653014265991717
train metrics, batch: 4096  acc, f1 
0.8234443664550781, 0.8163846626862119
eval metrics, batch: 5120 acc, f1
0.784558469682387, 0.7698042870456664
eval metrics, batch: 6144 acc, f1
0.794952392578125, 0.792206587289315
eval metrics, batch: 7168 acc, f1
0.7915043816942551, 0.7839848675914249
Epoch loss - train: tensor(0.4032, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4394, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7887658227848101, 0.7739940096366714
train metrics acc, f1 
0.8263816833496094, 0.8223279708623025
Epoch 10/10
----------
eval metrics, batch: 1024 acc, f1
0.7590116279069767, 0.7309839044652129
eval metrics, batch: 2048 acc, f1
0.7863175675675675, 0.768919624217119
eval metrics, batch: 3072 acc, f1
0.792877197265625, 0.7989930401303125
eval metrics, batch: 4096 acc, f1
0.7953580097087378, 0.7916087372941576
train metrics, batch: 4096  acc, f1 
0.8225593566894531, 0.8251887540541252
eval metrics, batch: 5120 acc, f1
0.7894482090997096, 0.7773512476007678
eval metrics, batch: 6144 acc, f1
0.7637867647058824, 0.732336636989753
eval metrics, batch: 7168 acc, f1
0.795654296875, 0.8021978021978022
Epoch loss - train: tensor(0.4056, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4391, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7803802783109405, 0.7642988187582478
train metrics acc, f1 
0.8224906921386719, 0.8166093238274276
Training time 191m 47s
Experiment end
########################################
----------------------------------------
Starting experiment resnet_6
Experiment parameters Experiment[name: resnet_6, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 0.0001, weight_decay: 0, batch_size: 32, num_epochs: 10), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.46653696498054475, 0.5986974497822984
train metrics acc, f1
0.49983978271484375, 0.6661115185592633
Epoch 1/10
----------
eval metrics, batch: 1024 acc, f1
0.7590793918918919, 0.7343245850380867
eval metrics, batch: 2048 acc, f1
0.7823390609874153, 0.7710567346549145
eval metrics, batch: 3072 acc, f1
0.7885618932038835, 0.783052641409582
eval metrics, batch: 4096 acc, f1
0.7895934466019418, 0.7817466561762392
train metrics, batch: 4096  acc, f1 
0.8072242736816406, 0.8053373805387457
eval metrics, batch: 5120 acc, f1
0.789364140926641, 0.779067927990635
eval metrics, batch: 6144 acc, f1
0.7919599514563107, 0.7801045441426419
eval metrics, batch: 7168 acc, f1
0.7848488483685221, 0.7690574298223023
Epoch loss - train: tensor(0.4495, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4389, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7837092130518234, 0.766223662884927
train metrics acc, f1 
0.8142280578613281, 0.8047016927537627
Epoch 2/10
----------
eval metrics, batch: 1024 acc, f1
0.7908700387221684, 0.77696402645588
eval metrics, batch: 2048 acc, f1
0.7930521844660194, 0.7798470128780299
eval metrics, batch: 3072 acc, f1
0.7898769305019305, 0.7772875503548821
eval metrics, batch: 4096 acc, f1
0.790053242981607, 0.7738824449367914
train metrics, batch: 4096  acc, f1 
0.8205947875976562, 0.8139150252834997
eval metrics, batch: 5120 acc, f1
0.7904767666989352, 0.7737636375514471
eval metrics, batch: 6144 acc, f1
0.7951152912621359, 0.7872333721919406
eval metrics, batch: 7168 acc, f1
0.7924757281553398, 0.779724333376272
Epoch loss - train: tensor(0.4039, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4290, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7923543689320388, 0.7778499091145157
train metrics acc, f1 
0.8236885070800781, 0.818547643070545
Epoch 3/10
----------
eval metrics, batch: 1024 acc, f1
0.785503137065637, 0.7652283007032256
eval metrics, batch: 2048 acc, f1
0.792384708737864, 0.7812270213242112
eval metrics, batch: 3072 acc, f1
0.7937865141187926, 0.7811682650392328
eval metrics, batch: 4096 acc, f1
0.792748786407767, 0.7801486917060925
train metrics, batch: 4096  acc, f1 
0.8234939575195312, 0.8197703405939359
eval metrics, batch: 5120 acc, f1
0.7936589805825243, 0.7822216529507829
eval metrics, batch: 6144 acc, f1
0.7896657818532818, 0.7744460617823063
eval metrics, batch: 7168 acc, f1
0.7958252190847127, 0.7861422743498215
Epoch loss - train: tensor(0.3991, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4310, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7895389641819942, 0.7754575089565245
train metrics acc, f1 
0.8239479064941406, 0.8191539802895825
Epoch 4/10
----------
eval metrics, batch: 1024 acc, f1
0.7941140776699029, 0.7842426554750095
eval metrics, batch: 2048 acc, f1
0.7935321878025169, 0.7816069885763656
eval metrics, batch: 3072 acc, f1
0.7924757281553398, 0.7806848787995383
eval metrics, batch: 4096 acc, f1
0.793048160696999, 0.7827633292051698
train metrics, batch: 4096  acc, f1 
0.8252677917480469, 0.8231897260511922
eval metrics, batch: 5120 acc, f1
0.7883481713185756, 0.7729047665149902
eval metrics, batch: 6144 acc, f1
0.7959773612463485, 0.7869331723283232
eval metrics, batch: 7168 acc, f1
0.7917775895450145, 0.7788025837966385
Epoch loss - train: tensor(0.3964, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4291, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7904802123552124, 0.7778843694039397
train metrics acc, f1 
0.825836181640625, 0.822225683357994
Epoch 5/10
----------
eval metrics, batch: 1024 acc, f1
0.7775505293551492, 0.754644373673036
eval metrics, batch: 2048 acc, f1
0.7919902912621359, 0.775183630640084
eval metrics, batch: 3072 acc, f1
0.7950949367088608, 0.7805799934832193
eval metrics, batch: 4096 acc, f1
0.7952973300970874, 0.783715338996634
train metrics, batch: 4096  acc, f1 
0.8262290954589844, 0.8231823527813467
eval metrics, batch: 5120 acc, f1
0.7945472249269717, 0.7829915793533457
eval metrics, batch: 6144 acc, f1
0.7957035053554041, 0.7819563522992985
eval metrics, batch: 7168 acc, f1
0.7948819376825705, 0.7805306853328993
Epoch loss - train: tensor(0.3952, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4270, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7946385102239533, 0.7819456560369616
train metrics acc, f1 
0.8258819580078125, 0.8225984484554514
Epoch 6/10
----------
eval metrics, batch: 1024 acc, f1
0.783542471042471, 0.7646904512067156
eval metrics, batch: 2048 acc, f1
0.7949427945472249, 0.7841655190084232
eval metrics, batch: 3072 acc, f1
0.7907490319457889, 0.7755896570742628
eval metrics, batch: 4096 acc, f1
0.7906582768635043, 0.7764713482783125
train metrics, batch: 4096  acc, f1 
0.8252029418945312, 0.8207655659602432
eval metrics, batch: 5120 acc, f1
0.7968293573515093, 0.7868611740670987
eval metrics, batch: 6144 acc, f1
0.7949635922330097, 0.7836055075248158
eval metrics, batch: 7168 acc, f1
0.7934162621359223, 0.7793226381461675
Epoch loss - train: tensor(0.3950, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4248, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7930218446601942, 0.7789801075617184
train metrics acc, f1 
0.82537841796875, 0.8206044645096564
Epoch 7/10
----------
eval metrics, batch: 1024 acc, f1
0.795654296875, 0.7836370686312524
eval metrics, batch: 2048 acc, f1
0.7871621621621622, 0.7681997371879107
eval metrics, batch: 3072 acc, f1
0.7930218446601942, 0.781093569503273
eval metrics, batch: 4096 acc, f1
0.7929308252427184, 0.7794474066892875
train metrics, batch: 4096  acc, f1 
0.8266029357910156, 0.8225031141517207
eval metrics, batch: 5120 acc, f1
0.79833984375, 0.7910712027317567
eval metrics, batch: 6144 acc, f1
0.794577653359299, 0.7819374010788462
eval metrics, batch: 7168 acc, f1
0.7930562317429406, 0.7780280035249192
Epoch loss - train: tensor(0.3948, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4319, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7877123786407767, 0.7694183555775251
train metrics acc, f1 
0.8254776000976562, 0.8186337472051758
Epoch 8/10
----------
eval metrics, batch: 1024 acc, f1
0.7890776699029126, 0.7720655737704918
eval metrics, batch: 2048 acc, f1
0.7932083739045764, 0.7844729164023849
eval metrics, batch: 3072 acc, f1
0.7905643203883496, 0.7733972359912025
eval metrics, batch: 4096 acc, f1
0.7899575242718446, 0.7748837511787467
train metrics, batch: 4096  acc, f1 
0.825469970703125, 0.8205620965274891
eval metrics, batch: 5120 acc, f1
0.7923543689320388, 0.7813977258208764
eval metrics, batch: 6144 acc, f1
0.7905946601941748, 0.7764027471815472
eval metrics, batch: 7168 acc, f1
0.7929308252427184, 0.7805819000160746
Epoch loss - train: tensor(0.3950, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4292, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7931475170399221, 0.7794718743917473
train metrics acc, f1 
0.8266944885253906, 0.8227034494600828
Epoch 9/10
----------
eval metrics, batch: 1024 acc, f1
0.7884801548886737, 0.7741164308328488
eval metrics, batch: 2048 acc, f1
0.7877051158301158, 0.7714341387373344
eval metrics, batch: 3072 acc, f1
0.7967529296875, 0.7865110911655341
eval metrics, batch: 4096 acc, f1
0.7897562741312741, 0.7757688843134731
train metrics, batch: 4096  acc, f1 
0.8259468078613281, 0.821203108284448
eval metrics, batch: 5120 acc, f1
0.7946689386562804, 0.7837733914380928
eval metrics, batch: 6144 acc, f1
0.79583740234375, 0.7865756396350412
eval metrics, batch: 7168 acc, f1
0.793482229795521, 0.781085701383737
Epoch loss - train: tensor(0.3941, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4331, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7867255566311714, 0.767403497195645
train metrics acc, f1 
0.824371337890625, 0.8159975061347486
Epoch 10/10
----------
eval metrics, batch: 1024 acc, f1
0.7747458857696031, 0.7505193325738793
eval metrics, batch: 2048 acc, f1
0.7894961051606622, 0.7739363440298019
eval metrics, batch: 3072 acc, f1
0.7913522395326192, 0.7790843777183544
eval metrics, batch: 4096 acc, f1
0.7922346640701071, 0.7788287121015807
train metrics, batch: 4096  acc, f1 
0.8244514465332031, 0.8207054276552888
eval metrics, batch: 5120 acc, f1
0.795166015625, 0.7830780169349105
eval metrics, batch: 6144 acc, f1
0.795684814453125, 0.7840949401786578
eval metrics, batch: 7168 acc, f1
0.795806884765625, 0.7858811481967423
Epoch loss - train: tensor(0.3956, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4301, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.793975830078125, 0.7795159868055782
train metrics acc, f1 
0.8244705200195312, 0.8198073308270677
Training time 192m 48s
Experiment end
########################################
