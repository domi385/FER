----------------------------------------
Starting experiment alexnet_13-1559673726
Experiment parameters Experiment[name: alexnet_13-1559673726, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 1e-05, weight_decay: 0, batch_size: 32, num_epochs: 20), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.500457763671875, 0.0
train metrics acc, f1
0.5, 0.0
Epoch 1/20
----------
eval metrics, batch: 1024 acc, f1
0.76776123046875, 0.7746120127946926
eval metrics, batch: 2048 acc, f1
0.75738525390625, 0.7672580361847884
eval metrics, batch: 3072 acc, f1
0.763275146484375, 0.7712136852971538
eval metrics, batch: 4096 acc, f1
0.774627685546875, 0.7600636797816693
train metrics, batch: 4096  acc, f1 
0.8039436340332031, 0.7997147411041702
eval metrics, batch: 5120 acc, f1
0.797088623046875, 0.7970824304940947
eval metrics, batch: 6144 acc, f1
0.7862548828125, 0.7806726373144611
eval metrics, batch: 7168 acc, f1
0.774688720703125, 0.7461054369132364
Epoch loss - train: tensor(0.4487, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4310, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.795501708984375, 0.7913306137701243
train metrics acc, f1 
0.8318824768066406, 0.835076584549867
Epoch 2/20
----------
eval metrics, batch: 1024 acc, f1
0.760528564453125, 0.7854545454545454
eval metrics, batch: 2048 acc, f1
0.7933349609375, 0.7827258726899384
eval metrics, batch: 3072 acc, f1
0.7933349609375, 0.7744471089794831
eval metrics, batch: 4096 acc, f1
0.79449462890625, 0.784304932735426
train metrics, batch: 4096  acc, f1 
0.8448562622070312, 0.8449225184552498
eval metrics, batch: 5120 acc, f1
0.795989990234375, 0.7915562346044713
eval metrics, batch: 6144 acc, f1
0.792022705078125, 0.7767111169358802
eval metrics, batch: 7168 acc, f1
0.795684814453125, 0.7999043605606863
Epoch loss - train: tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4167, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.80450439453125, 0.8085475194261805
train metrics acc, f1 
0.85357666015625, 0.8614916066454006
Epoch 3/20
----------
eval metrics, batch: 1024 acc, f1
0.796234130859375, 0.782515227517019
eval metrics, batch: 2048 acc, f1
0.79168701171875, 0.7730868958180972
eval metrics, batch: 3072 acc, f1
0.79986572265625, 0.7860219263899765
eval metrics, batch: 4096 acc, f1
0.79949951171875, 0.7939793038570084
train metrics, batch: 4096  acc, f1 
0.8659400939941406, 0.8698026459593733
eval metrics, batch: 5120 acc, f1
0.77801513671875, 0.7432403812213202
eval metrics, batch: 6144 acc, f1
0.776611328125, 0.7411049020301337
eval metrics, batch: 7168 acc, f1
0.823577880859375, 0.8255845527228843
Epoch loss - train: tensor(0.3287, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4156, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.81353759765625, 0.8110231349746382
train metrics acc, f1 
0.8748397827148438, 0.8792506992492272
Epoch 4/20
----------
eval metrics, batch: 1024 acc, f1
0.804962158203125, 0.7958473087366236
eval metrics, batch: 2048 acc, f1
0.79571533203125, 0.7752635466326462
eval metrics, batch: 3072 acc, f1
0.79296875, 0.775274943686233
eval metrics, batch: 4096 acc, f1
0.775360107421875, 0.7435995680796963
train metrics, batch: 4096  acc, f1 
0.8848495483398438, 0.8808516349053476
eval metrics, batch: 5120 acc, f1
0.77880859375, 0.7503616449679686
eval metrics, batch: 6144 acc, f1
0.783966064453125, 0.7541928539185389
eval metrics, batch: 7168 acc, f1
0.790008544921875, 0.7737926953548769
Epoch loss - train: tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5861, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7498779296875, 0.693607476635514
train metrics acc, f1 
0.8785438537597656, 0.8697018681835853
Epoch 5/20
----------
eval metrics, batch: 1024 acc, f1
0.7735595703125, 0.7375309515387336
eval metrics, batch: 2048 acc, f1
0.768218994140625, 0.7233251976248588
eval metrics, batch: 3072 acc, f1
0.8045654296875, 0.7928044519218326
eval metrics, batch: 4096 acc, f1
0.7734375, 0.7399831885682264
train metrics, batch: 4096  acc, f1 
0.8989715576171875, 0.8957610107450703
eval metrics, batch: 5120 acc, f1
0.778228759765625, 0.7503178148084522
eval metrics, batch: 6144 acc, f1
0.750244140625, 0.6867008651711202
eval metrics, batch: 7168 acc, f1
0.77996826171875, 0.7492173913043478
Epoch loss - train: tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5375, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7537841796875, 0.7070230227322246
train metrics acc, f1 
0.9032096862792969, 0.8995061053615491
Epoch 6/20
----------
eval metrics, batch: 1024 acc, f1
0.79327392578125, 0.7731109324758842
eval metrics, batch: 2048 acc, f1
0.782623291015625, 0.7504991418263337
eval metrics, batch: 3072 acc, f1
0.819854736328125, 0.8200798561370356
eval metrics, batch: 4096 acc, f1
0.8099365234375, 0.8039289761994711
train metrics, batch: 4096  acc, f1 
0.9086875915527344, 0.9121839012990633
eval metrics, batch: 5120 acc, f1
0.788970947265625, 0.7620030975735673
eval metrics, batch: 6144 acc, f1
0.769561767578125, 0.7315390905535606
eval metrics, batch: 7168 acc, f1
0.786956787109375, 0.7599133335626096
Epoch loss - train: tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4394, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.804168701171875, 0.7930867700641666
train metrics acc, f1 
0.91693115234375, 0.9192512496477254
Epoch 7/20
----------
eval metrics, batch: 1024 acc, f1
0.810638427734375, 0.8027716855789708
eval metrics, batch: 2048 acc, f1
0.782623291015625, 0.7569854320903415
eval metrics, batch: 3072 acc, f1
0.761138916015625, 0.716361659720964
eval metrics, batch: 4096 acc, f1
0.742767333984375, 0.6893679749401143
train metrics, batch: 4096  acc, f1 
0.913482666015625, 0.9106594185771685
eval metrics, batch: 5120 acc, f1
0.745758056640625, 0.6879892138871203
eval metrics, batch: 6144 acc, f1
0.8023681640625, 0.7928607983623337
eval metrics, batch: 7168 acc, f1
0.80078125, 0.7858970154148901
Epoch loss - train: tensor(0.2140, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5390, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.78204345703125, 0.7523750086679148
train metrics acc, f1 
0.9312019348144531, 0.9305344246509388
Epoch 8/20
----------
eval metrics, batch: 1024 acc, f1
0.77813720703125, 0.7435987867672992
eval metrics, batch: 2048 acc, f1
0.76605224609375, 0.7260381673933243
eval metrics, batch: 3072 acc, f1
0.799072265625, 0.7794157062449746
eval metrics, batch: 4096 acc, f1
0.81005859375, 0.8012898282357448
train metrics, batch: 4096  acc, f1 
0.9251060485839844, 0.9271251303789434
eval metrics, batch: 5120 acc, f1
0.7899169921875, 0.771811190665606
eval metrics, batch: 6144 acc, f1
0.804473876953125, 0.7934092154902783
eval metrics, batch: 7168 acc, f1
0.7421875, 0.6839033151238494
Epoch loss - train: tensor(0.1919, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5236, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.783905029296875, 0.7550759226591954
train metrics acc, f1 
0.9430465698242188, 0.942948634664914
Epoch 9/20
----------
eval metrics, batch: 1024 acc, f1
0.76995849609375, 0.7324863368585421
eval metrics, batch: 2048 acc, f1
0.78143310546875, 0.7482601054481547
eval metrics, batch: 3072 acc, f1
0.795806884765625, 0.7744480026967807
eval metrics, batch: 4096 acc, f1
0.758819580078125, 0.712272909309353
train metrics, batch: 4096  acc, f1 
0.9419021606445312, 0.9402060398574054
eval metrics, batch: 5120 acc, f1
0.766815185546875, 0.7270779012037004
eval metrics, batch: 6144 acc, f1
0.7843017578125, 0.7557536802819822
eval metrics, batch: 7168 acc, f1
0.79669189453125, 0.7797540333245173
Epoch loss - train: tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5618, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.799407958984375, 0.7824158363401635
train metrics acc, f1 
0.9461860656738281, 0.9466131296808595
Epoch 10/20
----------
eval metrics, batch: 1024 acc, f1
0.77947998046875, 0.7553328367305479
eval metrics, batch: 2048 acc, f1
0.7724609375, 0.7416314366899993
eval metrics, batch: 3072 acc, f1
0.76495361328125, 0.724258914506659
eval metrics, batch: 4096 acc, f1
0.760528564453125, 0.720856604176301
train metrics, batch: 4096  acc, f1 
0.95501708984375, 0.9546590585756362
eval metrics, batch: 5120 acc, f1
0.793548583984375, 0.7680756968013988
eval metrics, batch: 6144 acc, f1
0.76226806640625, 0.7240133210515128
eval metrics, batch: 7168 acc, f1
0.787506103515625, 0.7626546681664792
Epoch loss - train: tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5692, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.807830810546875, 0.8029416366765765
train metrics acc, f1 
0.9370613098144531, 0.9396898040348138
Epoch 11/20
----------
eval metrics, batch: 1024 acc, f1
0.796234130859375, 0.7885620190633016
eval metrics, batch: 2048 acc, f1
0.7735595703125, 0.7407226221259348
eval metrics, batch: 3072 acc, f1
0.754180908203125, 0.7073994696501871
eval metrics, batch: 4096 acc, f1
0.79345703125, 0.7698272343898789
train metrics, batch: 4096  acc, f1 
0.9557113647460938, 0.9556948016760416
eval metrics, batch: 5120 acc, f1
0.775482177734375, 0.7472776613651197
eval metrics, batch: 6144 acc, f1
0.7708740234375, 0.7426475628984712
eval metrics, batch: 7168 acc, f1
0.78131103515625, 0.7470525944228733
Epoch loss - train: tensor(0.1254, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6184, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.79547119140625, 0.781166329262718
train metrics acc, f1 
0.9637336730957031, 0.9644368133409644
Epoch 12/20
----------
eval metrics, batch: 1024 acc, f1
0.768524169921875, 0.7306176084099869
eval metrics, batch: 2048 acc, f1
0.782562255859375, 0.7570829497800962
eval metrics, batch: 3072 acc, f1
0.795928955078125, 0.7902249270634
eval metrics, batch: 4096 acc, f1
0.79095458984375, 0.778474872259233
train metrics, batch: 4096  acc, f1 
0.9609146118164062, 0.9618693898209209
eval metrics, batch: 5120 acc, f1
0.79888916015625, 0.7908733181010409
eval metrics, batch: 6144 acc, f1
0.7596435546875, 0.7166294883787868
eval metrics, batch: 7168 acc, f1
0.76043701171875, 0.7419969762702951
Epoch loss - train: tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.7661, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.762115478515625, 0.7145211499725325
train metrics acc, f1 
0.9684257507324219, 0.9677167719112123
Epoch 13/20
----------
eval metrics, batch: 1024 acc, f1
0.780853271484375, 0.7524390664322405
eval metrics, batch: 2048 acc, f1
0.783905029296875, 0.7616065717267616
eval metrics, batch: 3072 acc, f1
0.76507568359375, 0.7262641348410497
eval metrics, batch: 4096 acc, f1
0.762664794921875, 0.7244446019204195
train metrics, batch: 4096  acc, f1 
0.9691581726074219, 0.9688802669715131
eval metrics, batch: 5120 acc, f1
0.77618408203125, 0.746333702268954
eval metrics, batch: 6144 acc, f1
0.787628173828125, 0.7785239171254893
eval metrics, batch: 7168 acc, f1
0.77215576171875, 0.7410875294770426
Epoch loss - train: tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.9471, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.74444580078125, 0.6908594211458948
train metrics acc, f1 
0.9753570556640625, 0.9750143106889243
Epoch 14/20
----------
eval metrics, batch: 1024 acc, f1
0.77398681640625, 0.7432572973722527
eval metrics, batch: 2048 acc, f1
0.791168212890625, 0.7926803405338262
eval metrics, batch: 3072 acc, f1
0.733428955078125, 0.6681104905201566
eval metrics, batch: 4096 acc, f1
0.770782470703125, 0.7378816960390857
train metrics, batch: 4096  acc, f1 
0.9793243408203125, 0.9792397616019857
eval metrics, batch: 5120 acc, f1
0.772674560546875, 0.7403172389750741
eval metrics, batch: 6144 acc, f1
0.796600341796875, 0.7823673469387755
eval metrics, batch: 7168 acc, f1
0.7908935546875, 0.7686385737439222
Epoch loss - train: tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.7854, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.78765869140625, 0.7756352379723978
train metrics acc, f1 
0.9731903076171875, 0.9737563387329256
Epoch 15/20
----------
eval metrics, batch: 1024 acc, f1
0.754241943359375, 0.700353488372093
eval metrics, batch: 2048 acc, f1
0.74822998046875, 0.7026384083044983
eval metrics, batch: 3072 acc, f1
0.735382080078125, 0.6823693175574197
eval metrics, batch: 4096 acc, f1
0.761688232421875, 0.7164385053923527
train metrics, batch: 4096  acc, f1 
0.9780044555664062, 0.9777686957326382
eval metrics, batch: 5120 acc, f1
0.778594970703125, 0.7634110549486385
eval metrics, batch: 6144 acc, f1
0.775238037109375, 0.742851157431654
eval metrics, batch: 7168 acc, f1
0.7615966796875, 0.7380984310044254
Epoch loss - train: tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.0611, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.750518798828125, 0.7067264573991031
train metrics acc, f1 
0.9803504943847656, 0.9802182103068079
Epoch 16/20
----------
eval metrics, batch: 1024 acc, f1
0.780975341796875, 0.7566871207241415
eval metrics, batch: 2048 acc, f1
0.7862548828125, 0.7651398296559587
eval metrics, batch: 3072 acc, f1
0.77783203125, 0.7552776657254269
eval metrics, batch: 4096 acc, f1
0.768218994140625, 0.7459101401759727
train metrics, batch: 4096  acc, f1 
0.9834861755371094, 0.9836610064578466
eval metrics, batch: 5120 acc, f1
0.783294677734375, 0.757404940043046
eval metrics, batch: 6144 acc, f1
0.785247802734375, 0.7656442535051786
eval metrics, batch: 7168 acc, f1
0.777191162109375, 0.7533362613601811
Epoch loss - train: tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.0666, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7777099609375, 0.755324151830702
train metrics acc, f1 
0.9874954223632812, 0.9875702444240526
Epoch 17/20
----------
eval metrics, batch: 1024 acc, f1
0.783660888671875, 0.7653814330630482
eval metrics, batch: 2048 acc, f1
0.766021728515625, 0.7301777230336091
eval metrics, batch: 3072 acc, f1
0.77734375, 0.7513461931701997
eval metrics, batch: 4096 acc, f1
0.744110107421875, 0.691557844399485
train metrics, batch: 4096  acc, f1 
0.9787139892578125, 0.978410919896001
eval metrics, batch: 5120 acc, f1
0.731109619140625, 0.6694180767643417
eval metrics, batch: 6144 acc, f1
0.771087646484375, 0.7371114148529773
eval metrics, batch: 7168 acc, f1
0.772003173828125, 0.7450953631990174
Epoch loss - train: tensor(0.0518, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1742, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7666015625, 0.7365665472581978
train metrics acc, f1 
0.9870529174804688, 0.987125603131733
Epoch 18/20
----------
eval metrics, batch: 1024 acc, f1
0.756805419921875, 0.7060385849717806
eval metrics, batch: 2048 acc, f1
0.76324462890625, 0.7310359173484954
eval metrics, batch: 3072 acc, f1
0.760498046875, 0.7242057913972448
eval metrics, batch: 4096 acc, f1
0.778045654296875, 0.758283758184054
train metrics, batch: 4096  acc, f1 
0.9854698181152344, 0.9856072428555774
eval metrics, batch: 5120 acc, f1
0.76806640625, 0.7351731828001952
eval metrics, batch: 6144 acc, f1
0.767608642578125, 0.737928898372165
eval metrics, batch: 7168 acc, f1
0.792694091796875, 0.777037450356123
Epoch loss - train: tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1535, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.784393310546875, 0.7597020509506479
train metrics acc, f1 
0.9934501647949219, 0.9934565299410439
Epoch 19/20
----------
eval metrics, batch: 1024 acc, f1
0.7845458984375, 0.7559795382275681
eval metrics, batch: 2048 acc, f1
0.77923583984375, 0.7500518277935181
eval metrics, batch: 3072 acc, f1
0.787353515625, 0.7709702866158296
eval metrics, batch: 4096 acc, f1
0.779205322265625, 0.7587770479778615
train metrics, batch: 4096  acc, f1 
0.9823951721191406, 0.9824837077606853
eval metrics, batch: 5120 acc, f1
0.792327880859375, 0.7763205469546067
eval metrics, batch: 6144 acc, f1
0.77703857421875, 0.7509035117627003
eval metrics, batch: 7168 acc, f1
0.741790771484375, 0.6821443329952289
Epoch loss - train: tensor(0.0427, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1532, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.78460693359375, 0.7570061282104248
train metrics acc, f1 
0.991851806640625, 0.991834737534213
Epoch 20/20
----------
eval metrics, batch: 1024 acc, f1
0.792236328125, 0.7755949634122223
eval metrics, batch: 2048 acc, f1
0.763641357421875, 0.7209109581636698
eval metrics, batch: 3072 acc, f1
0.790008544921875, 0.7762349191896198
eval metrics, batch: 4096 acc, f1
0.763153076171875, 0.727961022117845
train metrics, batch: 4096  acc, f1 
0.9880027770996094, 0.9879735532892044
eval metrics, batch: 5120 acc, f1
0.778900146484375, 0.7549798775744868
eval metrics, batch: 6144 acc, f1
0.7862548828125, 0.7579485761680951
eval metrics, batch: 7168 acc, f1
0.744049072265625, 0.6872039682243688
Epoch loss - train: tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.2987, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.76324462890625, 0.7313339797755922
train metrics acc, f1 
0.9931297302246094, 0.9931343135647818
Training time 236m 19s
train_acc
0.5	0.8039436340332031	0.8318824768066406	0.8448562622070312	0.85357666015625	0.8659400939941406	0.8748397827148438	0.8848495483398438	0.8785438537597656	0.8989715576171875	0.9032096862792969	0.9086875915527344	0.91693115234375	0.913482666015625	0.9312019348144531	0.9251060485839844	0.9430465698242188	0.9419021606445312	0.9461860656738281	0.95501708984375	0.9370613098144531	0.9557113647460938	0.9637336730957031	0.9609146118164062	0.9684257507324219	0.9691581726074219	0.9753570556640625	0.9793243408203125	0.9731903076171875	0.9780044555664062	0.9803504943847656	0.9834861755371094	0.9874954223632812	0.9787139892578125	0.9870529174804688	0.9854698181152344	0.9934501647949219	0.9823951721191406	0.991851806640625	0.9880027770996094	0.9931297302246094
train_f1
0.0	0.7997147411041702	0.835076584549867	0.8449225184552498	0.8614916066454006	0.8698026459593733	0.8792506992492272	0.8808516349053476	0.8697018681835853	0.8957610107450703	0.8995061053615491	0.9121839012990633	0.9192512496477254	0.9106594185771685	0.9305344246509388	0.9271251303789434	0.942948634664914	0.9402060398574054	0.9466131296808595	0.9546590585756362	0.9396898040348138	0.9556948016760416	0.9644368133409644	0.9618693898209209	0.9677167719112123	0.9688802669715131	0.9750143106889243	0.9792397616019857	0.9737563387329256	0.9777686957326382	0.9802182103068079	0.9836610064578466	0.9875702444240526	0.978410919896001	0.987125603131733	0.9856072428555774	0.9934565299410439	0.9824837077606853	0.991834737534213	0.9879735532892044	0.9931343135647818
train_loss
tensor(0.4487, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3734, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3287, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2140, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1919, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1254, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1066, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0913, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0781, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0667, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0575, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0518, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0460, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0427, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0386, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.500457763671875	0.76776123046875	0.75738525390625	0.763275146484375	0.774627685546875	0.797088623046875	0.7862548828125	0.774688720703125	0.795501708984375	0.760528564453125	0.7933349609375	0.7933349609375	0.79449462890625	0.795989990234375	0.792022705078125	0.795684814453125	0.80450439453125	0.796234130859375	0.79168701171875	0.79986572265625	0.79949951171875	0.77801513671875	0.776611328125	0.823577880859375	0.81353759765625	0.804962158203125	0.79571533203125	0.79296875	0.775360107421875	0.77880859375	0.783966064453125	0.790008544921875	0.7498779296875	0.7735595703125	0.768218994140625	0.8045654296875	0.7734375	0.778228759765625	0.750244140625	0.77996826171875	0.7537841796875	0.79327392578125	0.782623291015625	0.819854736328125	0.8099365234375	0.788970947265625	0.769561767578125	0.786956787109375	0.804168701171875	0.810638427734375	0.782623291015625	0.761138916015625	0.742767333984375	0.745758056640625	0.8023681640625	0.80078125	0.78204345703125	0.77813720703125	0.76605224609375	0.799072265625	0.81005859375	0.7899169921875	0.804473876953125	0.7421875	0.783905029296875	0.76995849609375	0.78143310546875	0.795806884765625	0.758819580078125	0.766815185546875	0.7843017578125	0.79669189453125	0.799407958984375	0.77947998046875	0.7724609375	0.76495361328125	0.760528564453125	0.793548583984375	0.76226806640625	0.787506103515625	0.807830810546875	0.796234130859375	0.7735595703125	0.754180908203125	0.79345703125	0.775482177734375	0.7708740234375	0.78131103515625	0.79547119140625	0.768524169921875	0.782562255859375	0.795928955078125	0.79095458984375	0.79888916015625	0.7596435546875	0.76043701171875	0.762115478515625	0.780853271484375	0.783905029296875	0.76507568359375	0.762664794921875	0.77618408203125	0.787628173828125	0.77215576171875	0.74444580078125	0.77398681640625	0.791168212890625	0.733428955078125	0.770782470703125	0.772674560546875	0.796600341796875	0.7908935546875	0.78765869140625	0.754241943359375	0.74822998046875	0.735382080078125	0.761688232421875	0.778594970703125	0.775238037109375	0.7615966796875	0.750518798828125	0.780975341796875	0.7862548828125	0.77783203125	0.768218994140625	0.783294677734375	0.785247802734375	0.777191162109375	0.7777099609375	0.783660888671875	0.766021728515625	0.77734375	0.744110107421875	0.731109619140625	0.771087646484375	0.772003173828125	0.7666015625	0.756805419921875	0.76324462890625	0.760498046875	0.778045654296875	0.76806640625	0.767608642578125	0.792694091796875	0.784393310546875	0.7845458984375	0.77923583984375	0.787353515625	0.779205322265625	0.792327880859375	0.77703857421875	0.741790771484375	0.78460693359375	0.792236328125	0.763641357421875	0.790008544921875	0.763153076171875	0.778900146484375	0.7862548828125	0.744049072265625	0.76324462890625
valid_f1
0.0	0.7746120127946926	0.7672580361847884	0.7712136852971538	0.7600636797816693	0.7970824304940947	0.7806726373144611	0.7461054369132364	0.7913306137701243	0.7854545454545454	0.7827258726899384	0.7744471089794831	0.784304932735426	0.7915562346044713	0.7767111169358802	0.7999043605606863	0.8085475194261805	0.782515227517019	0.7730868958180972	0.7860219263899765	0.7939793038570084	0.7432403812213202	0.7411049020301337	0.8255845527228843	0.8110231349746382	0.7958473087366236	0.7752635466326462	0.775274943686233	0.7435995680796963	0.7503616449679686	0.7541928539185389	0.7737926953548769	0.693607476635514	0.7375309515387336	0.7233251976248588	0.7928044519218326	0.7399831885682264	0.7503178148084522	0.6867008651711202	0.7492173913043478	0.7070230227322246	0.7731109324758842	0.7504991418263337	0.8200798561370356	0.8039289761994711	0.7620030975735673	0.7315390905535606	0.7599133335626096	0.7930867700641666	0.8027716855789708	0.7569854320903415	0.716361659720964	0.6893679749401143	0.6879892138871203	0.7928607983623337	0.7858970154148901	0.7523750086679148	0.7435987867672992	0.7260381673933243	0.7794157062449746	0.8012898282357448	0.771811190665606	0.7934092154902783	0.6839033151238494	0.7550759226591954	0.7324863368585421	0.7482601054481547	0.7744480026967807	0.712272909309353	0.7270779012037004	0.7557536802819822	0.7797540333245173	0.7824158363401635	0.7553328367305479	0.7416314366899993	0.724258914506659	0.720856604176301	0.7680756968013988	0.7240133210515128	0.7626546681664792	0.8029416366765765	0.7885620190633016	0.7407226221259348	0.7073994696501871	0.7698272343898789	0.7472776613651197	0.7426475628984712	0.7470525944228733	0.781166329262718	0.7306176084099869	0.7570829497800962	0.7902249270634	0.778474872259233	0.7908733181010409	0.7166294883787868	0.7419969762702951	0.7145211499725325	0.7524390664322405	0.7616065717267616	0.7262641348410497	0.7244446019204195	0.746333702268954	0.7785239171254893	0.7410875294770426	0.6908594211458948	0.7432572973722527	0.7926803405338262	0.6681104905201566	0.7378816960390857	0.7403172389750741	0.7823673469387755	0.7686385737439222	0.7756352379723978	0.700353488372093	0.7026384083044983	0.6823693175574197	0.7164385053923527	0.7634110549486385	0.742851157431654	0.7380984310044254	0.7067264573991031	0.7566871207241415	0.7651398296559587	0.7552776657254269	0.7459101401759727	0.757404940043046	0.7656442535051786	0.7533362613601811	0.755324151830702	0.7653814330630482	0.7301777230336091	0.7513461931701997	0.691557844399485	0.6694180767643417	0.7371114148529773	0.7450953631990174	0.7365665472581978	0.7060385849717806	0.7310359173484954	0.7242057913972448	0.758283758184054	0.7351731828001952	0.737928898372165	0.777037450356123	0.7597020509506479	0.7559795382275681	0.7500518277935181	0.7709702866158296	0.7587770479778615	0.7763205469546067	0.7509035117627003	0.6821443329952289	0.7570061282104248	0.7755949634122223	0.7209109581636698	0.7762349191896198	0.727961022117845	0.7549798775744868	0.7579485761680951	0.6872039682243688	0.7313339797755922
valid_loss
tensor(0.4310, device='cuda:0')	tensor(0.4167, device='cuda:0')	tensor(0.4156, device='cuda:0')	tensor(0.5861, device='cuda:0')	tensor(0.5375, device='cuda:0')	tensor(0.4394, device='cuda:0')	tensor(0.5390, device='cuda:0')	tensor(0.5236, device='cuda:0')	tensor(0.5618, device='cuda:0')	tensor(0.5692, device='cuda:0')	tensor(0.6184, device='cuda:0')	tensor(0.7661, device='cuda:0')	tensor(0.9471, device='cuda:0')	tensor(0.7854, device='cuda:0')	tensor(1.0611, device='cuda:0')	tensor(1.0666, device='cuda:0')	tensor(1.1742, device='cuda:0')	tensor(1.1535, device='cuda:0')	tensor(1.1532, device='cuda:0')	tensor(1.2987, device='cuda:0')
Best model metrics: train, valid, test: acc, f1
0.8748397827148438, 0.8792506992492272
0.81353759765625, 0.8110231349746382
0.78466796875, 0.776255707762557
Model saved, path ./models/alexnet_13-1559673726.pth
experiment validation
train set
Evaluation results
[[109879.  21193.]
 [ 11617. 119455.]]
#############################
Accuracy
0.8748397827148438
------------------------
Recall
0.9113693237304688
------------------------
Specificity
0.8383102416992188
------------------------
Precision
0.8493188669586486
------------------------
Fall_out
0.16168975830078125
------------------------
F1
0.8792506992492272
------------------------
#############################
valid set
Evaluation results
[[13547.  2852.]
 [ 3258. 13111.]]
#############################
Accuracy
0.81353759765625
------------------------
Recall
0.8009652391716049
------------------------
Specificity
0.8260869565217391
------------------------
Precision
0.8213368414458435
------------------------
Fall_out
0.17391304347826086
------------------------
F1
0.8110231349746382
------------------------
#############################
test set
Evaluation results
[[13472.  2919.]
 [ 4137. 12240.]]
#############################
Accuracy
0.78466796875
------------------------
Recall
0.7473896318006961
------------------------
Specificity
0.8219144652553231
------------------------
Precision
0.8074411240847021
------------------------
Fall_out
0.17808553474467695
------------------------
F1
0.776255707762557
------------------------
#############################
AUC: 0.8662283921435148
Experiment end
########################################
----------------------------------------
Starting experiment alexnet_14-1559673726
Experiment parameters Experiment[name: alexnet_14-1559673726, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 1e-06, weight_decay: 0, batch_size: 32, num_epochs: 20), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-06
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.499542236328125, 0.6662596414107496
train metrics acc, f1
0.5, 0.6666666666666666
Epoch 1/20
----------
eval metrics, batch: 1024 acc, f1
0.661865234375, 0.5695750135964571
eval metrics, batch: 2048 acc, f1
0.738311767578125, 0.7120260603821742
eval metrics, batch: 3072 acc, f1
0.747039794921875, 0.7374655560130491
eval metrics, batch: 4096 acc, f1
0.750701904296875, 0.7318562284588872
train metrics, batch: 4096  acc, f1 
0.7716827392578125, 0.7645494527973816
eval metrics, batch: 5120 acc, f1
0.744781494140625, 0.7234914861960655
eval metrics, batch: 6144 acc, f1
0.75872802734375, 0.7657203816748651
eval metrics, batch: 7168 acc, f1
0.753021240234375, 0.7378275940263695
Epoch loss - train: tensor(0.5167, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4836, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.755462646484375, 0.7488953652345586
train metrics acc, f1 
0.7800521850585938, 0.7839051338365478
Epoch 2/20
----------
eval metrics, batch: 1024 acc, f1
0.755767822265625, 0.7528336267333766
eval metrics, batch: 2048 acc, f1
0.7567138671875, 0.7465988556897648
eval metrics, batch: 3072 acc, f1
0.758392333984375, 0.7559569680342776
eval metrics, batch: 4096 acc, f1
0.763153076171875, 0.7609572796993871
train metrics, batch: 4096  acc, f1 
0.7827949523925781, 0.7884087268997655
eval metrics, batch: 5120 acc, f1
0.76678466796875, 0.7720847002684164
eval metrics, batch: 6144 acc, f1
0.76666259765625, 0.7639686361671915
eval metrics, batch: 7168 acc, f1
0.75323486328125, 0.7350589777195282
Epoch loss - train: tensor(0.4722, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4809, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.76434326171875, 0.7536056158264199
train metrics acc, f1 
0.7867965698242188, 0.7847420679242958
Epoch 3/20
----------
eval metrics, batch: 1024 acc, f1
0.770355224609375, 0.7714363818607053
eval metrics, batch: 2048 acc, f1
0.766632080078125, 0.7712054573198097
eval metrics, batch: 3072 acc, f1
0.7620849609375, 0.7442592835585881
eval metrics, batch: 4096 acc, f1
0.774932861328125, 0.7772239842924029
train metrics, batch: 4096  acc, f1 
0.7910118103027344, 0.7982485536573779
eval metrics, batch: 5120 acc, f1
0.77166748046875, 0.7694867213013741
eval metrics, batch: 6144 acc, f1
0.765777587890625, 0.7478232298340726
eval metrics, batch: 7168 acc, f1
0.772003173828125, 0.7786435957453113
Epoch loss - train: tensor(0.4549, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4817, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.771392822265625, 0.7636535731187885
train metrics acc, f1 
0.7968559265136719, 0.7972032765534496
Epoch 4/20
----------
eval metrics, batch: 1024 acc, f1
0.7774658203125, 0.773526305981738
eval metrics, batch: 2048 acc, f1
0.774627685546875, 0.7703169222156564
eval metrics, batch: 3072 acc, f1
0.7735595703125, 0.780200248829907
eval metrics, batch: 4096 acc, f1
0.777984619140625, 0.7692600463065749
train metrics, batch: 4096  acc, f1 
0.8040962219238281, 0.8029453634316016
eval metrics, batch: 5120 acc, f1
0.779052734375, 0.7735660223931945
eval metrics, batch: 6144 acc, f1
0.77703857421875, 0.7703815450374002
eval metrics, batch: 7168 acc, f1
0.774627685546875, 0.7858985881193286
Epoch loss - train: tensor(0.4383, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4843, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.767181396484375, 0.7459794226351014
train metrics acc, f1 
0.8049850463867188, 0.7962406434589907
Epoch 5/20
----------
eval metrics, batch: 1024 acc, f1
0.778106689453125, 0.770782762208001
eval metrics, batch: 2048 acc, f1
0.7666015625, 0.7433040209438142
eval metrics, batch: 3072 acc, f1
0.7828369140625, 0.778772617049058
eval metrics, batch: 4096 acc, f1
0.774993896484375, 0.7635419005163401
train metrics, batch: 4096  acc, f1 
0.8131828308105469, 0.8111563985794217
eval metrics, batch: 5120 acc, f1
0.735137939453125, 0.6788529139685476
eval metrics, batch: 6144 acc, f1
0.780029296875, 0.7745386299655928
eval metrics, batch: 7168 acc, f1
0.77752685546875, 0.7768731635651323
Epoch loss - train: tensor(0.4266, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4794, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.77191162109375, 0.7575580640975736
train metrics acc, f1 
0.8153114318847656, 0.8121767939511734
Epoch 6/20
----------
eval metrics, batch: 1024 acc, f1
0.773162841796875, 0.7570518058506291
eval metrics, batch: 2048 acc, f1
0.76910400390625, 0.7491711974539186
eval metrics, batch: 3072 acc, f1
0.78076171875, 0.7799828494426069
eval metrics, batch: 4096 acc, f1
0.776611328125, 0.7627689914441276
train metrics, batch: 4096  acc, f1 
0.8175392150878906, 0.8137008603934675
eval metrics, batch: 5120 acc, f1
0.767181396484375, 0.7445846864642272
eval metrics, batch: 6144 acc, f1
0.77947998046875, 0.7741027885457047
eval metrics, batch: 7168 acc, f1
0.778717041015625, 0.7674694545104704
Epoch loss - train: tensor(0.4161, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4593, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.779815673828125, 0.7809720409216478
train metrics acc, f1 
0.8190040588378906, 0.825940695033952
Epoch 7/20
----------
eval metrics, batch: 1024 acc, f1
0.78106689453125, 0.7770249269596569
eval metrics, batch: 2048 acc, f1
0.76116943359375, 0.7288100353454848
eval metrics, batch: 3072 acc, f1
0.781036376953125, 0.7768481945697135
eval metrics, batch: 4096 acc, f1
0.777130126953125, 0.7658469332136331
train metrics, batch: 4096  acc, f1 
0.8232841491699219, 0.8221204243767015
eval metrics, batch: 5120 acc, f1
0.78179931640625, 0.7696075272282014
eval metrics, batch: 6144 acc, f1
0.7767333984375, 0.7798507462686567
eval metrics, batch: 7168 acc, f1
0.7763671875, 0.7746062992125984
Epoch loss - train: tensor(0.4076, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4699, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.778717041015625, 0.7766930491823473
train metrics acc, f1 
0.8237686157226562, 0.8294294870848163
Epoch 8/20
----------
eval metrics, batch: 1024 acc, f1
0.7901611328125, 0.7909776264591439
eval metrics, batch: 2048 acc, f1
0.77423095703125, 0.7610619469026548
eval metrics, batch: 3072 acc, f1
0.78204345703125, 0.771529110684581
eval metrics, batch: 4096 acc, f1
0.778076171875, 0.7858531126685906
train metrics, batch: 4096  acc, f1 
0.8180046081542969, 0.8300543937078556
eval metrics, batch: 5120 acc, f1
0.773101806640625, 0.7620114593002785
eval metrics, batch: 6144 acc, f1
0.7740478515625, 0.757801766437684
eval metrics, batch: 7168 acc, f1
0.7801513671875, 0.7733165512901196
Epoch loss - train: tensor(0.3997, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4791, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.772674560546875, 0.7655999244784292
train metrics acc, f1 
0.8262901306152344, 0.829342697492439
Epoch 9/20
----------
eval metrics, batch: 1024 acc, f1
0.78662109375, 0.7939286766872974
eval metrics, batch: 2048 acc, f1
0.77276611328125, 0.7531167108753316
eval metrics, batch: 3072 acc, f1
0.7867431640625, 0.7825762289981332
eval metrics, batch: 4096 acc, f1
0.780181884765625, 0.7696145849992004
train metrics, batch: 4096  acc, f1 
0.83013916015625, 0.8302337107781463
eval metrics, batch: 5120 acc, f1
0.77423095703125, 0.7656339099030602
eval metrics, batch: 6144 acc, f1
0.769073486328125, 0.7437781464802086
eval metrics, batch: 7168 acc, f1
0.7840576171875, 0.7862364811793849
Epoch loss - train: tensor(0.3928, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4469, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.792694091796875, 0.7993264600750347
train metrics acc, f1 
0.8265533447265625, 0.8368755650589096
Epoch 10/20
----------
eval metrics, batch: 1024 acc, f1
0.766143798828125, 0.7450001663838142
eval metrics, batch: 2048 acc, f1
0.778717041015625, 0.7701816107254921
eval metrics, batch: 3072 acc, f1
0.7813720703125, 0.7776536312849162
eval metrics, batch: 4096 acc, f1
0.7569580078125, 0.7303812038729772
train metrics, batch: 4096  acc, f1 
0.8298683166503906, 0.8245494636049993
eval metrics, batch: 5120 acc, f1
0.7763671875, 0.75783212161269
eval metrics, batch: 6144 acc, f1
0.72528076171875, 0.6584199741974652
eval metrics, batch: 7168 acc, f1
0.78155517578125, 0.7733375554148195
Epoch loss - train: tensor(0.3854, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5080, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.76458740234375, 0.7532941025969042
train metrics acc, f1 
0.8266677856445312, 0.8292099862429806
Epoch 11/20
----------
eval metrics, batch: 1024 acc, f1
0.7818603515625, 0.7843740573152338
eval metrics, batch: 2048 acc, f1
0.768798828125, 0.7492055084745762
eval metrics, batch: 3072 acc, f1
0.781402587890625, 0.7681651940317831
eval metrics, batch: 4096 acc, f1
0.7808837890625, 0.7724679934085436
train metrics, batch: 4096  acc, f1 
0.8368873596191406, 0.839268194581753
eval metrics, batch: 5120 acc, f1
0.78570556640625, 0.7805076269067267
eval metrics, batch: 6144 acc, f1
0.7760009765625, 0.785643361953157
eval metrics, batch: 7168 acc, f1
0.7823486328125, 0.7711902470324029
Epoch loss - train: tensor(0.3795, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4748, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.77691650390625, 0.7706306871666144
train metrics acc, f1 
0.8360939025878906, 0.8408871245477538
Epoch 12/20
----------
eval metrics, batch: 1024 acc, f1
0.78460693359375, 0.7763766554717698
eval metrics, batch: 2048 acc, f1
0.773406982421875, 0.7629386034928642
eval metrics, batch: 3072 acc, f1
0.776947021484375, 0.7873992844469008
eval metrics, batch: 4096 acc, f1
0.7896728515625, 0.7913791015861484
train metrics, batch: 4096  acc, f1 
0.8367691040039062, 0.8450513477889309
eval metrics, batch: 5120 acc, f1
0.77593994140625, 0.762240932642487
eval metrics, batch: 6144 acc, f1
0.738128662109375, 0.6844640558926274
eval metrics, batch: 7168 acc, f1
0.782440185546875, 0.7719522727999744
Epoch loss - train: tensor(0.3732, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4889, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.772369384765625, 0.7509266370588039
train metrics acc, f1 
0.8383293151855469, 0.8341894921341633
Epoch 13/20
----------
eval metrics, batch: 1024 acc, f1
0.77764892578125, 0.7636410822033348
eval metrics, batch: 2048 acc, f1
0.766876220703125, 0.7385605256853417
eval metrics, batch: 3072 acc, f1
0.775787353515625, 0.7571159377169493
eval metrics, batch: 4096 acc, f1
0.77838134765625, 0.7687702986690441
train metrics, batch: 4096  acc, f1 
0.8439369201660156, 0.8468263387859477
eval metrics, batch: 5120 acc, f1
0.77471923828125, 0.761486268174475
eval metrics, batch: 6144 acc, f1
0.783905029296875, 0.7869030064100635
eval metrics, batch: 7168 acc, f1
0.772979736328125, 0.7537162721403741
Epoch loss - train: tensor(0.3674, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4895, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.765869140625, 0.7359399738418118
train metrics acc, f1 
0.83984375, 0.8320277179870852
Epoch 14/20
----------
eval metrics, batch: 1024 acc, f1
0.769866943359375, 0.7405827513846366
eval metrics, batch: 2048 acc, f1
0.78228759765625, 0.7861382576893099
eval metrics, batch: 3072 acc, f1
0.759918212890625, 0.7303698118380917
eval metrics, batch: 4096 acc, f1
0.76812744140625, 0.7439336748449716
train metrics, batch: 4096  acc, f1 
0.8461189270019531, 0.8424214724621376
eval metrics, batch: 5120 acc, f1
0.784515380859375, 0.7735915605861416
eval metrics, batch: 6144 acc, f1
0.779083251953125, 0.7746193841651359
eval metrics, batch: 7168 acc, f1
0.772369384765625, 0.7484571544194517
Epoch loss - train: tensor(0.3632, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4737, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.78143310546875, 0.7753450439146801
train metrics acc, f1 
0.8460693359375, 0.8510270685352275
Epoch 15/20
----------
eval metrics, batch: 1024 acc, f1
0.76971435546875, 0.7398110475139645
eval metrics, batch: 2048 acc, f1
0.78564453125, 0.7849620377173647
eval metrics, batch: 3072 acc, f1
0.788726806640625, 0.7923702126383348
eval metrics, batch: 4096 acc, f1
0.7496337890625, 0.7073971039303802
train metrics, batch: 4096  acc, f1 
0.8393135070800781, 0.8289706079393888
eval metrics, batch: 5120 acc, f1
0.782989501953125, 0.7897087091527428
eval metrics, batch: 6144 acc, f1
0.774444580078125, 0.7554996857322439
eval metrics, batch: 7168 acc, f1
0.77301025390625, 0.7510042849491162
Epoch loss - train: tensor(0.3575, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5468, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.74365234375, 0.6953872932985204
train metrics acc, f1 
0.8365478515625, 0.8232386987120781
Epoch 16/20
----------
eval metrics, batch: 1024 acc, f1
0.78692626953125, 0.7788406715235984
eval metrics, batch: 2048 acc, f1
0.74554443359375, 0.6995098745855557
eval metrics, batch: 3072 acc, f1
0.775970458984375, 0.7658298510319308
eval metrics, batch: 4096 acc, f1
0.775238037109375, 0.7732939329577985
train metrics, batch: 4096  acc, f1 
0.8453636169433594, 0.8534597128985963
eval metrics, batch: 5120 acc, f1
0.776824951171875, 0.7641804520976427
eval metrics, batch: 6144 acc, f1
0.7828369140625, 0.7771514468245021
eval metrics, batch: 7168 acc, f1
0.76318359375, 0.7315436241610739
Epoch loss - train: tensor(0.3526, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4592, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.785064697265625, 0.7745013287228252
train metrics acc, f1 
0.8547401428222656, 0.8568883677404079
Epoch 17/20
----------
eval metrics, batch: 1024 acc, f1
0.786773681640625, 0.778239756244644
eval metrics, batch: 2048 acc, f1
0.768096923828125, 0.7532071059725245
eval metrics, batch: 3072 acc, f1
0.768463134765625, 0.7385325843471069
eval metrics, batch: 4096 acc, f1
0.78460693359375, 0.7775466464952093
train metrics, batch: 4096  acc, f1 
0.8517913818359375, 0.8551930287511834
eval metrics, batch: 5120 acc, f1
0.789215087890625, 0.7826004847187686
eval metrics, batch: 6144 acc, f1
0.7662353515625, 0.734064713234273
eval metrics, batch: 7168 acc, f1
0.765167236328125, 0.7368241047915456
Epoch loss - train: tensor(0.3478, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5178, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.765106201171875, 0.738241795612991
train metrics acc, f1 
0.8525886535644531, 0.8488269743096224
Epoch 18/20
----------
eval metrics, batch: 1024 acc, f1
0.779541015625, 0.7595366486918315
eval metrics, batch: 2048 acc, f1
0.778717041015625, 0.7634180560540311
eval metrics, batch: 3072 acc, f1
0.78326416015625, 0.7848921734916404
eval metrics, batch: 4096 acc, f1
0.781982421875, 0.7652625353223369
train metrics, batch: 4096  acc, f1 
0.8586311340332031, 0.8579129587951798
eval metrics, batch: 5120 acc, f1
0.786895751953125, 0.7879634409255154
eval metrics, batch: 6144 acc, f1
0.77313232421875, 0.7511881652051677
eval metrics, batch: 7168 acc, f1
0.784637451171875, 0.7854297789534495
Epoch loss - train: tensor(0.3435, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4655, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.789031982421875, 0.7814209378063047
train metrics acc, f1 
0.8559646606445312, 0.8595813995001785
Epoch 19/20
----------
eval metrics, batch: 1024 acc, f1
0.78753662109375, 0.7937551842635383
eval metrics, batch: 2048 acc, f1
0.765380859375, 0.7350427350427351
eval metrics, batch: 3072 acc, f1
0.78338623046875, 0.7669577779236982
eval metrics, batch: 4096 acc, f1
0.79095458984375, 0.788788850518007
train metrics, batch: 4096  acc, f1 
0.8517951965332031, 0.8585101152648542
eval metrics, batch: 5120 acc, f1
0.778106689453125, 0.7719188180306785
eval metrics, batch: 6144 acc, f1
0.786224365234375, 0.7776966773507664
eval metrics, batch: 7168 acc, f1
0.769775390625, 0.74273632519438
Epoch loss - train: tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4875, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.779571533203125, 0.7578693305621669
train metrics acc, f1 
0.8580398559570312, 0.8552389991908882
Epoch 20/20
----------
eval metrics, batch: 1024 acc, f1
0.786041259765625, 0.7798536753854366
eval metrics, batch: 2048 acc, f1
0.764434814453125, 0.726480280642075
eval metrics, batch: 3072 acc, f1
0.78564453125, 0.7774680015207198
eval metrics, batch: 4096 acc, f1
0.788177490234375, 0.7820516846170754
train metrics, batch: 4096  acc, f1 
0.8592605590820312, 0.8634637731575714
eval metrics, batch: 5120 acc, f1
0.764007568359375, 0.7286952250640284
eval metrics, batch: 6144 acc, f1
0.77874755859375, 0.7576871657754011
eval metrics, batch: 7168 acc, f1
0.758758544921875, 0.7196709103159686
Epoch loss - train: tensor(0.3348, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4657, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.785980224609375, 0.7703140863983231
train metrics acc, f1 
0.8637161254882812, 0.8640169912151154
Training time 565m 23s
train_acc
0.5	0.7716827392578125	0.7800521850585938	0.7827949523925781	0.7867965698242188	0.7910118103027344	0.7968559265136719	0.8040962219238281	0.8049850463867188	0.8131828308105469	0.8153114318847656	0.8175392150878906	0.8190040588378906	0.8232841491699219	0.8237686157226562	0.8180046081542969	0.8262901306152344	0.83013916015625	0.8265533447265625	0.8298683166503906	0.8266677856445312	0.8368873596191406	0.8360939025878906	0.8367691040039062	0.8383293151855469	0.8439369201660156	0.83984375	0.8461189270019531	0.8460693359375	0.8393135070800781	0.8365478515625	0.8453636169433594	0.8547401428222656	0.8517913818359375	0.8525886535644531	0.8586311340332031	0.8559646606445312	0.8517951965332031	0.8580398559570312	0.8592605590820312	0.8637161254882812
train_f1
0.6666666666666666	0.7645494527973816	0.7839051338365478	0.7884087268997655	0.7847420679242958	0.7982485536573779	0.7972032765534496	0.8029453634316016	0.7962406434589907	0.8111563985794217	0.8121767939511734	0.8137008603934675	0.825940695033952	0.8221204243767015	0.8294294870848163	0.8300543937078556	0.829342697492439	0.8302337107781463	0.8368755650589096	0.8245494636049993	0.8292099862429806	0.839268194581753	0.8408871245477538	0.8450513477889309	0.8341894921341633	0.8468263387859477	0.8320277179870852	0.8424214724621376	0.8510270685352275	0.8289706079393888	0.8232386987120781	0.8534597128985963	0.8568883677404079	0.8551930287511834	0.8488269743096224	0.8579129587951798	0.8595813995001785	0.8585101152648542	0.8552389991908882	0.8634637731575714	0.8640169912151154
train_loss
tensor(0.5167, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4722, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4549, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4383, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4266, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4161, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4076, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3997, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3928, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3854, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3795, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3732, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3674, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3632, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3575, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3526, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3478, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3435, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3348, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.499542236328125	0.661865234375	0.738311767578125	0.747039794921875	0.750701904296875	0.744781494140625	0.75872802734375	0.753021240234375	0.755462646484375	0.755767822265625	0.7567138671875	0.758392333984375	0.763153076171875	0.76678466796875	0.76666259765625	0.75323486328125	0.76434326171875	0.770355224609375	0.766632080078125	0.7620849609375	0.774932861328125	0.77166748046875	0.765777587890625	0.772003173828125	0.771392822265625	0.7774658203125	0.774627685546875	0.7735595703125	0.777984619140625	0.779052734375	0.77703857421875	0.774627685546875	0.767181396484375	0.778106689453125	0.7666015625	0.7828369140625	0.774993896484375	0.735137939453125	0.780029296875	0.77752685546875	0.77191162109375	0.773162841796875	0.76910400390625	0.78076171875	0.776611328125	0.767181396484375	0.77947998046875	0.778717041015625	0.779815673828125	0.78106689453125	0.76116943359375	0.781036376953125	0.777130126953125	0.78179931640625	0.7767333984375	0.7763671875	0.778717041015625	0.7901611328125	0.77423095703125	0.78204345703125	0.778076171875	0.773101806640625	0.7740478515625	0.7801513671875	0.772674560546875	0.78662109375	0.77276611328125	0.7867431640625	0.780181884765625	0.77423095703125	0.769073486328125	0.7840576171875	0.792694091796875	0.766143798828125	0.778717041015625	0.7813720703125	0.7569580078125	0.7763671875	0.72528076171875	0.78155517578125	0.76458740234375	0.7818603515625	0.768798828125	0.781402587890625	0.7808837890625	0.78570556640625	0.7760009765625	0.7823486328125	0.77691650390625	0.78460693359375	0.773406982421875	0.776947021484375	0.7896728515625	0.77593994140625	0.738128662109375	0.782440185546875	0.772369384765625	0.77764892578125	0.766876220703125	0.775787353515625	0.77838134765625	0.77471923828125	0.783905029296875	0.772979736328125	0.765869140625	0.769866943359375	0.78228759765625	0.759918212890625	0.76812744140625	0.784515380859375	0.779083251953125	0.772369384765625	0.78143310546875	0.76971435546875	0.78564453125	0.788726806640625	0.7496337890625	0.782989501953125	0.774444580078125	0.77301025390625	0.74365234375	0.78692626953125	0.74554443359375	0.775970458984375	0.775238037109375	0.776824951171875	0.7828369140625	0.76318359375	0.785064697265625	0.786773681640625	0.768096923828125	0.768463134765625	0.78460693359375	0.789215087890625	0.7662353515625	0.765167236328125	0.765106201171875	0.779541015625	0.778717041015625	0.78326416015625	0.781982421875	0.786895751953125	0.77313232421875	0.784637451171875	0.789031982421875	0.78753662109375	0.765380859375	0.78338623046875	0.79095458984375	0.778106689453125	0.786224365234375	0.769775390625	0.779571533203125	0.786041259765625	0.764434814453125	0.78564453125	0.788177490234375	0.764007568359375	0.77874755859375	0.758758544921875	0.785980224609375
valid_f1
0.6662596414107496	0.5695750135964571	0.7120260603821742	0.7374655560130491	0.7318562284588872	0.7234914861960655	0.7657203816748651	0.7378275940263695	0.7488953652345586	0.7528336267333766	0.7465988556897648	0.7559569680342776	0.7609572796993871	0.7720847002684164	0.7639686361671915	0.7350589777195282	0.7536056158264199	0.7714363818607053	0.7712054573198097	0.7442592835585881	0.7772239842924029	0.7694867213013741	0.7478232298340726	0.7786435957453113	0.7636535731187885	0.773526305981738	0.7703169222156564	0.780200248829907	0.7692600463065749	0.7735660223931945	0.7703815450374002	0.7858985881193286	0.7459794226351014	0.770782762208001	0.7433040209438142	0.778772617049058	0.7635419005163401	0.6788529139685476	0.7745386299655928	0.7768731635651323	0.7575580640975736	0.7570518058506291	0.7491711974539186	0.7799828494426069	0.7627689914441276	0.7445846864642272	0.7741027885457047	0.7674694545104704	0.7809720409216478	0.7770249269596569	0.7288100353454848	0.7768481945697135	0.7658469332136331	0.7696075272282014	0.7798507462686567	0.7746062992125984	0.7766930491823473	0.7909776264591439	0.7610619469026548	0.771529110684581	0.7858531126685906	0.7620114593002785	0.757801766437684	0.7733165512901196	0.7655999244784292	0.7939286766872974	0.7531167108753316	0.7825762289981332	0.7696145849992004	0.7656339099030602	0.7437781464802086	0.7862364811793849	0.7993264600750347	0.7450001663838142	0.7701816107254921	0.7776536312849162	0.7303812038729772	0.75783212161269	0.6584199741974652	0.7733375554148195	0.7532941025969042	0.7843740573152338	0.7492055084745762	0.7681651940317831	0.7724679934085436	0.7805076269067267	0.785643361953157	0.7711902470324029	0.7706306871666144	0.7763766554717698	0.7629386034928642	0.7873992844469008	0.7913791015861484	0.762240932642487	0.6844640558926274	0.7719522727999744	0.7509266370588039	0.7636410822033348	0.7385605256853417	0.7571159377169493	0.7687702986690441	0.761486268174475	0.7869030064100635	0.7537162721403741	0.7359399738418118	0.7405827513846366	0.7861382576893099	0.7303698118380917	0.7439336748449716	0.7735915605861416	0.7746193841651359	0.7484571544194517	0.7753450439146801	0.7398110475139645	0.7849620377173647	0.7923702126383348	0.7073971039303802	0.7897087091527428	0.7554996857322439	0.7510042849491162	0.6953872932985204	0.7788406715235984	0.6995098745855557	0.7658298510319308	0.7732939329577985	0.7641804520976427	0.7771514468245021	0.7315436241610739	0.7745013287228252	0.778239756244644	0.7532071059725245	0.7385325843471069	0.7775466464952093	0.7826004847187686	0.734064713234273	0.7368241047915456	0.738241795612991	0.7595366486918315	0.7634180560540311	0.7848921734916404	0.7652625353223369	0.7879634409255154	0.7511881652051677	0.7854297789534495	0.7814209378063047	0.7937551842635383	0.7350427350427351	0.7669577779236982	0.788788850518007	0.7719188180306785	0.7776966773507664	0.74273632519438	0.7578693305621669	0.7798536753854366	0.726480280642075	0.7774680015207198	0.7820516846170754	0.7286952250640284	0.7576871657754011	0.7196709103159686	0.7703140863983231
valid_loss
tensor(0.4836, device='cuda:0')	tensor(0.4809, device='cuda:0')	tensor(0.4817, device='cuda:0')	tensor(0.4843, device='cuda:0')	tensor(0.4794, device='cuda:0')	tensor(0.4593, device='cuda:0')	tensor(0.4699, device='cuda:0')	tensor(0.4791, device='cuda:0')	tensor(0.4469, device='cuda:0')	tensor(0.5080, device='cuda:0')	tensor(0.4748, device='cuda:0')	tensor(0.4889, device='cuda:0')	tensor(0.4895, device='cuda:0')	tensor(0.4737, device='cuda:0')	tensor(0.5468, device='cuda:0')	tensor(0.4592, device='cuda:0')	tensor(0.5178, device='cuda:0')	tensor(0.4655, device='cuda:0')	tensor(0.4875, device='cuda:0')	tensor(0.4657, device='cuda:0')
Best model metrics: train, valid, test: acc, f1
0.8265533447265625, 0.8368755650589096
0.792694091796875, 0.7993264600750347
0.768768310546875, 0.7694227199415721
Model saved, path ./models/alexnet_14-1559673726.pth
experiment validation
train set
Evaluation results
[[100044.  31028.]
 [ 14440. 116632.]]
#############################
Accuracy
0.8265533447265625
------------------------
Recall
0.88983154296875
------------------------
Specificity
0.763275146484375
------------------------
Precision
0.7898686170933225
------------------------
Fall_out
0.236724853515625
------------------------
F1
0.8368755650589096
------------------------
#############################
valid set
Evaluation results
[[12446.  3953.]
 [ 2840. 13529.]]
#############################
Accuracy
0.792694091796875
------------------------
Recall
0.8265013134583664
------------------------
Specificity
0.7589487163851454
------------------------
Precision
0.7738817068985242
------------------------
Fall_out
0.24105128361485456
------------------------
F1
0.7993264600750347
------------------------
#############################
test set
Evaluation results
[[12549.  3842.]
 [ 3735. 12642.]]
#############################
Accuracy
0.768768310546875
------------------------
Recall
0.771936252060817
------------------------
Specificity
0.7656030748581538
------------------------
Precision
0.7669255035185635
------------------------
Fall_out
0.23439692514184612
------------------------
F1
0.7694227199415721
------------------------
#############################
AUC: 0.8478922659409084
Experiment end
########################################
