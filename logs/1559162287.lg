----------------------------------------
Starting experiment alexnet_sgd-1559162287
Experiment parameters Experiment[name: alexnet_sgd-1559162287, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 0.001, weight_decay: 0, batch_size: 32, num_epochs: 10), optimizer: SGD (
Parameter Group 0
    dampening: 0
    lr: 0.001
    momentum: 0
    nesterov: False
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.5106201171875, 0.667854183927092
train metrics acc, f1
0.49529266357421875, 0.6543242777194275
Epoch 1/10
----------
eval metrics, batch: 1024 acc, f1
0.794830322265625, 0.7967224019593021
eval metrics, batch: 2048 acc, f1
0.80267333984375, 0.7927696942503686
eval metrics, batch: 3072 acc, f1
0.808074951171875, 0.791748071128183
eval metrics, batch: 4096 acc, f1
0.81561279296875, 0.8121502300708867
train metrics, batch: 4096  acc, f1 
0.8601722717285156, 0.8631351771158879
eval metrics, batch: 5120 acc, f1
0.813720703125, 0.8032237266279819
eval metrics, batch: 6144 acc, f1
0.807037353515625, 0.783925093121006
eval metrics, batch: 7168 acc, f1
0.817779541015625, 0.8006809760656942
Epoch loss - train: tensor(0.3425, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3636, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.836700439453125, 0.8366256526119745
train metrics acc, f1 
0.8781852722167969, 0.8820350278353448
Epoch 2/10
----------
eval metrics, batch: 1024 acc, f1
0.827362060546875, 0.8158348797083048
eval metrics, batch: 2048 acc, f1
0.830352783203125, 0.8228658828027913
eval metrics, batch: 3072 acc, f1
0.813262939453125, 0.7931722156498225
eval metrics, batch: 4096 acc, f1
0.7845458984375, 0.7440359654847364
train metrics, batch: 4096  acc, f1 
0.88037109375, 0.871586981802696
eval metrics, batch: 5120 acc, f1
0.83050537109375, 0.8215295629820052
eval metrics, batch: 6144 acc, f1
0.828826904296875, 0.8241086267992097
eval metrics, batch: 7168 acc, f1
0.796600341796875, 0.7624309392265194
Epoch loss - train: tensor(0.2736, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3927, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.821990966796875, 0.8049098632061273
train metrics acc, f1 
0.9021263122558594, 0.9005245751639055
Epoch 3/10
----------
eval metrics, batch: 1024 acc, f1
0.833709716796875, 0.8254253035594143
eval metrics, batch: 2048 acc, f1
0.83514404296875, 0.8291263364332258
eval metrics, batch: 3072 acc, f1
0.842437744140625, 0.8407120599759356
eval metrics, batch: 4096 acc, f1
0.8173828125, 0.7964764301748181
train metrics, batch: 4096  acc, f1 
0.9097404479980469, 0.9077554648483643
eval metrics, batch: 5120 acc, f1
0.818817138671875, 0.796503856041131
eval metrics, batch: 6144 acc, f1
0.8330078125, 0.8224414303329223
eval metrics, batch: 7168 acc, f1
0.83502197265625, 0.8299037190862752
Epoch loss - train: tensor(0.2420, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4119, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.821319580078125, 0.8040954261049955
train metrics acc, f1 
0.9108543395996094, 0.9104131445680134
Epoch 4/10
----------
eval metrics, batch: 1024 acc, f1
0.835723876953125, 0.8279367108838102
eval metrics, batch: 2048 acc, f1
0.804962158203125, 0.7770607318519552
eval metrics, batch: 3072 acc, f1
0.833892822265625, 0.8250458037350133
eval metrics, batch: 4096 acc, f1
0.825958251953125, 0.8212505876821815
train metrics, batch: 4096  acc, f1 
0.901519775390625, 0.9052700332450224
eval metrics, batch: 5120 acc, f1
0.827972412109375, 0.8100805228934335
eval metrics, batch: 6144 acc, f1
0.8458251953125, 0.841808617234469
eval metrics, batch: 7168 acc, f1
0.81890869140625, 0.7941727367325703
Epoch loss - train: tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4306, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.818756103515625, 0.7955664176792537
train metrics acc, f1 
0.9198799133300781, 0.9180213972623058
Epoch 5/10
----------
eval metrics, batch: 1024 acc, f1
0.831146240234375, 0.8172177992137689
eval metrics, batch: 2048 acc, f1
0.82891845703125, 0.8113855056860239
eval metrics, batch: 3072 acc, f1
0.8125, 0.7857441763146883
eval metrics, batch: 4096 acc, f1
0.813812255859375, 0.7892209362584212
train metrics, batch: 4096  acc, f1 
0.9268302917480469, 0.9254130648654745
eval metrics, batch: 5120 acc, f1
0.83447265625, 0.8203973509933775
eval metrics, batch: 6144 acc, f1
0.826934814453125, 0.8122371949806311
eval metrics, batch: 7168 acc, f1
0.822052001953125, 0.8044535363358932
Epoch loss - train: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4813, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.807891845703125, 0.7766542487138549
train metrics acc, f1 
0.9262466430664062, 0.9236757542022944
Epoch 6/10
----------
eval metrics, batch: 1024 acc, f1
0.81317138671875, 0.7853887681413447
eval metrics, batch: 2048 acc, f1
0.80670166015625, 0.7802068151849538
eval metrics, batch: 3072 acc, f1
0.806793212890625, 0.7769125057260651
eval metrics, batch: 4096 acc, f1
0.81781005859375, 0.7916957431960921
train metrics, batch: 4096  acc, f1 
0.9321365356445312, 0.930443690276974
eval metrics, batch: 5120 acc, f1
0.83013916015625, 0.8167994207096307
eval metrics, batch: 6144 acc, f1
0.8363037109375, 0.8247516989022478
eval metrics, batch: 7168 acc, f1
0.8310546875, 0.814040980853208
Epoch loss - train: tensor(0.1894, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4320, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.82611083984375, 0.807539012362359
train metrics acc, f1 
0.9333534240722656, 0.9332400964466812
Epoch 7/10
----------
eval metrics, batch: 1024 acc, f1
0.844818115234375, 0.8394734349843735
eval metrics, batch: 2048 acc, f1
0.829132080078125, 0.8148295135099382
eval metrics, batch: 3072 acc, f1
0.830841064453125, 0.8145719733716924
eval metrics, batch: 4096 acc, f1
0.7969970703125, 0.7605988627366299
train metrics, batch: 4096  acc, f1 
0.9361953735351562, 0.9343800511589222
eval metrics, batch: 5120 acc, f1
0.849609375, 0.8440506329113924
eval metrics, batch: 6144 acc, f1
0.835235595703125, 0.8265047077348244
eval metrics, batch: 7168 acc, f1
0.831817626953125, 0.8156671237916848
Epoch loss - train: tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4311, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.816619873046875, 0.7938947007374378
train metrics acc, f1 
0.9412002563476562, 0.9407632296990892
Epoch 8/10
----------
eval metrics, batch: 1024 acc, f1
0.8387451171875, 0.8306518812896609
eval metrics, batch: 2048 acc, f1
0.834320068359375, 0.8191237714476095
eval metrics, batch: 3072 acc, f1
0.81365966796875, 0.7857243121841662
eval metrics, batch: 4096 acc, f1
0.840576171875, 0.8332056194125159
train metrics, batch: 4096  acc, f1 
0.9327621459960938, 0.9343826549226039
eval metrics, batch: 5120 acc, f1
0.841705322265625, 0.8325531846208477
eval metrics, batch: 6144 acc, f1
0.832244873046875, 0.8160246326851635
eval metrics, batch: 7168 acc, f1
0.82489013671875, 0.8046571798188874
Epoch loss - train: tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4124, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.82958984375, 0.8175997909453191
train metrics acc, f1 
0.9395332336425781, 0.9406878281140668
Epoch 9/10
----------
eval metrics, batch: 1024 acc, f1
0.820831298828125, 0.7983236577238845
eval metrics, batch: 2048 acc, f1
0.844146728515625, 0.837382582391339
eval metrics, batch: 3072 acc, f1
0.81463623046875, 0.7903927117123335
eval metrics, batch: 4096 acc, f1
0.813629150390625, 0.7875752200076525
train metrics, batch: 4096  acc, f1 
0.9464836120605469, 0.9457713731295975
eval metrics, batch: 5120 acc, f1
0.83782958984375, 0.8273890729552394
eval metrics, batch: 6144 acc, f1
0.838897705078125, 0.8307741625260459
eval metrics, batch: 7168 acc, f1
0.840301513671875, 0.8302792462621218
Epoch loss - train: tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5159, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8087158203125, 0.776732920139631
train metrics acc, f1 
0.9464454650878906, 0.9449910466943299
Epoch 10/10
----------
eval metrics, batch: 1024 acc, f1
0.843048095703125, 0.8387622660438285
eval metrics, batch: 2048 acc, f1
0.8355712890625, 0.8227165043432483
eval metrics, batch: 3072 acc, f1
0.830841064453125, 0.81570635369219
eval metrics, batch: 4096 acc, f1
0.8228759765625, 0.8004949814381961
train metrics, batch: 4096  acc, f1 
0.9522285461425781, 0.9518184931111564
eval metrics, batch: 5120 acc, f1
0.7369384765625, 0.6539820166987798
eval metrics, batch: 6144 acc, f1
0.810882568359375, 0.7816343070580358
eval metrics, batch: 7168 acc, f1
0.811309814453125, 0.784
Epoch loss - train: tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4332, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.82659912109375, 0.8084417773582361
train metrics acc, f1 
0.9505119323730469, 0.9505445701193594
Training time 111m 35s
train_acc
0.49529266357421875	0.8601722717285156	0.8781852722167969	0.88037109375	0.9021263122558594	0.9097404479980469	0.9108543395996094	0.901519775390625	0.9198799133300781	0.9268302917480469	0.9262466430664062	0.9321365356445312	0.9333534240722656	0.9361953735351562	0.9412002563476562	0.9327621459960938	0.9395332336425781	0.9464836120605469	0.9464454650878906	0.9522285461425781	0.9505119323730469
train_f1
0.6543242777194275	0.8631351771158879	0.8820350278353448	0.871586981802696	0.9005245751639055	0.9077554648483643	0.9104131445680134	0.9052700332450224	0.9180213972623058	0.9254130648654745	0.9236757542022944	0.930443690276974	0.9332400964466812	0.9343800511589222	0.9407632296990892	0.9343826549226039	0.9406878281140668	0.9457713731295975	0.9449910466943299	0.9518184931111564	0.9505445701193594
train_loss
tensor(0.3425, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2736, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2420, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1894, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1668, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1568, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1486, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.5106201171875	0.794830322265625	0.80267333984375	0.808074951171875	0.81561279296875	0.813720703125	0.807037353515625	0.817779541015625	0.836700439453125	0.827362060546875	0.830352783203125	0.813262939453125	0.7845458984375	0.83050537109375	0.828826904296875	0.796600341796875	0.821990966796875	0.833709716796875	0.83514404296875	0.842437744140625	0.8173828125	0.818817138671875	0.8330078125	0.83502197265625	0.821319580078125	0.835723876953125	0.804962158203125	0.833892822265625	0.825958251953125	0.827972412109375	0.8458251953125	0.81890869140625	0.818756103515625	0.831146240234375	0.82891845703125	0.8125	0.813812255859375	0.83447265625	0.826934814453125	0.822052001953125	0.807891845703125	0.81317138671875	0.80670166015625	0.806793212890625	0.81781005859375	0.83013916015625	0.8363037109375	0.8310546875	0.82611083984375	0.844818115234375	0.829132080078125	0.830841064453125	0.7969970703125	0.849609375	0.835235595703125	0.831817626953125	0.816619873046875	0.8387451171875	0.834320068359375	0.81365966796875	0.840576171875	0.841705322265625	0.832244873046875	0.82489013671875	0.82958984375	0.820831298828125	0.844146728515625	0.81463623046875	0.813629150390625	0.83782958984375	0.838897705078125	0.840301513671875	0.8087158203125	0.843048095703125	0.8355712890625	0.830841064453125	0.8228759765625	0.7369384765625	0.810882568359375	0.811309814453125	0.82659912109375
valid_f1
0.667854183927092	0.7967224019593021	0.7927696942503686	0.791748071128183	0.8121502300708867	0.8032237266279819	0.783925093121006	0.8006809760656942	0.8366256526119745	0.8158348797083048	0.8228658828027913	0.7931722156498225	0.7440359654847364	0.8215295629820052	0.8241086267992097	0.7624309392265194	0.8049098632061273	0.8254253035594143	0.8291263364332258	0.8407120599759356	0.7964764301748181	0.796503856041131	0.8224414303329223	0.8299037190862752	0.8040954261049955	0.8279367108838102	0.7770607318519552	0.8250458037350133	0.8212505876821815	0.8100805228934335	0.841808617234469	0.7941727367325703	0.7955664176792537	0.8172177992137689	0.8113855056860239	0.7857441763146883	0.7892209362584212	0.8203973509933775	0.8122371949806311	0.8044535363358932	0.7766542487138549	0.7853887681413447	0.7802068151849538	0.7769125057260651	0.7916957431960921	0.8167994207096307	0.8247516989022478	0.814040980853208	0.807539012362359	0.8394734349843735	0.8148295135099382	0.8145719733716924	0.7605988627366299	0.8440506329113924	0.8265047077348244	0.8156671237916848	0.7938947007374378	0.8306518812896609	0.8191237714476095	0.7857243121841662	0.8332056194125159	0.8325531846208477	0.8160246326851635	0.8046571798188874	0.8175997909453191	0.7983236577238845	0.837382582391339	0.7903927117123335	0.7875752200076525	0.8273890729552394	0.8307741625260459	0.8302792462621218	0.776732920139631	0.8387622660438285	0.8227165043432483	0.81570635369219	0.8004949814381961	0.6539820166987798	0.7816343070580358	0.784	0.8084417773582361
valid_loss
tensor(0.3636, device='cuda:0')	tensor(0.3927, device='cuda:0')	tensor(0.4119, device='cuda:0')	tensor(0.4306, device='cuda:0')	tensor(0.4813, device='cuda:0')	tensor(0.4320, device='cuda:0')	tensor(0.4311, device='cuda:0')	tensor(0.4124, device='cuda:0')	tensor(0.5159, device='cuda:0')	tensor(0.4332, device='cuda:0')
Best model metrics: train, valid, test: acc, f1
0.8781852722167969, 0.8820350278353448
0.836700439453125, 0.8366256526119745
0.795928955078125, 0.7841162227602906
Model saved, path ./models/alexnet_sgd-1559162287.pth
experiment validation
train set
Evaluation results
[[110828.  20244.]
 [ 11689. 119383.]]
#############################
Accuracy
0.8781852722167969
------------------------
Recall
0.9108200073242188
------------------------
Specificity
0.845550537109375
------------------------
Precision
0.8550137151124066
------------------------
Fall_out
0.154449462890625
------------------------
F1
0.8820350278353448
------------------------
#############################
valid set
Evaluation results
[[13716.  2683.]
 [ 2668. 13701.]]
#############################
Accuracy
0.836700439453125
------------------------
Recall
0.8370089803897611
------------------------
Specificity
0.8363924629550582
------------------------
Precision
0.83624267578125
------------------------
Fall_out
0.16360753704494177
------------------------
F1
0.8366256526119745
------------------------
#############################
test set
Evaluation results
[[13937.  2454.]
 [ 4233. 12144.]]
#############################
Accuracy
0.795928955078125
------------------------
Recall
0.7415277523355926
------------------------
Specificity
0.8502836922701482
------------------------
Precision
0.8318947801068639
------------------------
Fall_out
0.14971630772985176
------------------------
F1
0.7841162227602906
------------------------
#############################
AUC: 0.8771230596267802
Experiment end
########################################
