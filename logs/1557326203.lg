----------------------------------------
Starting experiment alexnet_1
Experiment parameters Experiment[name: alexnet_1, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 1e-05, weight_decay: 0, batch_size: 32, num_epochs: 10), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.48601766190075696, 0.6224710424710425
train metrics acc, f1
0.49529266357421875, 0.6543242777194275
Epoch 1/10
----------
eval metrics, batch: 1024 acc, f1
0.8014849074975657, 0.8039427815843251
eval metrics, batch: 2048 acc, f1
0.8097028392685275, 0.7974128269988153
eval metrics, batch: 3072 acc, f1
0.8307570593963, 0.8243874715837333
eval metrics, batch: 4096 acc, f1
0.7682836669699727, 0.7426821181597145
train metrics, batch: 4096  acc, f1 
0.8946571350097656, 0.88965519997123
eval metrics, batch: 5120 acc, f1
0.8257775119617224, 0.8154226333797998
eval metrics, batch: 6144 acc, f1
0.8086200673724735, 0.7951582268293468
eval metrics, batch: 7168 acc, f1
0.8334644240077445, 0.8266305545932667
Epoch loss - train: tensor(0.2832, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3834, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8232665547024952, 0.8158955293823612
train metrics acc, f1 
0.918548583984375, 0.92
Epoch 2/10
----------
eval metrics, batch: 1024 acc, f1
0.7988887582314205, 0.7820435212030459
eval metrics, batch: 2048 acc, f1
0.800711429915334, 0.7844172364445858
eval metrics, batch: 3072 acc, f1
0.7966545155221072, 0.7809759032329565
eval metrics, batch: 4096 acc, f1
0.7235138773819387, 0.6966624059082517
train metrics, batch: 4096  acc, f1 
0.9233970642089844, 0.919757846996064
eval metrics, batch: 5120 acc, f1
0.7822063456345635, 0.765114515395116
eval metrics, batch: 6144 acc, f1
0.8121811224489796, 0.8001480613220642
eval metrics, batch: 7168 acc, f1
0.7849264705882353, 0.7676514619168372
Epoch loss - train: tensor(0.1909, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4258, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8092642257462687, 0.7952561254185312
train metrics acc, f1 
0.9391708374023438, 0.9391327582258188
Epoch 3/10
----------
eval metrics, batch: 1024 acc, f1
0.776519495412844, 0.7534398228688913
eval metrics, batch: 2048 acc, f1
0.8436589805825243, 0.8379508789584578
eval metrics, batch: 3072 acc, f1
0.781870487364621, 0.7618255728011826
eval metrics, batch: 4096 acc, f1
0.768348623853211, 0.7408429020463148
train metrics, batch: 4096  acc, f1 
0.9497146606445312, 0.9495282874383557
eval metrics, batch: 5120 acc, f1
0.8217768791627021, 0.8110340479192938
eval metrics, batch: 6144 acc, f1
0.813675917215428, 0.8012044413775798
eval metrics, batch: 7168 acc, f1
0.7849628712871287, 0.7687048074304904
Epoch loss - train: tensor(0.1499, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4488, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7966581868640148, 0.781144990665837
train metrics acc, f1 
0.9565925598144531, 0.9568341230070065
Epoch 4/10
----------
eval metrics, batch: 1024 acc, f1
0.7655972468916519, 0.7440916252575446
eval metrics, batch: 2048 acc, f1
0.7888726372637264, 0.7747028454796494
eval metrics, batch: 3072 acc, f1
0.7238493723849372, 0.6970392471884324
eval metrics, batch: 4096 acc, f1
0.7630369796279893, 0.7414298227068169
train metrics, batch: 4096  acc, f1 
0.9625091552734375, 0.9623335709522386
eval metrics, batch: 5120 acc, f1
0.7943313953488372, 0.7765671877467235
eval metrics, batch: 6144 acc, f1
0.7128059791332263, 0.6902372386182271
eval metrics, batch: 7168 acc, f1
0.7911154197080292, 0.774320744254821
Epoch loss - train: tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5869, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7629663330300273, 0.7372833280806808
train metrics acc, f1 
0.9663925170898438, 0.9664613487029945
Epoch 5/10
----------
eval metrics, batch: 1024 acc, f1
0.8178504233301975, 0.8065321925935177
eval metrics, batch: 2048 acc, f1
0.7146388426311407, 0.6842665898949186
eval metrics, batch: 3072 acc, f1
0.748120095902354, 0.7230626366713597
eval metrics, batch: 4096 acc, f1
0.7053751005631537, 0.6796424373308548
train metrics, batch: 4096  acc, f1 
0.968536376953125, 0.9679038672571193
eval metrics, batch: 5120 acc, f1
0.7474720309810671, 0.7232537577365163
eval metrics, batch: 6144 acc, f1
0.7263241525423729, 0.6968612496333235
eval metrics, batch: 7168 acc, f1
0.7348175965665236, 0.707306963524396
Epoch loss - train: tensor(0.0971, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5888, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7595132263660017, 0.7391751668185426
train metrics acc, f1 
0.9765548706054688, 0.9764197635070326
Epoch 6/10
----------
eval metrics, batch: 1024 acc, f1
0.6805364173228347, 0.6467691470548225
eval metrics, batch: 2048 acc, f1
0.7201656879194631, 0.6901416627960985
eval metrics, batch: 3072 acc, f1
0.7363693998309383, 0.7124416527401602
eval metrics, batch: 4096 acc, f1
0.7313880628717078, 0.7045009784735812
train metrics, batch: 4096  acc, f1 
0.97747802734375, 0.9772573189522342
eval metrics, batch: 5120 acc, f1
0.6943725099601593, 0.6651023192360164
eval metrics, batch: 6144 acc, f1
0.7693080357142857, 0.7504677974286231
eval metrics, batch: 7168 acc, f1
0.7317596566523605, 0.7031231445196533
Epoch loss - train: tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6981, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7621100615114236, 0.7405277503219816
train metrics acc, f1 
0.9843521118164062, 0.9843156147957818
Epoch 7/10
----------
eval metrics, batch: 1024 acc, f1
0.7917717889908257, 0.7754799220996013
eval metrics, batch: 2048 acc, f1
0.7216193656093489, 0.6936678339743958
eval metrics, batch: 3072 acc, f1
0.7047448979591837, 0.6746683157184619
eval metrics, batch: 4096 acc, f1
0.7179235537190083, 0.6902614712721911
train metrics, batch: 4096  acc, f1 
0.9808425903320312, 0.9806160259379342
eval metrics, batch: 5120 acc, f1
0.7654997773820125, 0.7432905839705121
eval metrics, batch: 6144 acc, f1
0.734375, 0.7099243230800218
eval metrics, batch: 7168 acc, f1
0.714808326463314, 0.6873941036936632
Epoch loss - train: tensor(0.0616, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8423, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7287341101694915, 0.7016399172759313
train metrics acc, f1 
0.9884071350097656, 0.9883737389581125
Epoch 8/10
----------
eval metrics, batch: 1024 acc, f1
0.7639705882352941, 0.740145712684476
eval metrics, batch: 2048 acc, f1
0.7006048387096774, 0.6715328467153284
eval metrics, batch: 3072 acc, f1
0.7754275427542754, 0.7561988518382802
eval metrics, batch: 4096 acc, f1
0.7173674874791319, 0.687509012776512
train metrics, batch: 4096  acc, f1 
0.9820213317871094, 0.9817928956365533
eval metrics, batch: 5120 acc, f1
0.756801791958042, 0.7342308725633601
eval metrics, batch: 6144 acc, f1
0.7127722032450897, 0.6748436603123773
eval metrics, batch: 7168 acc, f1
0.7059004934210527, 0.6750156187879821
Epoch loss - train: tensor(0.0484, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.0620, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7173640167364017, 0.6882067851373183
train metrics acc, f1 
0.9913749694824219, 0.9913379944449765
Epoch 9/10
----------
eval metrics, batch: 1024 acc, f1
0.7495697074010327, 0.7283705734787935
eval metrics, batch: 2048 acc, f1
0.7346523668639053, 0.7094049237712269
eval metrics, batch: 3072 acc, f1
0.774904106498195, 0.7537412447159739
eval metrics, batch: 4096 acc, f1
0.7589719522968198, 0.7371526627931481
train metrics, batch: 4096  acc, f1 
0.9917221069335938, 0.9917229278712286
eval metrics, batch: 5120 acc, f1
0.7589833479404031, 0.7369679579148732
eval metrics, batch: 6144 acc, f1
0.7541118421052632, 0.7241434161549963
eval metrics, batch: 7168 acc, f1
0.7241397621070518, 0.6929124549269965
Epoch loss - train: tensor(0.0391, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1057, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7182089859851608, 0.691330849983068
train metrics acc, f1 
0.991424560546875, 0.9913791119871761
Epoch 10/10
----------
eval metrics, batch: 1024 acc, f1
0.7479347826086956, 0.7235995232419548
eval metrics, batch: 2048 acc, f1
0.7254068047337278, 0.6971065590489234
eval metrics, batch: 3072 acc, f1
0.7453250222617988, 0.7148554336989033
eval metrics, batch: 4096 acc, f1
0.7282309322033899, 0.7001519401589528
train metrics, batch: 4096  acc, f1 
0.993743896484375, 0.9937229685765683
eval metrics, batch: 5120 acc, f1
0.7569382770870338, 0.7319745378871343
eval metrics, batch: 6144 acc, f1
0.7417064180398959, 0.7154374440131382
eval metrics, batch: 7168 acc, f1
0.7397301762114538, 0.7096476948121756
Epoch loss - train: tensor(0.0320, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1391, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7345879471890971, 0.7085610732762401
train metrics acc, f1 
0.9963836669921875, 0.9963795789923925
Training time 119m 1s
Experiment end
########################################
----------------------------------------
Starting experiment alexnet_2
Experiment parameters Experiment[name: alexnet_2, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 0.001, weight_decay: 0, batch_size: 32, num_epochs: 10), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.44818115234375, 0.22261392949269132
train metrics acc, f1
0.4727134704589844, 0.2693814122385551
Epoch 1/10
----------
eval metrics, batch: 1024 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 2048 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 3072 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 4096 acc, f1
0.46516750580945004, 0.5970492221837215
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 6144 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 7168 acc, f1
0.42228105509355507, 0.3505632748452592
Epoch loss - train: tensor(0.6940, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6931, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.46516750580945004, 0.5970492221837215
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 2/10
----------
eval metrics, batch: 1024 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 2048 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 3072 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 4096 acc, f1
0.42228105509355507, 0.3505632748452592
train metrics, batch: 4096  acc, f1 
0.5, 0.0
eval metrics, batch: 5120 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 6144 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 7168 acc, f1
0.46516750580945004, 0.5970492221837215
Epoch loss - train: tensor(0.8752, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.46516750580945004, 0.5970492221837215
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 3/10
----------
eval metrics, batch: 1024 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 2048 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 3072 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 4096 acc, f1
0.46516750580945004, 0.5970492221837215
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 6144 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 7168 acc, f1
0.42228105509355507, 0.3505632748452592
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.42228105509355507, 0.3505632748452592
train metrics acc, f1 
0.5, 0.0
Epoch 4/10
----------
eval metrics, batch: 1024 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 2048 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 3072 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 4096 acc, f1
0.46516750580945004, 0.5970492221837215
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 6144 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 7168 acc, f1
0.42228105509355507, 0.3505632748452592
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.46516750580945004, 0.5970492221837215
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 5/10
----------
eval metrics, batch: 1024 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 2048 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 3072 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 4096 acc, f1
0.46516750580945004, 0.5970492221837215
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 6144 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 7168 acc, f1
0.46516750580945004, 0.5970492221837215
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.46516750580945004, 0.5970492221837215
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 6/10
----------
eval metrics, batch: 1024 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 2048 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 3072 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 4096 acc, f1
0.46516750580945004, 0.5970492221837215
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 6144 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 7168 acc, f1
0.42228105509355507, 0.3505632748452592
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6931, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.42228105509355507, 0.3505632748452592
train metrics acc, f1 
0.5, 0.0
Epoch 7/10
----------
eval metrics, batch: 1024 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 2048 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 3072 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 4096 acc, f1
0.46516750580945004, 0.5970492221837215
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 6144 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 7168 acc, f1
0.42228105509355507, 0.3505632748452592
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.46516750580945004, 0.5970492221837215
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 8/10
----------
eval metrics, batch: 1024 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 2048 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 3072 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 4096 acc, f1
0.46516750580945004, 0.5970492221837215
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 6144 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 7168 acc, f1
0.42228105509355507, 0.3505632748452592
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.46516750580945004, 0.5970492221837215
train metrics acc, f1 
0.5, 0.6666666666666666
Epoch 9/10
----------
eval metrics, batch: 1024 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 2048 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 3072 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 4096 acc, f1
0.46516750580945004, 0.5970492221837215
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 6144 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 7168 acc, f1
0.42228105509355507, 0.3505632748452592
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.42228105509355507, 0.3505632748452592
train metrics acc, f1 
0.5, 0.0
Epoch 10/10
----------
eval metrics, batch: 1024 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 2048 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 3072 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 4096 acc, f1
0.46516750580945004, 0.5970492221837215
train metrics, batch: 4096  acc, f1 
0.5, 0.6666666666666666
eval metrics, batch: 5120 acc, f1
0.46516750580945004, 0.5970492221837215
eval metrics, batch: 6144 acc, f1
0.42228105509355507, 0.3505632748452592
eval metrics, batch: 7168 acc, f1
0.42228105509355507, 0.3505632748452592
Epoch loss - train: tensor(0.6932, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6932, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.42228105509355507, 0.3505632748452592
train metrics acc, f1 
0.5, 0.0
Training time 118m 46s
Experiment end
########################################
----------------------------------------
Starting experiment alexnet_3
Experiment parameters Experiment[name: alexnet_3, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 0.0001, weight_decay: 0, batch_size: 32, num_epochs: 10), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.4696394686907021, 0.13266097750193948
train metrics acc, f1
0.4830207824707031, 0.14623113995023151
Epoch 1/10
----------
eval metrics, batch: 1024 acc, f1
0.8336781888997079, 0.8291554666499968
eval metrics, batch: 2048 acc, f1
0.8138191838649156, 0.8017480880287186
eval metrics, batch: 3072 acc, f1
0.8140537054409006, 0.8045119733719605
eval metrics, batch: 4096 acc, f1
0.799739110707804, 0.7855320699708455
train metrics, batch: 4096  acc, f1 
0.9086265563964844, 0.9060522981946258
eval metrics, batch: 5120 acc, f1
0.7661042944785276, 0.7458787121347379
eval metrics, batch: 6144 acc, f1
0.8285832544938505, 0.8216219542210189
eval metrics, batch: 7168 acc, f1
0.7751341201716738, 0.7625414270741864
Epoch loss - train: tensor(0.2741, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4069, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.820532363977486, 0.8095326986497418
train metrics acc, f1 
0.9236068725585938, 0.9237586897428673
Epoch 2/10
----------
eval metrics, batch: 1024 acc, f1
0.8177771226415095, 0.804528636033016
eval metrics, batch: 2048 acc, f1
0.687621879875195, 0.6596914252330244
eval metrics, batch: 3072 acc, f1
0.837915062560154, 0.8340671860085599
eval metrics, batch: 4096 acc, f1
0.7605690619621343, 0.7424422136719993
train metrics, batch: 4096  acc, f1 
0.9399032592773438, 0.9388217933284144
eval metrics, batch: 5120 acc, f1
0.6948515139751553, 0.6708883946094466
eval metrics, batch: 6144 acc, f1
0.7958715596330275, 0.7819829750750199
eval metrics, batch: 7168 acc, f1
0.8054454291044776, 0.7915938046465151
Epoch loss - train: tensor(0.1870, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4292, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8087811346863468, 0.7954103821597113
train metrics acc, f1 
0.9510955810546875, 0.9513738222754927
Epoch 3/10
----------
eval metrics, batch: 1024 acc, f1
0.7546434671221178, 0.734645578388363
eval metrics, batch: 2048 acc, f1
0.7395921163575042, 0.7163562265017364
eval metrics, batch: 3072 acc, f1
0.6639953438395415, 0.645840215185692
eval metrics, batch: 4096 acc, f1
0.7569204152249135, 0.736613942589338
train metrics, batch: 4096  acc, f1 
0.954925537109375, 0.9545062526951272
eval metrics, batch: 5120 acc, f1
0.7484939759036144, 0.7262455359756455
eval metrics, batch: 6144 acc, f1
0.6907302833078101, 0.6691750492718012
eval metrics, batch: 7168 acc, f1
0.7688210227272727, 0.7501844909525637
Epoch loss - train: tensor(0.1471, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4690, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8171188026192704, 0.8058830830333871
train metrics acc, f1 
0.9560432434082031, 0.956708606808354
Epoch 4/10
----------
eval metrics, batch: 1024 acc, f1
0.7380554357204486, 0.7094535993061578
eval metrics, batch: 2048 acc, f1
0.774256993006993, 0.7580229561958304
eval metrics, batch: 3072 acc, f1
0.79796974522293, 0.7835095523934307
eval metrics, batch: 4096 acc, f1
0.7406793478260869, 0.7143755050731795
train metrics, batch: 4096  acc, f1 
0.9594802856445312, 0.9592370864993476
eval metrics, batch: 5120 acc, f1
0.7880232558139535, 0.7683608640406607
eval metrics, batch: 6144 acc, f1
0.679881599378882, 0.6503047972435727
eval metrics, batch: 7168 acc, f1
0.668026706231454, 0.6434618065929688
Epoch loss - train: tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4673, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7902547127468582, 0.7755261340778768
train metrics acc, f1 
0.9692878723144531, 0.9693137423055667
Epoch 5/10
----------
eval metrics, batch: 1024 acc, f1
0.7904329919857525, 0.777905570792415
eval metrics, batch: 2048 acc, f1
0.6806633232399697, 0.6576551444295098
eval metrics, batch: 3072 acc, f1
0.7341988291413704, 0.7032228778937812
eval metrics, batch: 4096 acc, f1
0.7864535681610247, 0.7678055149687568
train metrics, batch: 4096  acc, f1 
0.971466064453125, 0.9717063206869161
eval metrics, batch: 5120 acc, f1
0.7955670567056705, 0.7818465602113098
eval metrics, batch: 6144 acc, f1
0.7996136992619927, 0.7830456630980992
eval metrics, batch: 7168 acc, f1
0.7642475512021372, 0.7407747383881036
Epoch loss - train: tensor(0.0958, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5540, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7999349574266793, 0.7838088239992332
train metrics acc, f1 
0.9648666381835938, 0.9655185323848746
Epoch 6/10
----------
eval metrics, batch: 1024 acc, f1
0.6871882194934766, 0.6639874281886802
eval metrics, batch: 2048 acc, f1
0.7614701394943331, 0.741915514547652
eval metrics, batch: 3072 acc, f1
0.7280073221757322, 0.7024119481559898
eval metrics, batch: 4096 acc, f1
0.7539881993006993, 0.7310517828346175
train metrics, batch: 4096  acc, f1 
0.9829750061035156, 0.9829367977152208
eval metrics, batch: 5120 acc, f1
0.743114406779661, 0.7210078232857801
eval metrics, batch: 6144 acc, f1
0.8059919724770642, 0.7920980675289564
eval metrics, batch: 7168 acc, f1
0.7039576802507836, 0.6818612485524792
Epoch loss - train: tensor(0.0793, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5983, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7955232558139534, 0.7773768831497658
train metrics acc, f1 
0.9776496887207031, 0.9778592347661785
Epoch 7/10
----------
eval metrics, batch: 1024 acc, f1
0.7150059904153354, 0.6944607974310945
eval metrics, batch: 2048 acc, f1
0.7098635113904164, 0.6912890165861303
eval metrics, batch: 3072 acc, f1
0.725671315570358, 0.7011367179748845
eval metrics, batch: 4096 acc, f1
0.7113586082059533, 0.6866966844044208
train metrics, batch: 4096  acc, f1 
0.9732437133789062, 0.9727996153010889
eval metrics, batch: 5120 acc, f1
0.8018313953488372, 0.7873740681825271
eval metrics, batch: 6144 acc, f1
0.6974014683153014, 0.6758756272957732
eval metrics, batch: 7168 acc, f1
0.7376805437553101, 0.7140872786202107
Epoch loss - train: tensor(0.0650, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8208, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7092303005686433, 0.6817802967161194
train metrics acc, f1 
0.9882850646972656, 0.9881976764295569
Epoch 8/10
----------
eval metrics, batch: 1024 acc, f1
0.7308442242833052, 0.704998989228059
eval metrics, batch: 2048 acc, f1
0.7836755415162455, 0.7659587452703528
eval metrics, batch: 3072 acc, f1
0.7364130434782609, 0.7191937950622679
eval metrics, batch: 4096 acc, f1
0.7889471863468634, 0.7701051970482022
train metrics, batch: 4096  acc, f1 
0.9828567504882812, 0.9829995536153375
eval metrics, batch: 5120 acc, f1
0.8280948359073359, 0.8233799237611181
eval metrics, batch: 6144 acc, f1
0.7496772805507745, 0.728772072964625
eval metrics, batch: 7168 acc, f1
0.7047729976209358, 0.6810697935908763
Epoch loss - train: tensor(0.0563, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5653, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7999884686346863, 0.7851480242784591
train metrics acc, f1 
0.9835929870605469, 0.9836568896792556
Epoch 9/10
----------
eval metrics, batch: 1024 acc, f1
0.7501588983050848, 0.732019088739916
eval metrics, batch: 2048 acc, f1
0.7129254457050244, 0.6875585689873767
eval metrics, batch: 3072 acc, f1
0.6327203331020125, 0.6077995461071742
eval metrics, batch: 4096 acc, f1
0.788428274907749, 0.7692210936762995
train metrics, batch: 4096  acc, f1 
0.9856147766113281, 0.9857243987477144
eval metrics, batch: 5120 acc, f1
0.7855486425339366, 0.7672712764324955
eval metrics, batch: 6144 acc, f1
0.7486649956408021, 0.7228314755280474
eval metrics, batch: 7168 acc, f1
0.8222208969465649, 0.8125275139928306
Epoch loss - train: tensor(0.0482, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1216, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7109505425709516, 0.6790627624757436
train metrics acc, f1 
0.9829063415527344, 0.9827424852207737
Epoch 10/10
----------
eval metrics, batch: 1024 acc, f1
0.7438606661045531, 0.7230089756375552
eval metrics, batch: 2048 acc, f1
0.8022401222953904, 0.7846739861079991
eval metrics, batch: 3072 acc, f1
0.7499182650392328, 0.7261389742518722
eval metrics, batch: 4096 acc, f1
0.7205393145161291, 0.6982995510814856
train metrics, batch: 4096  acc, f1 
0.9908866882324219, 0.9908200475712897
eval metrics, batch: 5120 acc, f1
0.6495668777943369, 0.6140589336547585
eval metrics, batch: 6144 acc, f1
0.7401570567986231, 0.713429825602088
eval metrics, batch: 7168 acc, f1
0.6807332677165354, 0.6467946100449163
Epoch loss - train: tensor(0.0432, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.9191, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8035630291627469, 0.7866947583476984
train metrics acc, f1 
0.9871292114257812, 0.9872244394126423
Training time 127m 37s
Experiment end
########################################
----------------------------------------
Starting experiment alexnet_4
Experiment parameters Experiment[name: alexnet_4, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 1e-05, weight_decay: 0, batch_size: 32, num_epochs: 10), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.66485595703125, 0.6916381198405122
train metrics acc, f1
0.6578750610351562, 0.689145067483727
Epoch 1/10
----------
eval metrics, batch: 1024 acc, f1
0.785552978515625, 0.776615697618972
eval metrics, batch: 2048 acc, f1
0.783935546875, 0.7833537331701347
eval metrics, batch: 3072 acc, f1
0.7805805744888024, 0.7692258456811853
eval metrics, batch: 4096 acc, f1
0.7541508538899431, 0.7190295473027921
train metrics, batch: 4096  acc, f1 
0.8325462341308594, 0.8179371155784313
eval metrics, batch: 5120 acc, f1
0.7657001924927815, 0.7387133561414101
eval metrics, batch: 6144 acc, f1
0.7978515625, 0.7920642893018583
eval metrics, batch: 7168 acc, f1
0.7813699616122841, 0.7589923300714096
Epoch loss - train: tensor(0.3748, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4281, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7956122200584226, 0.7860487338748209
train metrics acc, f1 
0.8645248413085938, 0.8659150803059706
Epoch 2/10
----------
eval metrics, batch: 1024 acc, f1
0.796966552734375, 0.7962015622606831
eval metrics, batch: 2048 acc, f1
0.7820691747572815, 0.7627101846651911
eval metrics, batch: 3072 acc, f1
0.788067084942085, 0.7691549480877907
eval metrics, batch: 4096 acc, f1
0.79974365234375, 0.7940364092906466
train metrics, batch: 4096  acc, f1 
0.8654899597167969, 0.8693064095863958
eval metrics, batch: 5120 acc, f1
0.7905915287244402, 0.7793947942043852
eval metrics, batch: 6144 acc, f1
0.7828140038498557, 0.7610601899341517
eval metrics, batch: 7168 acc, f1
0.7877427184466019, 0.7764427685818368
Epoch loss - train: tensor(0.3178, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4353, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7961599318403116, 0.789610879055306
train metrics acc, f1 
0.8758621215820312, 0.879491034595131
Epoch 3/10
----------
eval metrics, batch: 1024 acc, f1
0.7898968446601942, 0.7811798906689418
eval metrics, batch: 2048 acc, f1
0.7976638349514563, 0.7883730523910767
eval metrics, batch: 3072 acc, f1
0.7885104065827686, 0.7714687326337811
eval metrics, batch: 4096 acc, f1
0.7835758587786259, 0.7655381832278072
train metrics, batch: 4096  acc, f1 
0.8855094909667969, 0.8842202719645096
eval metrics, batch: 5120 acc, f1
0.7882281553398058, 0.7790160197555879
eval metrics, batch: 6144 acc, f1
0.7829745480494766, 0.7667082174705149
eval metrics, batch: 7168 acc, f1
0.7917172330097088, 0.7755288885982409
Epoch loss - train: tensor(0.2895, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4585, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7826936958614052, 0.7614960551942693
train metrics acc, f1 
0.8947029113769531, 0.8938799204954808
Epoch 4/10
----------
eval metrics, batch: 1024 acc, f1
0.7907160194174757, 0.7811548223350254
eval metrics, batch: 2048 acc, f1
0.7944781553398058, 0.779291020461358
eval metrics, batch: 3072 acc, f1
0.8025803310613437, 0.7954602774274906
eval metrics, batch: 4096 acc, f1
0.789599467570184, 0.7714501659491966
train metrics, batch: 4096  acc, f1 
0.8997077941894531, 0.8999455791632891
eval metrics, batch: 5120 acc, f1
0.772029174573055, 0.7435717858929465
eval metrics, batch: 6144 acc, f1
0.7825849514563107, 0.762353253299728
eval metrics, batch: 7168 acc, f1
0.7667220113851992, 0.7398492262928185
Epoch loss - train: tensor(0.2677, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4657, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7875, 0.7745154851587148
train metrics acc, f1 
0.9009780883789062, 0.9029868596116185
Epoch 5/10
----------
eval metrics, batch: 1024 acc, f1
0.7965250730282376, 0.7901064063529929
eval metrics, batch: 2048 acc, f1
0.7880051119766309, 0.7745380408401022
eval metrics, batch: 3072 acc, f1
0.7643910561370124, 0.7343791901314025
eval metrics, batch: 4096 acc, f1
0.7847289448209099, 0.764884689090068
train metrics, batch: 4096  acc, f1 
0.9079971313476562, 0.9082128177804841
eval metrics, batch: 5120 acc, f1
0.7780410268714012, 0.7526817042606516
eval metrics, batch: 6144 acc, f1
0.7728226967370442, 0.7487645517561606
eval metrics, batch: 7168 acc, f1
0.7507308231992517, 0.7129632746490726
Epoch loss - train: tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5242, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7727027351247601, 0.7417101182564837
train metrics acc, f1 
0.9079246520996094, 0.9052971895586395
Epoch 6/10
----------
eval metrics, batch: 1024 acc, f1
0.8022456183057449, 0.8026000060747805
eval metrics, batch: 2048 acc, f1
0.7775311900191939, 0.7553430079155673
eval metrics, batch: 3072 acc, f1
0.7800538277511961, 0.7581467232251488
eval metrics, batch: 4096 acc, f1
0.7847087378640777, 0.7647058823529411
train metrics, batch: 4096  acc, f1 
0.9171562194824219, 0.9178211265207273
eval metrics, batch: 5120 acc, f1
0.7768286814244466, 0.7521378941742384
eval metrics, batch: 6144 acc, f1
0.783462918660287, 0.7600649458232546
eval metrics, batch: 7168 acc, f1
0.7564604770813844, 0.7275937612399045
Epoch loss - train: tensor(0.2310, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5088, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7718114714424008, 0.7506198961880517
train metrics acc, f1 
0.9102363586425781, 0.9113626518504567
Epoch 7/10
----------
eval metrics, batch: 1024 acc, f1
0.7997876213592233, 0.7968350728117977
eval metrics, batch: 2048 acc, f1
0.7848196999031946, 0.766518956179222
eval metrics, batch: 3072 acc, f1
0.7610925572519084, 0.728645939172255
eval metrics, batch: 4096 acc, f1
0.7848802032913843, 0.7681523263017183
train metrics, batch: 4096  acc, f1 
0.9226264953613281, 0.9238114198353999
eval metrics, batch: 5120 acc, f1
0.773105694980695, 0.7488648504273504
eval metrics, batch: 6144 acc, f1
0.7407299440298507, 0.701703783203649
eval metrics, batch: 7168 acc, f1
0.79571533203125, 0.7835058214747737
Epoch loss - train: tensor(0.2152, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5572, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7676043666026872, 0.736562978072412
train metrics acc, f1 
0.92926025390625, 0.9284716918543204
Epoch 8/10
----------
eval metrics, batch: 1024 acc, f1
0.7946080817916261, 0.7866354785687192
eval metrics, batch: 2048 acc, f1
0.7850314617618587, 0.7658957633260856
eval metrics, batch: 3072 acc, f1
0.7750299043062201, 0.7536269854265597
eval metrics, batch: 4096 acc, f1
0.7731691316793893, 0.7476195215818984
train metrics, batch: 4096  acc, f1 
0.93182373046875, 0.9312599521527419
eval metrics, batch: 5120 acc, f1
0.7775011996161229, 0.7540364022146339
eval metrics, batch: 6144 acc, f1
0.7891903272377286, 0.7737499596500855
eval metrics, batch: 7168 acc, f1
0.7475581395348837, 0.7110726643598616
Epoch loss - train: tensor(0.2016, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6042, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7644670356111646, 0.7285709334165194
train metrics acc, f1 
0.9325408935546875, 0.9312361472955633
Epoch 9/10
----------
eval metrics, batch: 1024 acc, f1
0.7926606621226875, 0.7872353712608505
eval metrics, batch: 2048 acc, f1
0.7517294847328244, 0.7108023619312261
eval metrics, batch: 3072 acc, f1
0.7510436545801527, 0.7123315990765944
eval metrics, batch: 4096 acc, f1
0.7494334446564885, 0.7078741526160264
train metrics, batch: 4096  acc, f1 
0.93463134765625, 0.9332819398696475
eval metrics, batch: 5120 acc, f1
0.7700591216216216, 0.7426661715558857
eval metrics, batch: 6144 acc, f1
0.7672650286259542, 0.7384996817100546
eval metrics, batch: 7168 acc, f1
0.7703934740882917, 0.742655462184874
Epoch loss - train: tensor(0.1887, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6335, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7446070429104478, 0.70652865708639
train metrics acc, f1 
0.9402580261230469, 0.9388139414042203
Epoch 10/10
----------
eval metrics, batch: 1024 acc, f1
0.7775204523580366, 0.7576899138467587
eval metrics, batch: 2048 acc, f1
0.7780946601941747, 0.7552208835341365
eval metrics, batch: 3072 acc, f1
0.7736788127413128, 0.7502080767053967
eval metrics, batch: 4096 acc, f1
0.7734978281853282, 0.7487200080313221
train metrics, batch: 4096  acc, f1 
0.9397621154785156, 0.9399552069113682
eval metrics, batch: 5120 acc, f1
0.7658791866028708, 0.73447515685942
eval metrics, batch: 6144 acc, f1
0.7840576171875, 0.7697214267117938
eval metrics, batch: 7168 acc, f1
0.7376037822878229, 0.6985294117647058
Epoch loss - train: tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6150, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7713546679499519, 0.7473915066126138
train metrics acc, f1 
0.9452705383300781, 0.9454331083008463
Training time 112m 26s
Experiment end
########################################
----------------------------------------
Starting experiment alexnet_5
Experiment parameters Experiment[name: alexnet_5, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 0.001, weight_decay: 0, batch_size: 32, num_epochs: 10), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.607421875, 0.6838224450670992
train metrics acc, f1
0.6085395812988281, 0.6844230408482712
Epoch 1/10
----------
eval metrics, batch: 1024 acc, f1
0.777099609375, 0.7767862600085569
eval metrics, batch: 2048 acc, f1
0.7406307656826568, 0.7000300070016338
eval metrics, batch: 3072 acc, f1
0.782710564751704, 0.7637542594369272
eval metrics, batch: 4096 acc, f1
0.777252197265625, 0.776152359922716
train metrics, batch: 4096  acc, f1 
0.8289947509765625, 0.836809878484736
eval metrics, batch: 5120 acc, f1
0.79443359375, 0.795631067961165
eval metrics, batch: 6144 acc, f1
0.7756696428571429, 0.7558998260412906
eval metrics, batch: 7168 acc, f1
0.7660885167464114, 0.7380442062960483
Epoch loss - train: tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4641, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7751820388349514, 0.7559931506849316
train metrics acc, f1 
0.8491973876953125, 0.8470561836006716
Epoch 2/10
----------
eval metrics, batch: 1024 acc, f1
0.779815673828125, 0.7964222228492424
eval metrics, batch: 2048 acc, f1
0.789947509765625, 0.7858898186455968
eval metrics, batch: 3072 acc, f1
0.7967076436222006, 0.7857623857623858
eval metrics, batch: 4096 acc, f1
0.7782681297709924, 0.7520010672358591
train metrics, batch: 4096  acc, f1 
0.8528251647949219, 0.8432412226705185
eval metrics, batch: 5120 acc, f1
0.79052734375, 0.7819290888295845
eval metrics, batch: 6144 acc, f1
0.7840634075508228, 0.7680660254743956
eval metrics, batch: 7168 acc, f1
0.780517578125, 0.7664935064935064
Epoch loss - train: tensor(0.3512, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4600, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7915956669912366, 0.7888261955415781
train metrics acc, f1 
0.860321044921875, 0.8662438995879482
Epoch 3/10
----------
eval metrics, batch: 1024 acc, f1
0.80078125, 0.801121130879844
eval metrics, batch: 2048 acc, f1
0.7817961165048544, 0.7657328990228013
eval metrics, batch: 3072 acc, f1
0.7806735436893204, 0.758510105227994
eval metrics, batch: 4096 acc, f1
0.7894048198636806, 0.7759396548933277
train metrics, batch: 4096  acc, f1 
0.8709640502929688, 0.8717983702861475
eval metrics, batch: 5120 acc, f1
0.7533999526963103, 0.7210274591123449
eval metrics, batch: 6144 acc, f1
0.763885556621881, 0.7339213897056338
eval metrics, batch: 7168 acc, f1
0.7875423523717329, 0.7695941734195072
Epoch loss - train: tensor(0.3324, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4599, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7866808252427184, 0.7742784680086038
train metrics acc, f1 
0.8759269714355469, 0.8777784040734269
Epoch 4/10
----------
eval metrics, batch: 1024 acc, f1
0.79931640625, 0.7946924758039338
eval metrics, batch: 2048 acc, f1
0.7757317658349329, 0.7536728374728243
eval metrics, batch: 3072 acc, f1
0.7514486754966887, 0.7149686387523309
eval metrics, batch: 4096 acc, f1
0.758094165085389, 0.7228318103067568
train metrics, batch: 4096  acc, f1 
0.8736228942871094, 0.866438480424765
eval metrics, batch: 5120 acc, f1
0.7810679611650485, 0.7655925155925156
eval metrics, batch: 6144 acc, f1
0.7786483543078412, 0.7557172904216606
eval metrics, batch: 7168 acc, f1
0.7756256015399422, 0.7514990006662225
Epoch loss - train: tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5061, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7663187741312741, 0.733275951110346
train metrics acc, f1 
0.878570556640625, 0.8735500683255474
Epoch 5/10
----------
eval metrics, batch: 1024 acc, f1
0.80145263671875, 0.7951511335012594
eval metrics, batch: 2048 acc, f1
0.7759862052274927, 0.7593513372981053
eval metrics, batch: 3072 acc, f1
0.7898665048543689, 0.7788492240883836
eval metrics, batch: 4096 acc, f1
0.7817354368932039, 0.7649173256649893
train metrics, batch: 4096  acc, f1 
0.883026123046875, 0.8837101704299811
eval metrics, batch: 5120 acc, f1
0.7720801158301158, 0.747914859544939
eval metrics, batch: 6144 acc, f1
0.7696207061068703, 0.7467715503113733
eval metrics, batch: 7168 acc, f1
0.796844482421875, 0.7889547601686586
Epoch loss - train: tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4730, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7938044530493708, 0.7776182707993474
train metrics acc, f1 
0.886077880859375, 0.8855285450349961
Epoch 6/10
----------
eval metrics, batch: 1024 acc, f1
0.7976813534566699, 0.7866106100966013
eval metrics, batch: 2048 acc, f1
0.7794902912621359, 0.7635653871177619
eval metrics, batch: 3072 acc, f1
0.7814913127413128, 0.761176315442437
eval metrics, batch: 4096 acc, f1
0.7821575508228461, 0.7607720673731769
train metrics, batch: 4096  acc, f1 
0.8874244689941406, 0.8861181537179176
eval metrics, batch: 5120 acc, f1
0.7812196601941748, 0.7662485007617751
eval metrics, batch: 6144 acc, f1
0.7818889970788705, 0.7638843138546676
eval metrics, batch: 7168 acc, f1
0.7981682083739046, 0.7878865402449554
Epoch loss - train: tensor(0.2989, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4798, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.783626082771896, 0.7663678877630553
train metrics acc, f1 
0.8922805786132812, 0.8921002957517215
Epoch 7/10
----------
eval metrics, batch: 1024 acc, f1
0.7913277511961723, 0.7742039865389594
eval metrics, batch: 2048 acc, f1
0.781945788964182, 0.7617977528089888
eval metrics, batch: 3072 acc, f1
0.7827625847047435, 0.7666460858544828
eval metrics, batch: 4096 acc, f1
0.7810376213592233, 0.7604156292533945
train metrics, batch: 4096  acc, f1 
0.8901481628417969, 0.8897076565414386
eval metrics, batch: 5120 acc, f1
0.7558014354066985, 0.7269261637239165
eval metrics, batch: 6144 acc, f1
0.7680842130518234, 0.7403203599852245
eval metrics, batch: 7168 acc, f1
0.7870009737098345, 0.7690683557666931
Epoch loss - train: tensor(0.2897, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4849, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7878559362934363, 0.7733702832468662
train metrics acc, f1 
0.8950119018554688, 0.89616063747906
Epoch 8/10
----------
eval metrics, batch: 1024 acc, f1
0.8017001452081317, 0.7918981554969999
eval metrics, batch: 2048 acc, f1
0.78985595703125, 0.7778852977227275
eval metrics, batch: 3072 acc, f1
0.780949230028874, 0.759945944164277
eval metrics, batch: 4096 acc, f1
0.7768683057448881, 0.7542477965079258
train metrics, batch: 4096  acc, f1 
0.8953361511230469, 0.8949204732159612
eval metrics, batch: 5120 acc, f1
0.7797026699029126, 0.7657666376334721
eval metrics, batch: 6144 acc, f1
0.7939690847127556, 0.7837224901779155
eval metrics, batch: 7168 acc, f1
0.7545324427480916, 0.7207029924679379
Epoch loss - train: tensor(0.2829, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5374, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7756440839694656, 0.7511081706913662
train metrics acc, f1 
0.8982124328613281, 0.8959974431031996
Epoch 9/10
----------
eval metrics, batch: 1024 acc, f1
0.7959165043816943, 0.7838891574029322
eval metrics, batch: 2048 acc, f1
0.7681063522617901, 0.7421577152029964
eval metrics, batch: 3072 acc, f1
0.7787765444015444, 0.7551415598290598
eval metrics, batch: 4096 acc, f1
0.7538915094339622, 0.7191306103223202
train metrics, batch: 4096  acc, f1 
0.8933944702148438, 0.8890265500782286
eval metrics, batch: 5120 acc, f1
0.7820041023166023, 0.7604018167954116
eval metrics, batch: 6144 acc, f1
0.790625, 0.7802579207132622
eval metrics, batch: 7168 acc, f1
0.7676669893514037, 0.7413967270523267
Epoch loss - train: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5097, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7770752662149081, 0.7515760374877793
train metrics acc, f1 
0.9028358459472656, 0.9015784694449275
Epoch 10/10
----------
eval metrics, batch: 1024 acc, f1
0.8003286270691334, 0.7905521864028088
eval metrics, batch: 2048 acc, f1
0.7846275559883155, 0.7673547199579279
eval metrics, batch: 3072 acc, f1
0.7839424007744433, 0.7660968101133163
eval metrics, batch: 4096 acc, f1
0.7783155856727977, 0.758311345646438
train metrics, batch: 4096  acc, f1 
0.902252197265625, 0.9028908393590734
eval metrics, batch: 5120 acc, f1
0.7419767441860465, 0.7042516326802613
eval metrics, batch: 6144 acc, f1
0.7687620656370656, 0.744005877245709
eval metrics, batch: 7168 acc, f1
0.7323255813953489, 0.6887506760411033
Epoch loss - train: tensor(0.2707, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5301, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7783626082771896, 0.7572553282603682
train metrics acc, f1 
0.9032669067382812, 0.9030279390282143
Training time 111m 55s
Experiment end
########################################
----------------------------------------
Starting experiment alexnet_6
Experiment parameters Experiment[name: alexnet_6, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 0.0001, weight_decay: 0, batch_size: 32, num_epochs: 10), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.6219482421875, 0.605829196894489
train metrics acc, f1
0.5633773803710938, 0.5287622278581074
Epoch 1/10
----------
eval metrics, batch: 1024 acc, f1
0.7788298644724104, 0.7954335599764962
eval metrics, batch: 2048 acc, f1
0.786376953125, 0.7744845360824743
eval metrics, batch: 3072 acc, f1
0.7722431840311588, 0.7608702597361107
eval metrics, batch: 4096 acc, f1
0.777891074856046, 0.7531826967939745
train metrics, batch: 4096  acc, f1 
0.841705322265625, 0.832089733421815
eval metrics, batch: 5120 acc, f1
0.7915652385589095, 0.778417545448664
eval metrics, batch: 6144 acc, f1
0.7833191333982473, 0.7689112445237709
eval metrics, batch: 7168 acc, f1
0.7886745374878287, 0.7920845433044936
Epoch loss - train: tensor(0.3679, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4522, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7840854247104247, 0.7671437865972675
train metrics acc, f1 
0.8670272827148438, 0.8660266117316074
Epoch 2/10
----------
eval metrics, batch: 1024 acc, f1
0.7880578214971209, 0.7728602192009771
eval metrics, batch: 2048 acc, f1
0.758325404376784, 0.7278510681041988
eval metrics, batch: 3072 acc, f1
0.7721029270633397, 0.7489842433851948
eval metrics, batch: 4096 acc, f1
0.7738597972972973, 0.7482115869017633
train metrics, batch: 4096  acc, f1 
0.8702888488769531, 0.8670620569940691
eval metrics, batch: 5120 acc, f1
0.7680300096805421, 0.7416616130988478
eval metrics, batch: 6144 acc, f1
0.7689785851780558, 0.7414065919267414
eval metrics, batch: 7168 acc, f1
0.7697431018078021, 0.7413666421748715
Epoch loss - train: tensor(0.3098, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5503, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7639952153110048, 0.731363605419021
train metrics acc, f1 
0.8732681274414062, 0.8677015220178883
Epoch 3/10
----------
eval metrics, batch: 1024 acc, f1
0.7734901347449471, 0.7491923935125054
eval metrics, batch: 2048 acc, f1
0.7569085136406397, 0.725236750290746
eval metrics, batch: 3072 acc, f1
0.7850314617618587, 0.7673367821360749
eval metrics, batch: 4096 acc, f1
0.7859087608906099, 0.7657785867946384
train metrics, batch: 4096  acc, f1 
0.8890037536621094, 0.8882736694172353
eval metrics, batch: 5120 acc, f1
0.7935430866601753, 0.7827618224314027
eval metrics, batch: 6144 acc, f1
0.7779007177033492, 0.751064186358304
eval metrics, batch: 7168 acc, f1
0.738295664206642, 0.6977022977022977
Epoch loss - train: tensor(0.2784, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5515, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7669935033686237, 0.7359307359307359
train metrics acc, f1 
0.8945884704589844, 0.8920666044317024
Epoch 4/10
----------
eval metrics, batch: 1024 acc, f1
0.793975830078125, 0.783739629048275
eval metrics, batch: 2048 acc, f1
0.7783070388349514, 0.7555124301535785
eval metrics, batch: 3072 acc, f1
0.7360749763481551, 0.6898731978461004
eval metrics, batch: 4096 acc, f1
0.7969970703125, 0.7859303597863165
train metrics, batch: 4096  acc, f1 
0.8930015563964844, 0.8954226678050654
eval metrics, batch: 5120 acc, f1
0.7908958130477117, 0.773709167544784
eval metrics, batch: 6144 acc, f1
0.7503557874762808, 0.7140916808149406
eval metrics, batch: 7168 acc, f1
0.7895024271844661, 0.7714003294892916
Epoch loss - train: tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5163, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7858952702702703, 0.7693807264929495
train metrics acc, f1 
0.90625, 0.9074559421599638
Epoch 5/10
----------
eval metrics, batch: 1024 acc, f1
0.7783458373668926, 0.7571991914371873
eval metrics, batch: 2048 acc, f1
0.7467441860465116, 0.7109872611464968
eval metrics, batch: 3072 acc, f1
0.7760919401544402, 0.7536914755947838
eval metrics, batch: 4096 acc, f1
0.7774521531100479, 0.7563993453355156
train metrics, batch: 4096  acc, f1 
0.9116325378417969, 0.9115140588174626
eval metrics, batch: 5120 acc, f1
0.7457841981132075, 0.7054885754294887
eval metrics, batch: 6144 acc, f1
0.7706027430221367, 0.7415715108596211
eval metrics, batch: 7168 acc, f1
0.7510643330179754, 0.7159627580623398
Epoch loss - train: tensor(0.2350, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5750, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7866182821497121, 0.765529741308288
train metrics acc, f1 
0.9137840270996094, 0.9132708860176597
Epoch 6/10
----------
eval metrics, batch: 1024 acc, f1
0.789461020211742, 0.7695397379337592
eval metrics, batch: 2048 acc, f1
0.7715652069297402, 0.7455526148279674
eval metrics, batch: 3072 acc, f1
0.7448109925788498, 0.7081910697119369
eval metrics, batch: 4096 acc, f1
0.7573408018867924, 0.7232253942634251
train metrics, batch: 4096  acc, f1 
0.9179229736328125, 0.9158551751648403
eval metrics, batch: 5120 acc, f1
0.7822755791505791, 0.7646867053530677
eval metrics, batch: 6144 acc, f1
0.7790416263310745, 0.7536593591905565
eval metrics, batch: 7168 acc, f1
0.7618850520340587, 0.7287850215517241
Epoch loss - train: tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6584, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7503206623134329, 0.7139756219736183
train metrics acc, f1 
0.9166908264160156, 0.9138973107447987
Epoch 7/10
----------
eval metrics, batch: 1024 acc, f1
0.7642423882017126, 0.7354089498448293
eval metrics, batch: 2048 acc, f1
0.7680701335877863, 0.7411647254575707
eval metrics, batch: 3072 acc, f1
0.784496359223301, 0.7640120934250307
eval metrics, batch: 4096 acc, f1
0.7692838291746641, 0.7385201046871283
train metrics, batch: 4096  acc, f1 
0.9289703369140625, 0.9282726103068638
eval metrics, batch: 5120 acc, f1
0.7713815789473685, 0.7488254427177449
eval metrics, batch: 6144 acc, f1
0.7601967370441459, 0.7273223298322193
eval metrics, batch: 7168 acc, f1
0.7574676103646834, 0.7195033124067843
Epoch loss - train: tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8089, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7430914863593603, 0.7009342596078163
train metrics acc, f1 
0.9317588806152344, 0.9299456843111071
Epoch 8/10
----------
eval metrics, batch: 1024 acc, f1
0.7792706333973128, 0.7565493516803388
eval metrics, batch: 2048 acc, f1
0.7794046466602129, 0.7601631364294171
eval metrics, batch: 3072 acc, f1
0.7687078922040423, 0.7403956518803592
eval metrics, batch: 4096 acc, f1
0.7759416986564299, 0.7538628801106975
train metrics, batch: 4096  acc, f1 
0.9302978515625, 0.9307411815542297
eval metrics, batch: 5120 acc, f1
0.7688696172248803, 0.7433504897891416
eval metrics, batch: 6144 acc, f1
0.7783980582524271, 0.752457127363926
eval metrics, batch: 7168 acc, f1
0.7496156575212867, 0.7102733399473162
Epoch loss - train: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8449, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7563152277039848, 0.7220587737986541
train metrics acc, f1 
0.9351539611816406, 0.9339949755572899
Epoch 9/10
----------
eval metrics, batch: 1024 acc, f1
0.7636477164605138, 0.7318965226483186
eval metrics, batch: 2048 acc, f1
0.7646883920076119, 0.7354946524064171
eval metrics, batch: 3072 acc, f1
0.7686240403071017, 0.742171573705845
eval metrics, batch: 4096 acc, f1
0.7608838263358778, 0.7308247457285757
train metrics, batch: 4096  acc, f1 
0.9425048828125, 0.9422023836915007
eval metrics, batch: 5120 acc, f1
0.7654283639883833, 0.7348697257744649
eval metrics, batch: 6144 acc, f1
0.755218388030888, 0.7191750008651417
eval metrics, batch: 7168 acc, f1
0.7591589581304771, 0.7268711825804893
Epoch loss - train: tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.9000, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.770694971537002, 0.7457593688362919
train metrics acc, f1 
0.9434890747070312, 0.9433212941140461
Epoch 10/10
----------
eval metrics, batch: 1024 acc, f1
0.791747572815534, 0.7731958762886598
eval metrics, batch: 2048 acc, f1
0.7794348983543078, 0.758696011914612
eval metrics, batch: 3072 acc, f1
0.7452963311382879, 0.7095151880909274
eval metrics, batch: 4096 acc, f1
0.772472249034749, 0.7484408871102218
train metrics, batch: 4096  acc, f1 
0.944732666015625, 0.9450883483296821
eval metrics, batch: 5120 acc, f1
0.7612788739172281, 0.7303550195345677
eval metrics, batch: 6144 acc, f1
0.7401844843897823, 0.6967982335081424
eval metrics, batch: 7168 acc, f1
0.7679777992277992, 0.7375818777292577
Epoch loss - train: tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1079, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7495565279091769, 0.7129933931899034
train metrics acc, f1 
0.9497032165527344, 0.9491376350639782
Training time 109m 45s
Experiment end
########################################
----------------------------------------
Starting experiment resnet_1
Experiment parameters Experiment[name: resnet_1, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 1e-05, weight_decay: 0, batch_size: 32, num_epochs: 10), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.4434814453125, 0.33029746603011384
train metrics acc, f1
0.43099212646484375, 0.30922411477581113
Epoch 1/10
----------
eval metrics, batch: 1024 acc, f1
0.7842553428317008, 0.7683804857646461
eval metrics, batch: 2048 acc, f1
0.8400735294117647, 0.833754546014917
eval metrics, batch: 3072 acc, f1
0.8113898756660746, 0.8030259115413599
eval metrics, batch: 4096 acc, f1
0.7468799920127795, 0.7371776597123234
train metrics, batch: 4096  acc, f1 
0.93719482421875, 0.9353404601258316
eval metrics, batch: 5120 acc, f1
0.8619541746641075, 0.8583648727653158
eval metrics, batch: 6144 acc, f1
0.7808685701830863, 0.7651610265993167
eval metrics, batch: 7168 acc, f1
0.7734118009868421, 0.7667645424966273
Epoch loss - train: tensor(0.2080, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.2810, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8621375116931712, 0.8596846176733115
train metrics acc, f1 
0.9477462768554688, 0.9488506519693507
Epoch 2/10
----------
eval metrics, batch: 1024 acc, f1
0.7865331783601014, 0.7789600372001423
eval metrics, batch: 2048 acc, f1
0.8212952488687782, 0.8140321963565732
eval metrics, batch: 3072 acc, f1
0.8380189324817519, 0.8333186632632104
eval metrics, batch: 4096 acc, f1
0.7736053719008265, 0.7661526970068826
train metrics, batch: 4096  acc, f1 
0.9643440246582031, 0.9641837598813662
eval metrics, batch: 5120 acc, f1
0.8675373134328358, 0.867351704810836
eval metrics, batch: 6144 acc, f1
0.7649360236220473, 0.76288813323736
eval metrics, batch: 7168 acc, f1
0.7314771884272997, 0.7300943725969941
Epoch loss - train: tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4465, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7065391459074734, 0.7056881552531786
train metrics acc, f1 
0.9696693420410156, 0.9691353951143011
Epoch 3/10
----------
eval metrics, batch: 1024 acc, f1
0.7500247231012658, 0.7431605151522849
eval metrics, batch: 2048 acc, f1
0.8450255102040817, 0.841740674955595
eval metrics, batch: 3072 acc, f1
0.7784849749582637, 0.7695522388059701
eval metrics, batch: 4096 acc, f1
0.6859363831308077, 0.6776707932141219
train metrics, batch: 4096  acc, f1 
0.9719085693359375, 0.9714063834744118
eval metrics, batch: 5120 acc, f1
0.8664482838589982, 0.8651938551572788
eval metrics, batch: 6144 acc, f1
0.7490203761755486, 0.743067743067743
eval metrics, batch: 7168 acc, f1
0.6664506688963211, 0.6650574085346656
Epoch loss - train: tensor(0.0918, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5408, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.6998791189111748, 0.6961035428519619
train metrics acc, f1 
0.9814376831054688, 0.981270207852194
Epoch 4/10
----------
eval metrics, batch: 1024 acc, f1
0.7223704268292683, 0.7129629629629629
eval metrics, batch: 2048 acc, f1
0.7421088303640588, 0.7365088786664689
eval metrics, batch: 3072 acc, f1
0.7603102906520032, 0.7575366277626024
eval metrics, batch: 4096 acc, f1
0.7244485294117647, 0.7232274741506647
train metrics, batch: 4096  acc, f1 
0.9863967895507812, 0.9863330803841761
eval metrics, batch: 5120 acc, f1
0.7941131342062193, 0.7934316869788326
eval metrics, batch: 6144 acc, f1
0.6967923516797713, 0.6919620569146281
eval metrics, batch: 7168 acc, f1
0.8139364700780573, 0.8096070111212802
Epoch loss - train: tensor(0.0648, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4779, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7527195411392406, 0.7461936662606578
train metrics acc, f1 
0.9902534484863281, 0.9902507335798314
Epoch 5/10
----------
eval metrics, batch: 1024 acc, f1
0.7009413468501087, 0.6951045079130715
eval metrics, batch: 2048 acc, f1
0.7735073111291633, 0.7687522678969467
eval metrics, batch: 3072 acc, f1
0.6935832732516222, 0.6863323954056921
eval metrics, batch: 4096 acc, f1
0.7136611769059955, 0.7072484332505616
train metrics, batch: 4096  acc, f1 
0.9874114990234375, 0.9873087661813231
eval metrics, batch: 5120 acc, f1
0.7513860887096774, 0.7425693483990501
eval metrics, batch: 6144 acc, f1
0.7339313123561013, 0.7282747134319585
eval metrics, batch: 7168 acc, f1
0.7878636172006745, 0.7807999128753845
Epoch loss - train: tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6785, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7074487554904831, 0.7015914500396696
train metrics acc, f1 
0.99359130859375, 0.9935738056076197
Epoch 6/10
----------
eval metrics, batch: 1024 acc, f1
0.7587440381558028, 0.753464994669239
eval metrics, batch: 2048 acc, f1
0.7735714285714286, 0.7677169475557416
eval metrics, batch: 3072 acc, f1
0.7594506048387096, 0.7519297242508511
eval metrics, batch: 4096 acc, f1
0.773664314516129, 0.7701599488163787
train metrics, batch: 4096  acc, f1 
0.9939155578613281, 0.9939229992570437
eval metrics, batch: 5120 acc, f1
0.7699002442996743, 0.7635460251046026
eval metrics, batch: 6144 acc, f1
0.8073516386182462, 0.8011087615019717
eval metrics, batch: 7168 acc, f1
0.7365731939163498, 0.7325500036190797
Epoch loss - train: tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8102, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.6844639139486468, 0.6815216915466444
train metrics acc, f1 
0.9948921203613281, 0.9948708912544674
Epoch 7/10
----------
eval metrics, batch: 1024 acc, f1
0.7328777047913446, 0.72532220815019
eval metrics, batch: 2048 acc, f1
0.7201378608438194, 0.7154716271194412
eval metrics, batch: 3072 acc, f1
0.8051438535309503, 0.7977604343400068
eval metrics, batch: 4096 acc, f1
0.7156939338235294, 0.7113226476283802
train metrics, batch: 4096  acc, f1 
0.9944839477539062, 0.9944657920117573
eval metrics, batch: 5120 acc, f1
0.664346399730821, 0.6605703591859303
eval metrics, batch: 6144 acc, f1
0.7220882789317508, 0.7185651234857733
eval metrics, batch: 7168 acc, f1
0.8142755681818182, 0.8104491343499958
Epoch loss - train: tensor(0.0256, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8001, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.736922554347826, 0.7291349204366616
train metrics acc, f1 
0.9968223571777344, 0.9968207198989347
Epoch 8/10
----------
eval metrics, batch: 1024 acc, f1
0.7432692307692308, 0.7396011118154776
eval metrics, batch: 2048 acc, f1
0.753477626459144, 0.7504984124640035
eval metrics, batch: 3072 acc, f1
0.7305730712166172, 0.7296706363974693
eval metrics, batch: 4096 acc, f1
0.7744229183841714, 0.7666186896956128
train metrics, batch: 4096  acc, f1 
0.9975357055664062, 0.9975371899566149
eval metrics, batch: 5120 acc, f1
0.7196312881097561, 0.7104091322852855
eval metrics, batch: 6144 acc, f1
0.7697166530278232, 0.7620683277406399
eval metrics, batch: 7168 acc, f1
0.7579608386075949, 0.7536239178578619
Epoch loss - train: tensor(0.0206, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8496, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7501476377952756, 0.7447589362023026
train metrics acc, f1 
0.9972572326660156, 0.9972589370470479
Epoch 9/10
----------
eval metrics, batch: 1024 acc, f1
0.7225456408345753, 0.7185809773494887
eval metrics, batch: 2048 acc, f1
0.7704897425583266, 0.7670281995661605
eval metrics, batch: 3072 acc, f1
0.7386473663826492, 0.7318115204053752
eval metrics, batch: 4096 acc, f1
0.7593376494023905, 0.753789326200484
train metrics, batch: 4096  acc, f1 
0.9966773986816406, 0.9966769550072679
eval metrics, batch: 5120 acc, f1
0.7887100082034455, 0.7860110084120885
eval metrics, batch: 6144 acc, f1
0.6983894902234636, 0.699131419117487
eval metrics, batch: 7168 acc, f1
0.7182139027877055, 0.7206784314593805
Epoch loss - train: tensor(0.0181, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1210, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.6654560810810811, 0.6617998633879781
train metrics acc, f1 
0.9966964721679688, 0.9966867654260528
Epoch 10/10
----------
eval metrics, batch: 1024 acc, f1
0.6923591298145506, 0.6866457794124324
eval metrics, batch: 2048 acc, f1
0.7902277542372881, 0.7835614941115392
eval metrics, batch: 3072 acc, f1
0.7917110306643952, 0.7842272163242796
eval metrics, batch: 4096 acc, f1
0.6912191901408451, 0.6874986079868148
train metrics, batch: 4096  acc, f1 
0.9944190979003906, 0.9943951299310789
eval metrics, batch: 5120 acc, f1
0.7419354838709677, 0.7418023173992588
eval metrics, batch: 6144 acc, f1
0.7785149918962723, 0.7755939857340791
eval metrics, batch: 7168 acc, f1
0.7879983388704319, 0.78364060182242
Epoch loss - train: tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.1673, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.6679868944923689, 0.6687767641035189
train metrics acc, f1 
0.9939689636230469, 0.9939337198460599
Training time 154m 10s
Experiment end
########################################
----------------------------------------
Starting experiment resnet_2
Experiment parameters Experiment[name: resnet_2, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 0.001, weight_decay: 0, batch_size: 32, num_epochs: 10), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.4961165048543689, 0.6450068399452804
train metrics acc, f1
0.48978424072265625, 0.6402016484817182
Epoch 1/10
----------
eval metrics, batch: 1024 acc, f1
0.609861729179911, 0.597301398515359
eval metrics, batch: 2048 acc, f1
0.7183151669758813, 0.6632939464291902
eval metrics, batch: 3072 acc, f1
0.764801025390625, 0.7452652454139812
eval metrics, batch: 4096 acc, f1
0.8044973222979552, 0.8008678134201147
train metrics, batch: 4096  acc, f1 
0.8254470825195312, 0.828780757947674
eval metrics, batch: 5120 acc, f1
0.809783935546875, 0.8047244587863028
eval metrics, batch: 6144 acc, f1
0.7485782529572339, 0.7153618336337884
eval metrics, batch: 7168 acc, f1
0.8205674184261037, 0.8104666265403745
Epoch loss - train: tensor(0.4076, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4075, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7874426605504588, 0.770364864027752
train metrics acc, f1 
0.8706245422363281, 0.8646221274863185
Epoch 2/10
----------
eval metrics, batch: 1024 acc, f1
0.8494070667957405, 0.8498703178720067
eval metrics, batch: 2048 acc, f1
0.6224413925822253, 0.5910802681130243
eval metrics, batch: 3072 acc, f1
0.8542173807205453, 0.8543370526891855
eval metrics, batch: 4096 acc, f1
0.8472490347490348, 0.8539371214306317
train metrics, batch: 4096  acc, f1 
0.87139892578125, 0.8815310439830759
eval metrics, batch: 5120 acc, f1
0.7611533717105263, 0.7504296455424275
eval metrics, batch: 6144 acc, f1
0.798278116826504, 0.7898978433598184
eval metrics, batch: 7168 acc, f1
0.8455726716839135, 0.8412655244311485
Epoch loss - train: tensor(0.2723, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3940, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7586102106969206, 0.7507843547375026
train metrics acc, f1 
0.9244804382324219, 0.9224726361340095
Epoch 3/10
----------
eval metrics, batch: 1024 acc, f1
0.7352884615384615, 0.7285545257345691
eval metrics, batch: 2048 acc, f1
0.8496793320425944, 0.8536937255248358
eval metrics, batch: 3072 acc, f1
0.779396186440678, 0.7697241112401172
eval metrics, batch: 4096 acc, f1
0.7420945678033307, 0.7317852632664107
train metrics, batch: 4096  acc, f1 
0.9289054870605469, 0.9261775272620684
eval metrics, batch: 5120 acc, f1
0.8480787476280834, 0.8430435581694542
eval metrics, batch: 6144 acc, f1
0.8526439980638916, 0.8513080374858818
eval metrics, batch: 7168 acc, f1
0.8648941289701636, 0.863282201120039
Epoch loss - train: tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3466, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7804635067114094, 0.7721112502041039
train metrics acc, f1 
0.9438323974609375, 0.9430710104470341
Epoch 4/10
----------
eval metrics, batch: 1024 acc, f1
0.7670570785597381, 0.7592949818988981
eval metrics, batch: 2048 acc, f1
0.7932227592267135, 0.7820045162410978
eval metrics, batch: 3072 acc, f1
0.7661681487469685, 0.7600705065062989
eval metrics, batch: 4096 acc, f1
0.6821239019033675, 0.6665066602664107
train metrics, batch: 4096  acc, f1 
0.9239463806152344, 0.9197373559261988
eval metrics, batch: 5120 acc, f1
0.820600810081008, 0.8129289611075262
eval metrics, batch: 6144 acc, f1
0.6537365951742627, 0.647068869817685
eval metrics, batch: 7168 acc, f1
0.7186538461538462, 0.7068430017032361
Epoch loss - train: tensor(0.1804, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3170, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8478415559772297, 0.8425090529675321
train metrics acc, f1 
0.93402099609375, 0.9357861518470392
Epoch 5/10
----------
eval metrics, batch: 1024 acc, f1
0.7686208677685951, 0.7590176722166931
eval metrics, batch: 2048 acc, f1
0.7876979880136986, 0.7782714393494844
eval metrics, batch: 3072 acc, f1
0.6737106017191977, 0.6599160055996267
eval metrics, batch: 4096 acc, f1
0.6612159242021277, 0.6587698553878995
train metrics, batch: 4096  acc, f1 
0.9400215148925781, 0.9370694865257537
eval metrics, batch: 5120 acc, f1
0.7569558944765046, 0.7445437313836989
eval metrics, batch: 6144 acc, f1
0.7377196485623003, 0.7261973005367659
eval metrics, batch: 7168 acc, f1
0.7001509882869692, 0.6909673920731851
Epoch loss - train: tensor(0.1569, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5200, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.6609047054840894, 0.6546575017776725
