----------------------------------------
Starting experiment densenet_saturation-1560322029
Experiment parameters Experiment[name: densenet_saturation-1560322029, model: DenseNet(
  (features): Sequential(
    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu0): ReLU(inplace)
    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (denseblock1): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition1): _Transition(
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock2): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition2): _Transition(
      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock3): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer17): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer18): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer19): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer20): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer21): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer22): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer23): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer24): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition3): _Transition(
      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock4): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (classifier): Linear(in_features=1024, out_features=1, bias=True)
), params: Params(lr: 0.0001, weight_decay: 0, batch_size: 32, num_epochs: 20), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.541595458984375, 0.6343031040779062
train metrics acc, f1
0.5075912475585938, 0.6009385897657854
Epoch 1/20
----------
eval metrics, batch: 1024 acc, f1
0.87799072265625, 0.8686251314405888
eval metrics, batch: 2048 acc, f1
0.865203857421875, 0.858805101812486
eval metrics, batch: 3072 acc, f1
0.88336181640625, 0.8746392023091052
eval metrics, batch: 4096 acc, f1
0.854400634765625, 0.8351359756729673
train metrics, batch: 4096  acc, f1 
0.9517784118652344, 0.9507163882336888
eval metrics, batch: 5120 acc, f1
0.901611328125, 0.897754661930737
eval metrics, batch: 6144 acc, f1
0.8743896484375, 0.8610586011342155
eval metrics, batch: 7168 acc, f1
0.8790283203125, 0.8667294244217321
Epoch loss - train: tensor(0.1754, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.2981, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.89031982421875, 0.8850802583615783
train metrics acc, f1 
0.9541740417480469, 0.9549249374322261
Epoch 2/20
----------
eval metrics, batch: 1024 acc, f1
0.888702392578125, 0.8796012016770658
eval metrics, batch: 2048 acc, f1
0.864837646484375, 0.8492049981274046
eval metrics, batch: 3072 acc, f1
0.89691162109375, 0.891800128122998
eval metrics, batch: 4096 acc, f1
0.875, 0.8606992245952931
train metrics, batch: 4096  acc, f1 
0.9631881713867188, 0.9625169935909885
eval metrics, batch: 5120 acc, f1
0.86639404296875, 0.8513816280806572
eval metrics, batch: 6144 acc, f1
0.8992919921875, 0.8955563995442462
eval metrics, batch: 7168 acc, f1
0.894439697265625, 0.8912435151705707
Epoch loss - train: tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3163, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.88836669921875, 0.8785766447586802
train metrics acc, f1 
0.96893310546875, 0.9685889721990805
Epoch 3/20
----------
eval metrics, batch: 1024 acc, f1
0.86236572265625, 0.8473773265651439
eval metrics, batch: 2048 acc, f1
0.8333740234375, 0.8038370338435008
eval metrics, batch: 3072 acc, f1
0.879730224609375, 0.8674090771456447
eval metrics, batch: 4096 acc, f1
0.871734619140625, 0.8586133817741447
train metrics, batch: 4096  acc, f1 
0.9745292663574219, 0.9745301407956423
eval metrics, batch: 5120 acc, f1
0.81378173828125, 0.7745844107868489
eval metrics, batch: 6144 acc, f1
0.894989013671875, 0.8886299640741819
eval metrics, batch: 7168 acc, f1
0.867889404296875, 0.8533586260628028
Epoch loss - train: tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3655, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.86798095703125, 0.8522238163558106
train metrics acc, f1 
0.9587135314941406, 0.9576530153103345
Epoch 4/20
----------
eval metrics, batch: 1024 acc, f1
0.85198974609375, 0.8318541117736791
eval metrics, batch: 2048 acc, f1
0.878936767578125, 0.8683765221142042
eval metrics, batch: 3072 acc, f1
0.773834228515625, 0.7118024499319463
eval metrics, batch: 4096 acc, f1
0.853179931640625, 0.833581237676848
train metrics, batch: 4096  acc, f1 
0.9783782958984375, 0.9782637040673104
eval metrics, batch: 5120 acc, f1
0.84619140625, 0.8226101647191327
eval metrics, batch: 6144 acc, f1
0.855377197265625, 0.8353885164472542
eval metrics, batch: 7168 acc, f1
0.87957763671875, 0.8686855241264559
Epoch loss - train: tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4715, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.833740234375, 0.8053590568060022
train metrics acc, f1 
0.9744110107421875, 0.9740261751723069
Epoch 5/20
----------
eval metrics, batch: 1024 acc, f1
0.86224365234375, 0.8453474030423461
eval metrics, batch: 2048 acc, f1
0.888336181640625, 0.881986776326399
eval metrics, batch: 3072 acc, f1
0.831207275390625, 0.7995796644562815
eval metrics, batch: 4096 acc, f1
0.859466552734375, 0.8423754920417593
train metrics, batch: 4096  acc, f1 
0.9785537719726562, 0.9785047372163979
eval metrics, batch: 5120 acc, f1
0.865509033203125, 0.8496366303865707
eval metrics, batch: 6144 acc, f1
0.870758056640625, 0.8579955068235925
eval metrics, batch: 7168 acc, f1
0.880218505859375, 0.8684254634440682
Epoch loss - train: tensor(0.0743, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3135, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.900177001953125, 0.896804113954002
train metrics acc, f1 
0.97320556640625, 0.9736344253926309
Epoch 6/20
----------
eval metrics, batch: 1024 acc, f1
0.88037109375, 0.8690977092099111
eval metrics, batch: 2048 acc, f1
0.86981201171875, 0.8559562398703403
eval metrics, batch: 3072 acc, f1
0.87548828125, 0.8629308607135658
eval metrics, batch: 4096 acc, f1
0.860595703125, 0.8416418220897178
train metrics, batch: 4096  acc, f1 
0.9791488647460938, 0.9788933081051859
eval metrics, batch: 5120 acc, f1
0.8956298828125, 0.888599348534202
eval metrics, batch: 6144 acc, f1
0.857940673828125, 0.8387096774193549
eval metrics, batch: 7168 acc, f1
0.8975830078125, 0.8904413685035257
Epoch loss - train: tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3238, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.892669677734375, 0.8882534235694087
train metrics acc, f1 
0.9724807739257812, 0.9729962417835807
Epoch 7/20
----------
eval metrics, batch: 1024 acc, f1
0.862457275390625, 0.8442801368206475
eval metrics, batch: 2048 acc, f1
0.8551025390625, 0.834817701085444
eval metrics, batch: 3072 acc, f1
0.850555419921875, 0.8278189937062691
eval metrics, batch: 4096 acc, f1
0.891143798828125, 0.8851170730136236
train metrics, batch: 4096  acc, f1 
0.9804649353027344, 0.9807026336515019
eval metrics, batch: 5120 acc, f1
0.882110595703125, 0.871100136808035
eval metrics, batch: 6144 acc, f1
0.86541748046875, 0.8483285183656624
eval metrics, batch: 7168 acc, f1
0.87921142578125, 0.8671990336867534
Epoch loss - train: tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5909, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.83099365234375, 0.8005905228287484
train metrics acc, f1 
0.98565673828125, 0.985505682081014
Epoch 8/20
----------
eval metrics, batch: 1024 acc, f1
0.877410888671875, 0.8654226272236926
eval metrics, batch: 2048 acc, f1
0.869354248046875, 0.8531036612565625
eval metrics, batch: 3072 acc, f1
0.830047607421875, 0.8005301049464523
eval metrics, batch: 4096 acc, f1
0.894805908203125, 0.889338341519792
train metrics, batch: 4096  acc, f1 
0.9806671142578125, 0.9808779250964027
eval metrics, batch: 5120 acc, f1
0.872406005859375, 0.8594858007057637
eval metrics, batch: 6144 acc, f1
0.868011474609375, 0.8524646085621695
eval metrics, batch: 7168 acc, f1
0.834503173828125, 0.8055226824457594
Epoch loss - train: tensor(0.0514, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5187, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.867767333984375, 0.8514824335904028
train metrics acc, f1 
0.9871368408203125, 0.9870641040395903
Epoch 9/20
----------
eval metrics, batch: 1024 acc, f1
0.852508544921875, 0.8317610610227312
eval metrics, batch: 2048 acc, f1
0.8642578125, 0.8469689671781463
eval metrics, batch: 3072 acc, f1
0.866302490234375, 0.8516474213538315
eval metrics, batch: 4096 acc, f1
0.816436767578125, 0.7791120414233778
train metrics, batch: 4096  acc, f1 
0.9818572998046875, 0.9816039669830661
eval metrics, batch: 5120 acc, f1
0.8587646484375, 0.8405237767057202
eval metrics, batch: 6144 acc, f1
0.87872314453125, 0.8702663880908853
eval metrics, batch: 7168 acc, f1
0.8671875, 0.8544092064766493
Epoch loss - train: tensor(0.0452, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4447, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.89263916015625, 0.8854966801197761
train metrics acc, f1 
0.9894447326660156, 0.9894832061968126
Epoch 10/20
----------
eval metrics, batch: 1024 acc, f1
0.86004638671875, 0.8411499826809837
eval metrics, batch: 2048 acc, f1
0.843231201171875, 0.8176881853994392
eval metrics, batch: 3072 acc, f1
0.85760498046875, 0.838266897746967
eval metrics, batch: 4096 acc, f1
0.858856201171875, 0.8394821781834588
train metrics, batch: 4096  acc, f1 
0.9913406372070312, 0.9913034150378129
eval metrics, batch: 5120 acc, f1
0.86688232421875, 0.8507186858316221
eval metrics, batch: 6144 acc, f1
0.84912109375, 0.8287851502978252
eval metrics, batch: 7168 acc, f1
0.8775634765625, 0.8654142905065414
Epoch loss - train: tensor(0.0409, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4080, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.892364501953125, 0.8881134409796022
train metrics acc, f1 
0.9807701110839844, 0.981061047221523
Epoch 11/20
----------
eval metrics, batch: 1024 acc, f1
0.852386474609375, 0.8311162319751405
eval metrics, batch: 2048 acc, f1
0.8392333984375, 0.8150280898876404
eval metrics, batch: 3072 acc, f1
0.843414306640625, 0.8182236865412549
eval metrics, batch: 4096 acc, f1
0.87371826171875, 0.8596241264671959
train metrics, batch: 4096  acc, f1 
0.9920883178710938, 0.9920802816578712
eval metrics, batch: 5120 acc, f1
0.882659912109375, 0.8742683365488375
eval metrics, batch: 6144 acc, f1
0.830108642578125, 0.7997121784493614
eval metrics, batch: 7168 acc, f1
0.8682861328125, 0.853446519524618
Epoch loss - train: tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(1.0284, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.783111572265625, 0.7261588255692983
train metrics acc, f1 
0.9727363586425781, 0.9720110749517331
Epoch 12/20
----------
eval metrics, batch: 1024 acc, f1
0.8577880859375, 0.8381157507121517
eval metrics, batch: 2048 acc, f1
0.888671875, 0.8823073945025165
eval metrics, batch: 3072 acc, f1
0.849700927734375, 0.8266882499912025
eval metrics, batch: 4096 acc, f1
0.814544677734375, 0.7755162350855158
train metrics, batch: 4096  acc, f1 
0.9866065979003906, 0.9864402983057131
eval metrics, batch: 5120 acc, f1
0.855804443359375, 0.8348652710306504
eval metrics, batch: 6144 acc, f1
0.87939453125, 0.8679938539648607
eval metrics, batch: 7168 acc, f1
0.816864013671875, 0.7793831109150399
Epoch loss - train: tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6565, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.86273193359375, 0.8456523231075423
train metrics acc, f1 
0.9942550659179688, 0.994245011196625
Epoch 13/20
----------
eval metrics, batch: 1024 acc, f1
0.859710693359375, 0.8426816330721056
eval metrics, batch: 2048 acc, f1
0.87030029296875, 0.8580873514091091
eval metrics, batch: 3072 acc, f1
0.88507080078125, 0.8765731515469324
eval metrics, batch: 4096 acc, f1
0.85260009765625, 0.8321867834062956
train metrics, batch: 4096  acc, f1 
0.9936027526855469, 0.9936017031602321
eval metrics, batch: 5120 acc, f1
0.821380615234375, 0.7880499728408473
eval metrics, batch: 6144 acc, f1
0.8673095703125, 0.8511366748835936
eval metrics, batch: 7168 acc, f1
0.8428955078125, 0.8179374734757392
Epoch loss - train: tensor(0.0299, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6414, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.858673095703125, 0.8387366368353241
train metrics acc, f1 
0.9934921264648438, 0.9934673559257132
Epoch 14/20
----------
eval metrics, batch: 1024 acc, f1
0.866912841796875, 0.8519034197031956
eval metrics, batch: 2048 acc, f1
0.86480712890625, 0.8490733169801036
eval metrics, batch: 3072 acc, f1
0.89678955078125, 0.8908257473045387
eval metrics, batch: 4096 acc, f1
0.865997314453125, 0.8549915788778442
train metrics, batch: 4096  acc, f1 
0.9823875427246094, 0.9826074836415416
eval metrics, batch: 5120 acc, f1
0.854095458984375, 0.8361492854450118
eval metrics, batch: 6144 acc, f1
0.867950439453125, 0.8527079007386731
eval metrics, batch: 7168 acc, f1
0.8878173828125, 0.8783748014822658
Epoch loss - train: tensor(0.0273, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.9260, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8240966796875, 0.7915672235481305
train metrics acc, f1 
0.9914741516113281, 0.99142893300762
Epoch 15/20
----------
eval metrics, batch: 1024 acc, f1
0.859039306640625, 0.8406746921458383
eval metrics, batch: 2048 acc, f1
0.864288330078125, 0.8484063405488325
eval metrics, batch: 3072 acc, f1
0.86883544921875, 0.8552081929659076
eval metrics, batch: 4096 acc, f1
0.8460693359375, 0.8273194111605614
train metrics, batch: 4096  acc, f1 
0.9830245971679688, 0.9830984845607506
eval metrics, batch: 5120 acc, f1
0.871337890625, 0.8599149388623073
eval metrics, batch: 6144 acc, f1
0.860137939453125, 0.8428272574505299
eval metrics, batch: 7168 acc, f1
0.863739013671875, 0.8490176850505529
Epoch loss - train: tensor(0.0260, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.7867, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.84722900390625, 0.8244001683737898
train metrics acc, f1 
0.9958229064941406, 0.9958153879078085
Epoch 16/20
----------
eval metrics, batch: 1024 acc, f1
0.85711669921875, 0.8382058193378948
eval metrics, batch: 2048 acc, f1
0.79669189453125, 0.7496429913566328
eval metrics, batch: 3072 acc, f1
0.889373779296875, 0.8817330592802844
eval metrics, batch: 4096 acc, f1
0.829254150390625, 0.7988929226124151
train metrics, batch: 4096  acc, f1 
0.9923591613769531, 0.9923165150811887
eval metrics, batch: 5120 acc, f1
0.848358154296875, 0.8254592714882855
eval metrics, batch: 6144 acc, f1
0.882659912109375, 0.8732069249793899
eval metrics, batch: 7168 acc, f1
0.868377685546875, 0.8568203698170833
Epoch loss - train: tensor(0.0236, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8821, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.826873779296875, 0.797515793982225
train metrics acc, f1 
0.992706298828125, 0.9926966034622378
Epoch 17/20
----------
eval metrics, batch: 1024 acc, f1
0.86810302734375, 0.852722687930212
eval metrics, batch: 2048 acc, f1
0.868804931640625, 0.8541673733844432
eval metrics, batch: 3072 acc, f1
0.852447509765625, 0.8323102001179205
eval metrics, batch: 4096 acc, f1
0.865936279296875, 0.8506341164870287
train metrics, batch: 4096  acc, f1 
0.9961433410644531, 0.9961461783888662
eval metrics, batch: 5120 acc, f1
0.831085205078125, 0.8006482982171799
eval metrics, batch: 6144 acc, f1
0.870941162109375, 0.8580443758182001
eval metrics, batch: 7168 acc, f1
0.869781494140625, 0.8561992383648435
Epoch loss - train: tensor(0.0225, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6275, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.868011474609375, 0.8539394144068083
train metrics acc, f1 
0.9951820373535156, 0.9951959467940648
Epoch 18/20
----------
eval metrics, batch: 1024 acc, f1
0.845794677734375, 0.8212656078667185
eval metrics, batch: 2048 acc, f1
0.881988525390625, 0.8729673795210408
eval metrics, batch: 3072 acc, f1
0.868621826171875, 0.8538746138963376
eval metrics, batch: 4096 acc, f1
0.8809814453125, 0.8707068028112982
train metrics, batch: 4096  acc, f1 
0.9936752319335938, 0.9936905876353783
eval metrics, batch: 5120 acc, f1
0.861053466796875, 0.8429729263666149
eval metrics, batch: 6144 acc, f1
0.85931396484375, 0.8406828863699198
eval metrics, batch: 7168 acc, f1
0.9005126953125, 0.8983663798478613
Epoch loss - train: tensor(0.0207, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8330, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.836639404296875, 0.810426036760279
train metrics acc, f1 
0.9960098266601562, 0.9960053465724652
Epoch 19/20
----------
eval metrics, batch: 1024 acc, f1
0.85479736328125, 0.8347457627118644
eval metrics, batch: 2048 acc, f1
0.8709716796875, 0.8575663657189058
eval metrics, batch: 3072 acc, f1
0.874481201171875, 0.8610613789142992
eval metrics, batch: 4096 acc, f1
0.862030029296875, 0.8509642327344651
train metrics, batch: 4096  acc, f1 
0.9884109497070312, 0.9885332528119575
eval metrics, batch: 5120 acc, f1
0.8499755859375, 0.8293529575118023
eval metrics, batch: 6144 acc, f1
0.8743896484375, 0.8647476340694006
eval metrics, batch: 7168 acc, f1
0.860382080078125, 0.8434880777257021
Epoch loss - train: tensor(0.0193, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6663, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.863677978515625, 0.8493677288821446
train metrics acc, f1 
0.9959831237792969, 0.9959915186167885
Epoch 20/20
----------
eval metrics, batch: 1024 acc, f1
0.8583984375, 0.8398343113565757
eval metrics, batch: 2048 acc, f1
0.8914794921875, 0.8875039544447959
eval metrics, batch: 3072 acc, f1
0.824066162109375, 0.7948471584641116
eval metrics, batch: 4096 acc, f1
0.864410400390625, 0.850086041097277
train metrics, batch: 4096  acc, f1 
0.994476318359375, 0.9944946315053077
eval metrics, batch: 5120 acc, f1
0.8525390625, 0.8322571686454211
eval metrics, batch: 6144 acc, f1
0.82940673828125, 0.7973903588256614
eval metrics, batch: 7168 acc, f1
0.862884521484375, 0.8454792447639028
Epoch loss - train: tensor(0.0188, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.7151, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.865020751953125, 0.8482623760677896
train metrics acc, f1 
0.9968605041503906, 0.996855333896291
Training time 507m 15s
train_acc
0.5075912475585938	0.9517784118652344	0.9541740417480469	0.9631881713867188	0.96893310546875	0.9745292663574219	0.9587135314941406	0.9783782958984375	0.9744110107421875	0.9785537719726562	0.97320556640625	0.9791488647460938	0.9724807739257812	0.9804649353027344	0.98565673828125	0.9806671142578125	0.9871368408203125	0.9818572998046875	0.9894447326660156	0.9913406372070312	0.9807701110839844	0.9920883178710938	0.9727363586425781	0.9866065979003906	0.9942550659179688	0.9936027526855469	0.9934921264648438	0.9823875427246094	0.9914741516113281	0.9830245971679688	0.9958229064941406	0.9923591613769531	0.992706298828125	0.9961433410644531	0.9951820373535156	0.9936752319335938	0.9960098266601562	0.9884109497070312	0.9959831237792969	0.994476318359375	0.9968605041503906
train_f1
0.6009385897657854	0.9507163882336888	0.9549249374322261	0.9625169935909885	0.9685889721990805	0.9745301407956423	0.9576530153103345	0.9782637040673104	0.9740261751723069	0.9785047372163979	0.9736344253926309	0.9788933081051859	0.9729962417835807	0.9807026336515019	0.985505682081014	0.9808779250964027	0.9870641040395903	0.9816039669830661	0.9894832061968126	0.9913034150378129	0.981061047221523	0.9920802816578712	0.9720110749517331	0.9864402983057131	0.994245011196625	0.9936017031602321	0.9934673559257132	0.9826074836415416	0.99142893300762	0.9830984845607506	0.9958153879078085	0.9923165150811887	0.9926966034622378	0.9961461783888662	0.9951959467940648	0.9936905876353783	0.9960053465724652	0.9885332528119575	0.9959915186167885	0.9944946315053077	0.996855333896291
train_loss
tensor(0.1754, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1234, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1019, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0872, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0743, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0654, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0580, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0514, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0452, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0409, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0365, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0328, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0299, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0273, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0260, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0236, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0225, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0207, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0193, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0188, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.541595458984375	0.87799072265625	0.865203857421875	0.88336181640625	0.854400634765625	0.901611328125	0.8743896484375	0.8790283203125	0.89031982421875	0.888702392578125	0.864837646484375	0.89691162109375	0.875	0.86639404296875	0.8992919921875	0.894439697265625	0.88836669921875	0.86236572265625	0.8333740234375	0.879730224609375	0.871734619140625	0.81378173828125	0.894989013671875	0.867889404296875	0.86798095703125	0.85198974609375	0.878936767578125	0.773834228515625	0.853179931640625	0.84619140625	0.855377197265625	0.87957763671875	0.833740234375	0.86224365234375	0.888336181640625	0.831207275390625	0.859466552734375	0.865509033203125	0.870758056640625	0.880218505859375	0.900177001953125	0.88037109375	0.86981201171875	0.87548828125	0.860595703125	0.8956298828125	0.857940673828125	0.8975830078125	0.892669677734375	0.862457275390625	0.8551025390625	0.850555419921875	0.891143798828125	0.882110595703125	0.86541748046875	0.87921142578125	0.83099365234375	0.877410888671875	0.869354248046875	0.830047607421875	0.894805908203125	0.872406005859375	0.868011474609375	0.834503173828125	0.867767333984375	0.852508544921875	0.8642578125	0.866302490234375	0.816436767578125	0.8587646484375	0.87872314453125	0.8671875	0.89263916015625	0.86004638671875	0.843231201171875	0.85760498046875	0.858856201171875	0.86688232421875	0.84912109375	0.8775634765625	0.892364501953125	0.852386474609375	0.8392333984375	0.843414306640625	0.87371826171875	0.882659912109375	0.830108642578125	0.8682861328125	0.783111572265625	0.8577880859375	0.888671875	0.849700927734375	0.814544677734375	0.855804443359375	0.87939453125	0.816864013671875	0.86273193359375	0.859710693359375	0.87030029296875	0.88507080078125	0.85260009765625	0.821380615234375	0.8673095703125	0.8428955078125	0.858673095703125	0.866912841796875	0.86480712890625	0.89678955078125	0.865997314453125	0.854095458984375	0.867950439453125	0.8878173828125	0.8240966796875	0.859039306640625	0.864288330078125	0.86883544921875	0.8460693359375	0.871337890625	0.860137939453125	0.863739013671875	0.84722900390625	0.85711669921875	0.79669189453125	0.889373779296875	0.829254150390625	0.848358154296875	0.882659912109375	0.868377685546875	0.826873779296875	0.86810302734375	0.868804931640625	0.852447509765625	0.865936279296875	0.831085205078125	0.870941162109375	0.869781494140625	0.868011474609375	0.845794677734375	0.881988525390625	0.868621826171875	0.8809814453125	0.861053466796875	0.85931396484375	0.9005126953125	0.836639404296875	0.85479736328125	0.8709716796875	0.874481201171875	0.862030029296875	0.8499755859375	0.8743896484375	0.860382080078125	0.863677978515625	0.8583984375	0.8914794921875	0.824066162109375	0.864410400390625	0.8525390625	0.82940673828125	0.862884521484375	0.865020751953125
valid_f1
0.6343031040779062	0.8686251314405888	0.858805101812486	0.8746392023091052	0.8351359756729673	0.897754661930737	0.8610586011342155	0.8667294244217321	0.8850802583615783	0.8796012016770658	0.8492049981274046	0.891800128122998	0.8606992245952931	0.8513816280806572	0.8955563995442462	0.8912435151705707	0.8785766447586802	0.8473773265651439	0.8038370338435008	0.8674090771456447	0.8586133817741447	0.7745844107868489	0.8886299640741819	0.8533586260628028	0.8522238163558106	0.8318541117736791	0.8683765221142042	0.7118024499319463	0.833581237676848	0.8226101647191327	0.8353885164472542	0.8686855241264559	0.8053590568060022	0.8453474030423461	0.881986776326399	0.7995796644562815	0.8423754920417593	0.8496366303865707	0.8579955068235925	0.8684254634440682	0.896804113954002	0.8690977092099111	0.8559562398703403	0.8629308607135658	0.8416418220897178	0.888599348534202	0.8387096774193549	0.8904413685035257	0.8882534235694087	0.8442801368206475	0.834817701085444	0.8278189937062691	0.8851170730136236	0.871100136808035	0.8483285183656624	0.8671990336867534	0.8005905228287484	0.8654226272236926	0.8531036612565625	0.8005301049464523	0.889338341519792	0.8594858007057637	0.8524646085621695	0.8055226824457594	0.8514824335904028	0.8317610610227312	0.8469689671781463	0.8516474213538315	0.7791120414233778	0.8405237767057202	0.8702663880908853	0.8544092064766493	0.8854966801197761	0.8411499826809837	0.8176881853994392	0.838266897746967	0.8394821781834588	0.8507186858316221	0.8287851502978252	0.8654142905065414	0.8881134409796022	0.8311162319751405	0.8150280898876404	0.8182236865412549	0.8596241264671959	0.8742683365488375	0.7997121784493614	0.853446519524618	0.7261588255692983	0.8381157507121517	0.8823073945025165	0.8266882499912025	0.7755162350855158	0.8348652710306504	0.8679938539648607	0.7793831109150399	0.8456523231075423	0.8426816330721056	0.8580873514091091	0.8765731515469324	0.8321867834062956	0.7880499728408473	0.8511366748835936	0.8179374734757392	0.8387366368353241	0.8519034197031956	0.8490733169801036	0.8908257473045387	0.8549915788778442	0.8361492854450118	0.8527079007386731	0.8783748014822658	0.7915672235481305	0.8406746921458383	0.8484063405488325	0.8552081929659076	0.8273194111605614	0.8599149388623073	0.8428272574505299	0.8490176850505529	0.8244001683737898	0.8382058193378948	0.7496429913566328	0.8817330592802844	0.7988929226124151	0.8254592714882855	0.8732069249793899	0.8568203698170833	0.797515793982225	0.852722687930212	0.8541673733844432	0.8323102001179205	0.8506341164870287	0.8006482982171799	0.8580443758182001	0.8561992383648435	0.8539394144068083	0.8212656078667185	0.8729673795210408	0.8538746138963376	0.8707068028112982	0.8429729263666149	0.8406828863699198	0.8983663798478613	0.810426036760279	0.8347457627118644	0.8575663657189058	0.8610613789142992	0.8509642327344651	0.8293529575118023	0.8647476340694006	0.8434880777257021	0.8493677288821446	0.8398343113565757	0.8875039544447959	0.7948471584641116	0.850086041097277	0.8322571686454211	0.7973903588256614	0.8454792447639028	0.8482623760677896
valid_loss
tensor(0.2981, device='cuda:0')	tensor(0.3163, device='cuda:0')	tensor(0.3655, device='cuda:0')	tensor(0.4715, device='cuda:0')	tensor(0.3135, device='cuda:0')	tensor(0.3238, device='cuda:0')	tensor(0.5909, device='cuda:0')	tensor(0.5187, device='cuda:0')	tensor(0.4447, device='cuda:0')	tensor(0.4080, device='cuda:0')	tensor(1.0284, device='cuda:0')	tensor(0.6565, device='cuda:0')	tensor(0.6414, device='cuda:0')	tensor(0.9260, device='cuda:0')	tensor(0.7867, device='cuda:0')	tensor(0.8821, device='cuda:0')	tensor(0.6275, device='cuda:0')	tensor(0.8330, device='cuda:0')	tensor(0.6663, device='cuda:0')	tensor(0.7151, device='cuda:0')
Best model metrics: train, valid, test: acc, f1
0.9729576110839844, 0.9733961308239356
0.900177001953125, 0.896804113954002
0.856597900390625, 0.8425004189710072
Model saved, path ./models/densenet_saturation-1560322029.pth
experiment validation
train set
Evaluation results
[[125419.   5653.]
 [  1401. 129671.]]
#############################
Accuracy
0.9730911254882812
------------------------
Recall
0.9893112182617188
------------------------
Specificity
0.9568710327148438
------------------------
Precision
0.9582261830865183
------------------------
Fall_out
0.04312896728515625
------------------------
F1
0.9735206234327842
------------------------
#############################
valid set
Evaluation results
[[15284.  1115.]
 [ 2156. 14213.]]
#############################
Accuracy
0.900177001953125
------------------------
Recall
0.8682876168367035
------------------------
Specificity
0.932008049271297
------------------------
Precision
0.9272573068893528
------------------------
Fall_out
0.06799195072870297
------------------------
F1
0.896804113954002
------------------------
#############################
test set
Evaluation results
[[15501.   890.]
 [ 3809. 12568.]]
#############################
Accuracy
0.856597900390625
------------------------
Recall
0.767417719973133
------------------------
Specificity
0.945701909584528
------------------------
Precision
0.933868331104176
------------------------
Fall_out
0.05429809041547191
------------------------
F1
0.8425004189710072
------------------------
#############################
AUC: 0.927155259738146
Experiment end
########################################
