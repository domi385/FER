----------------------------------------
Starting experiment alexnet_7
Experiment parameters Experiment[name: alexnet_7, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 1e-05, weight_decay: 0, batch_size: 32, num_epochs: 8), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.5106201171875, 0.667854183927092
train metrics acc, f1
0.49529266357421875, 0.6543242777194275
Epoch 1/8
----------
eval metrics, batch: 1024 acc, f1
0.810089111328125, 0.8055980756614913
eval metrics, batch: 2048 acc, f1
0.820892333984375, 0.8108543620484063
eval metrics, batch: 3072 acc, f1
0.8282470703125, 0.816282561859372
eval metrics, batch: 4096 acc, f1
0.7596435546875, 0.7004411988437548
train metrics, batch: 4096  acc, f1 
0.8715629577636719, 0.8585900585900585
eval metrics, batch: 5120 acc, f1
0.822906494140625, 0.8028671399938853
eval metrics, batch: 6144 acc, f1
0.81756591796875, 0.7969567284831194
eval metrics, batch: 7168 acc, f1
0.830657958984375, 0.8208786597372414
Epoch loss - train: tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3775, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.837738037109375, 0.8337970054077709
train metrics acc, f1 
0.9113693237304688, 0.9143781600554254
Epoch 2/8
----------
eval metrics, batch: 1024 acc, f1
0.830657958984375, 0.8169915240262524
eval metrics, batch: 2048 acc, f1
0.80535888671875, 0.7728308875908249
eval metrics, batch: 3072 acc, f1
0.832275390625, 0.8236539819033563
eval metrics, batch: 4096 acc, f1
0.83148193359375, 0.8239607243050242
train metrics, batch: 4096  acc, f1 
0.9214134216308594, 0.9234143639425562
eval metrics, batch: 5120 acc, f1
0.8338623046875, 0.820755959436323
eval metrics, batch: 6144 acc, f1
0.774658203125, 0.7243541884425863
eval metrics, batch: 7168 acc, f1
0.809722900390625, 0.7828055874873724
Epoch loss - train: tensor(0.1905, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4583, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8096923828125, 0.7842960913178831
train metrics acc, f1 
0.9451065063476562, 0.9450398356160198
Epoch 3/8
----------
eval metrics, batch: 1024 acc, f1
0.821197509765625, 0.8001909763666746
eval metrics, batch: 2048 acc, f1
0.808197021484375, 0.7817177786267495
eval metrics, batch: 3072 acc, f1
0.844024658203125, 0.8376274740286559
eval metrics, batch: 4096 acc, f1
0.81658935546875, 0.7907090123972698
train metrics, batch: 4096  acc, f1 
0.9461021423339844, 0.9453150701897659
eval metrics, batch: 5120 acc, f1
0.79058837890625, 0.7513587941155156
eval metrics, batch: 6144 acc, f1
0.809417724609375, 0.7814523184601925
eval metrics, batch: 7168 acc, f1
0.819732666015625, 0.8043067748881895
Epoch loss - train: tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4763, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8211669921875, 0.8033029001074113
train metrics acc, f1 
0.9549560546875, 0.9554307455385451
Epoch 4/8
----------
eval metrics, batch: 1024 acc, f1
0.800140380859375, 0.7687744942273065
eval metrics, batch: 2048 acc, f1
0.800262451171875, 0.7689972823209685
eval metrics, batch: 3072 acc, f1
0.808258056640625, 0.780980932129536
eval metrics, batch: 4096 acc, f1
0.8203125, 0.798134942402633
train metrics, batch: 4096  acc, f1 
0.9610557556152344, 0.9609722344341949
eval metrics, batch: 5120 acc, f1
0.788238525390625, 0.7453484531542441
eval metrics, batch: 6144 acc, f1
0.79449462890625, 0.757420749279539
eval metrics, batch: 7168 acc, f1
0.789459228515625, 0.7518256052375984
Epoch loss - train: tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6186, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7960205078125, 0.7626589020666146
train metrics acc, f1 
0.9681777954101562, 0.9681892021751234
Epoch 5/8
----------
eval metrics, batch: 1024 acc, f1
0.79498291015625, 0.7572450675724507
eval metrics, batch: 2048 acc, f1
0.80206298828125, 0.7708774904620602
eval metrics, batch: 3072 acc, f1
0.7874755859375, 0.743650150923949
eval metrics, batch: 4096 acc, f1
0.791778564453125, 0.7565388046387155
train metrics, batch: 4096  acc, f1 
0.9718246459960938, 0.9717024504620477
eval metrics, batch: 5120 acc, f1
0.788116455078125, 0.748578671012131
eval metrics, batch: 6144 acc, f1
0.807586669921875, 0.7780789130970399
eval metrics, batch: 7168 acc, f1
0.817108154296875, 0.7943306221901918
Epoch loss - train: tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.7445, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.777984619140625, 0.7272522775840737
train metrics acc, f1 
0.9697494506835938, 0.9690565566542061
Epoch 6/8
----------
eval metrics, batch: 1024 acc, f1
0.810791015625, 0.7875839386049062
eval metrics, batch: 2048 acc, f1
0.805755615234375, 0.7761561455952172
eval metrics, batch: 3072 acc, f1
0.80523681640625, 0.7785872883708022
eval metrics, batch: 4096 acc, f1
0.806793212890625, 0.7780076440267891
train metrics, batch: 4096  acc, f1 
0.980316162109375, 0.9802426024627826
eval metrics, batch: 5120 acc, f1
0.7960205078125, 0.7643325576475566
eval metrics, batch: 6144 acc, f1
0.796783447265625, 0.7633028827355774
eval metrics, batch: 7168 acc, f1
0.8011474609375, 0.773198746954403
Epoch loss - train: tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.7156, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.78955078125, 0.7516744688512783
train metrics acc, f1 
0.984527587890625, 0.9844383057090239
Epoch 7/8
----------
eval metrics, batch: 1024 acc, f1
0.81610107421875, 0.7975270479134466
eval metrics, batch: 2048 acc, f1
0.812530517578125, 0.7873879486380784
eval metrics, batch: 3072 acc, f1
0.80694580078125, 0.7763557943859153
eval metrics, batch: 4096 acc, f1
0.797149658203125, 0.763376170303656
train metrics, batch: 4096  acc, f1 
0.9854545593261719, 0.98543160726089
eval metrics, batch: 5120 acc, f1
0.776885986328125, 0.728124651370347
eval metrics, batch: 6144 acc, f1
0.805450439453125, 0.7778203743073223
eval metrics, batch: 7168 acc, f1
0.815521240234375, 0.7963892350702281
Epoch loss - train: tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8523, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7921142578125, 0.7576145744378024
train metrics acc, f1 
0.98370361328125, 0.9837402087282194
Epoch 8/8
----------
eval metrics, batch: 1024 acc, f1
0.7860107421875, 0.7481321839080459
eval metrics, batch: 2048 acc, f1
0.809356689453125, 0.7868136368289936
eval metrics, batch: 3072 acc, f1
0.813995361328125, 0.7900520133650236
eval metrics, batch: 4096 acc, f1
0.821380615234375, 0.8049715104461698
train metrics, batch: 4096  acc, f1 
0.9806327819824219, 0.9809150405419121
eval metrics, batch: 5120 acc, f1
0.795257568359375, 0.7589725166157715
eval metrics, batch: 6144 acc, f1
0.786468505859375, 0.74572082712505
eval metrics, batch: 7168 acc, f1
0.80206298828125, 0.7750572241104252
Epoch loss - train: tensor(0.0483, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8916, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.80316162109375, 0.7774173510939333
train metrics acc, f1 
0.984954833984375, 0.9850244150636767
Training time 90m 20s
train_acc
0.49529266357421875	0.8715629577636719	0.9113693237304688	0.9214134216308594	0.9451065063476562	0.9461021423339844	0.9549560546875	0.9610557556152344	0.9681777954101562	0.9718246459960938	0.9697494506835938	0.980316162109375	0.984527587890625	0.9854545593261719	0.98370361328125	0.9806327819824219	0.984954833984375
train_f1
0.6543242777194275	0.8585900585900585	0.9143781600554254	0.9234143639425562	0.9450398356160198	0.9453150701897659	0.9554307455385451	0.9609722344341949	0.9681892021751234	0.9717024504620477	0.9690565566542061	0.9802426024627826	0.9844383057090239	0.98543160726089	0.9837402087282194	0.9809150405419121	0.9850244150636767
train_loss
tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1905, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1500, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0766, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0600, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0483, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.5106201171875	0.810089111328125	0.820892333984375	0.8282470703125	0.7596435546875	0.822906494140625	0.81756591796875	0.830657958984375	0.837738037109375	0.830657958984375	0.80535888671875	0.832275390625	0.83148193359375	0.8338623046875	0.774658203125	0.809722900390625	0.8096923828125	0.821197509765625	0.808197021484375	0.844024658203125	0.81658935546875	0.79058837890625	0.809417724609375	0.819732666015625	0.8211669921875	0.800140380859375	0.800262451171875	0.808258056640625	0.8203125	0.788238525390625	0.79449462890625	0.789459228515625	0.7960205078125	0.79498291015625	0.80206298828125	0.7874755859375	0.791778564453125	0.788116455078125	0.807586669921875	0.817108154296875	0.777984619140625	0.810791015625	0.805755615234375	0.80523681640625	0.806793212890625	0.7960205078125	0.796783447265625	0.8011474609375	0.78955078125	0.81610107421875	0.812530517578125	0.80694580078125	0.797149658203125	0.776885986328125	0.805450439453125	0.815521240234375	0.7921142578125	0.7860107421875	0.809356689453125	0.813995361328125	0.821380615234375	0.795257568359375	0.786468505859375	0.80206298828125	0.80316162109375
valid_f1
0.667854183927092	0.8055980756614913	0.8108543620484063	0.816282561859372	0.7004411988437548	0.8028671399938853	0.7969567284831194	0.8208786597372414	0.8337970054077709	0.8169915240262524	0.7728308875908249	0.8236539819033563	0.8239607243050242	0.820755959436323	0.7243541884425863	0.7828055874873724	0.7842960913178831	0.8001909763666746	0.7817177786267495	0.8376274740286559	0.7907090123972698	0.7513587941155156	0.7814523184601925	0.8043067748881895	0.8033029001074113	0.7687744942273065	0.7689972823209685	0.780980932129536	0.798134942402633	0.7453484531542441	0.757420749279539	0.7518256052375984	0.7626589020666146	0.7572450675724507	0.7708774904620602	0.743650150923949	0.7565388046387155	0.748578671012131	0.7780789130970399	0.7943306221901918	0.7272522775840737	0.7875839386049062	0.7761561455952172	0.7785872883708022	0.7780076440267891	0.7643325576475566	0.7633028827355774	0.773198746954403	0.7516744688512783	0.7975270479134466	0.7873879486380784	0.7763557943859153	0.763376170303656	0.728124651370347	0.7778203743073223	0.7963892350702281	0.7576145744378024	0.7481321839080459	0.7868136368289936	0.7900520133650236	0.8049715104461698	0.7589725166157715	0.74572082712505	0.7750572241104252	0.7774173510939333
valid_loss
tensor(0.3775, device='cuda:0')	tensor(0.4583, device='cuda:0')	tensor(0.4763, device='cuda:0')	tensor(0.6186, device='cuda:0')	tensor(0.7445, device='cuda:0')	tensor(0.7156, device='cuda:0')	tensor(0.8523, device='cuda:0')	tensor(0.8916, device='cuda:0')
Experiment end
########################################
----------------------------------------
Starting experiment alexnet_8
Experiment parameters Experiment[name: alexnet_8, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 1e-06, weight_decay: 0, batch_size: 32, num_epochs: 8), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-06
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.44818115234375, 0.22261392949269132
train metrics acc, f1
0.4727134704589844, 0.2693814122385551
Epoch 1/8
----------
eval metrics, batch: 1024 acc, f1
0.784912109375, 0.7802718543459284
eval metrics, batch: 2048 acc, f1
0.790618896484375, 0.7868526515269192
eval metrics, batch: 3072 acc, f1
0.792266845703125, 0.7841446012367211
eval metrics, batch: 4096 acc, f1
0.790679931640625, 0.7735182433547961
train metrics, batch: 4096  acc, f1 
0.8372726440429688, 0.8333489600425047
eval metrics, batch: 5120 acc, f1
0.798919677734375, 0.7880055339274799
eval metrics, batch: 6144 acc, f1
0.801300048828125, 0.7873820331123665
eval metrics, batch: 7168 acc, f1
0.802642822265625, 0.786842018524012
Epoch loss - train: tensor(0.3868, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4150, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8006591796875, 0.7843085457667415
train metrics acc, f1 
0.8591499328613281, 0.8567882367999503
Epoch 2/8
----------
eval metrics, batch: 1024 acc, f1
0.8145751953125, 0.8144166157605376
eval metrics, batch: 2048 acc, f1
0.805572509765625, 0.7891305067355112
eval metrics, batch: 3072 acc, f1
0.814300537109375, 0.8030808064463933
eval metrics, batch: 4096 acc, f1
0.816741943359375, 0.8071797835789745
train metrics, batch: 4096  acc, f1 
0.8704948425292969, 0.8704676655639878
eval metrics, batch: 5120 acc, f1
0.819793701171875, 0.8116367348240773
eval metrics, batch: 6144 acc, f1
0.8212890625, 0.8146600835548804
eval metrics, batch: 7168 acc, f1
0.815032958984375, 0.8020122170319799
Epoch loss - train: tensor(0.3090, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4177, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.81011962890625, 0.7913760729613734
train metrics acc, f1 
0.8786735534667969, 0.8754888642689644
Epoch 3/8
----------
eval metrics, batch: 1024 acc, f1
0.819915771484375, 0.812625027783952
eval metrics, batch: 2048 acc, f1
0.8160400390625, 0.799534419687396
eval metrics, batch: 3072 acc, f1
0.8209228515625, 0.8101953680941907
eval metrics, batch: 4096 acc, f1
0.82171630859375, 0.8126723529789008
train metrics, batch: 4096  acc, f1 
0.8857192993164062, 0.8865270254914587
eval metrics, batch: 5120 acc, f1
0.81793212890625, 0.8013849124442373
eval metrics, batch: 6144 acc, f1
0.82073974609375, 0.8100135843198137
eval metrics, batch: 7168 acc, f1
0.82293701171875, 0.8092702169625247
Epoch loss - train: tensor(0.2775, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3847, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.82403564453125, 0.8124878048780488
train metrics acc, f1 
0.8937454223632812, 0.8935098102185316
Epoch 4/8
----------
eval metrics, batch: 1024 acc, f1
0.82818603515625, 0.8260627780523975
eval metrics, batch: 2048 acc, f1
0.82635498046875, 0.8178267272843696
eval metrics, batch: 3072 acc, f1
0.82684326171875, 0.8183738796414852
eval metrics, batch: 4096 acc, f1
0.824432373046875, 0.8132203499886367
train metrics, batch: 4096  acc, f1 
0.898101806640625, 0.8984226457569627
eval metrics, batch: 5120 acc, f1
0.822967529296875, 0.8100212870476502
eval metrics, batch: 6144 acc, f1
0.8240966796875, 0.8126015995838481
eval metrics, batch: 7168 acc, f1
0.81689453125, 0.7987117552334944
Epoch loss - train: tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3876, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.827911376953125, 0.8137776163270698
train metrics acc, f1 
0.9035453796386719, 0.9026140342092999
Epoch 5/8
----------
eval metrics, batch: 1024 acc, f1
0.83148193359375, 0.8285306173146193
eval metrics, batch: 2048 acc, f1
0.822174072265625, 0.8060059260245697
eval metrics, batch: 3072 acc, f1
0.824951171875, 0.8097386227942152
eval metrics, batch: 4096 acc, f1
0.815673828125, 0.7956421707944241
train metrics, batch: 4096  acc, f1 
0.9076957702636719, 0.9061699000701874
eval metrics, batch: 5120 acc, f1
0.821624755859375, 0.8058204046377196
eval metrics, batch: 6144 acc, f1
0.821685791015625, 0.8044053158370434
eval metrics, batch: 7168 acc, f1
0.814666748046875, 0.7929494391599332
Epoch loss - train: tensor(0.2373, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4026, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.825836181640625, 0.811345079501504
train metrics acc, f1 
0.9112396240234375, 0.9109938030755107
Epoch 6/8
----------
eval metrics, batch: 1024 acc, f1
0.8265380859375, 0.8148895981241451
eval metrics, batch: 2048 acc, f1
0.827484130859375, 0.8129322611601972
eval metrics, batch: 3072 acc, f1
0.83001708984375, 0.8170531432700519
eval metrics, batch: 4096 acc, f1
0.823822021484375, 0.8085938795132788
train metrics, batch: 4096  acc, f1 
0.9136276245117188, 0.9133526206220915
eval metrics, batch: 5120 acc, f1
0.820709228515625, 0.8040425602881826
eval metrics, batch: 6144 acc, f1
0.821014404296875, 0.8012605469147097
eval metrics, batch: 7168 acc, f1
0.82135009765625, 0.8037677661571467
Epoch loss - train: tensor(0.2228, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4175, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.81439208984375, 0.792946142847416
train metrics acc, f1 
0.9179039001464844, 0.9167656124907662
Epoch 7/8
----------
eval metrics, batch: 1024 acc, f1
0.823272705078125, 0.8102990795033904
eval metrics, batch: 2048 acc, f1
0.8255615234375, 0.8102635597158601
eval metrics, batch: 3072 acc, f1
0.817108154296875, 0.7956351236146633
eval metrics, batch: 4096 acc, f1
0.8214111328125, 0.8015194681861348
train metrics, batch: 4096  acc, f1 
0.9198989868164062, 0.9187742249936174
eval metrics, batch: 5120 acc, f1
0.820831298828125, 0.8011380957219795
eval metrics, batch: 6144 acc, f1
0.822967529296875, 0.8057722570060603
eval metrics, batch: 7168 acc, f1
0.823516845703125, 0.806128264440645
Epoch loss - train: tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3882, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.83038330078125, 0.8179137727689687
train metrics acc, f1 
0.9218635559082031, 0.9224437250336041
Epoch 8/8
----------
eval metrics, batch: 1024 acc, f1
0.8297119140625, 0.8213485304475892
eval metrics, batch: 2048 acc, f1
0.815093994140625, 0.7912920671006854
eval metrics, batch: 3072 acc, f1
0.81646728515625, 0.7951634877384196
eval metrics, batch: 4096 acc, f1
0.823883056640625, 0.8069318523970426
train metrics, batch: 4096  acc, f1 
0.9247512817382812, 0.9246524064171123
eval metrics, batch: 5120 acc, f1
0.826812744140625, 0.8127000891118519
eval metrics, batch: 6144 acc, f1
0.81207275390625, 0.7863734128911399
eval metrics, batch: 7168 acc, f1
0.824310302734375, 0.8072841696515248
Epoch loss - train: tensor(0.2011, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4092, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.826507568359375, 0.8095668777007335
train metrics acc, f1 
0.9276237487792969, 0.9273613402910447
Training time 88m 29s
train_acc
0.4727134704589844	0.8372726440429688	0.8591499328613281	0.8704948425292969	0.8786735534667969	0.8857192993164062	0.8937454223632812	0.898101806640625	0.9035453796386719	0.9076957702636719	0.9112396240234375	0.9136276245117188	0.9179039001464844	0.9198989868164062	0.9218635559082031	0.9247512817382812	0.9276237487792969
train_f1
0.2693814122385551	0.8333489600425047	0.8567882367999503	0.8704676655639878	0.8754888642689644	0.8865270254914587	0.8935098102185316	0.8984226457569627	0.9026140342092999	0.9061699000701874	0.9109938030755107	0.9133526206220915	0.9167656124907662	0.9187742249936174	0.9224437250336041	0.9246524064171123	0.9273613402910447
train_loss
tensor(0.3868, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3090, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2775, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2373, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2228, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2011, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.44818115234375	0.784912109375	0.790618896484375	0.792266845703125	0.790679931640625	0.798919677734375	0.801300048828125	0.802642822265625	0.8006591796875	0.8145751953125	0.805572509765625	0.814300537109375	0.816741943359375	0.819793701171875	0.8212890625	0.815032958984375	0.81011962890625	0.819915771484375	0.8160400390625	0.8209228515625	0.82171630859375	0.81793212890625	0.82073974609375	0.82293701171875	0.82403564453125	0.82818603515625	0.82635498046875	0.82684326171875	0.824432373046875	0.822967529296875	0.8240966796875	0.81689453125	0.827911376953125	0.83148193359375	0.822174072265625	0.824951171875	0.815673828125	0.821624755859375	0.821685791015625	0.814666748046875	0.825836181640625	0.8265380859375	0.827484130859375	0.83001708984375	0.823822021484375	0.820709228515625	0.821014404296875	0.82135009765625	0.81439208984375	0.823272705078125	0.8255615234375	0.817108154296875	0.8214111328125	0.820831298828125	0.822967529296875	0.823516845703125	0.83038330078125	0.8297119140625	0.815093994140625	0.81646728515625	0.823883056640625	0.826812744140625	0.81207275390625	0.824310302734375	0.826507568359375
valid_f1
0.22261392949269132	0.7802718543459284	0.7868526515269192	0.7841446012367211	0.7735182433547961	0.7880055339274799	0.7873820331123665	0.786842018524012	0.7843085457667415	0.8144166157605376	0.7891305067355112	0.8030808064463933	0.8071797835789745	0.8116367348240773	0.8146600835548804	0.8020122170319799	0.7913760729613734	0.812625027783952	0.799534419687396	0.8101953680941907	0.8126723529789008	0.8013849124442373	0.8100135843198137	0.8092702169625247	0.8124878048780488	0.8260627780523975	0.8178267272843696	0.8183738796414852	0.8132203499886367	0.8100212870476502	0.8126015995838481	0.7987117552334944	0.8137776163270698	0.8285306173146193	0.8060059260245697	0.8097386227942152	0.7956421707944241	0.8058204046377196	0.8044053158370434	0.7929494391599332	0.811345079501504	0.8148895981241451	0.8129322611601972	0.8170531432700519	0.8085938795132788	0.8040425602881826	0.8012605469147097	0.8037677661571467	0.792946142847416	0.8102990795033904	0.8102635597158601	0.7956351236146633	0.8015194681861348	0.8011380957219795	0.8057722570060603	0.806128264440645	0.8179137727689687	0.8213485304475892	0.7912920671006854	0.7951634877384196	0.8069318523970426	0.8127000891118519	0.7863734128911399	0.8072841696515248	0.8095668777007335
valid_loss
tensor(0.4150, device='cuda:0')	tensor(0.4177, device='cuda:0')	tensor(0.3847, device='cuda:0')	tensor(0.3876, device='cuda:0')	tensor(0.4026, device='cuda:0')	tensor(0.4175, device='cuda:0')	tensor(0.3882, device='cuda:0')	tensor(0.4092, device='cuda:0')
Experiment end
########################################
----------------------------------------
Starting experiment alexnet_9
Experiment parameters Experiment[name: alexnet_9, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 1e-05, weight_decay: 0, batch_size: 32, num_epochs: 8), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.4736328125, 0.10835401157981803
train metrics acc, f1
0.4830207824707031, 0.14623113995023151
Epoch 1/8
----------
eval metrics, batch: 1024 acc, f1
0.780426025390625, 0.7884632346455767
eval metrics, batch: 2048 acc, f1
0.769561767578125, 0.7458859162039374
eval metrics, batch: 3072 acc, f1
0.777587890625, 0.7534506089309878
eval metrics, batch: 4096 acc, f1
0.77960205078125, 0.7657780372316274
train metrics, batch: 4096  acc, f1 
0.8405570983886719, 0.8403091653071595
eval metrics, batch: 5120 acc, f1
0.78350830078125, 0.7617224237538627
eval metrics, batch: 6144 acc, f1
0.79827880859375, 0.7930494677520351
eval metrics, batch: 7168 acc, f1
0.79583740234375, 0.7826228229789446
Epoch loss - train: tensor(0.3747, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4563, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.78521728515625, 0.7676153998547184
train metrics acc, f1 
0.8581581115722656, 0.8568348343029636
Epoch 2/8
----------
eval metrics, batch: 1024 acc, f1
0.7972412109375, 0.7922971114167813
eval metrics, batch: 2048 acc, f1
0.795684814453125, 0.7805565570815169
eval metrics, batch: 3072 acc, f1
0.795318603515625, 0.7928083778690803
eval metrics, batch: 4096 acc, f1
0.796661376953125, 0.7842642059252064
train metrics, batch: 4096  acc, f1 
0.8706817626953125, 0.8715490652257932
eval metrics, batch: 5120 acc, f1
0.78753662109375, 0.7624863537117904
eval metrics, batch: 6144 acc, f1
0.797576904296875, 0.7869463270484695
eval metrics, batch: 7168 acc, f1
0.786865234375, 0.7678963110667996
Epoch loss - train: tensor(0.3183, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4402, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.79364013671875, 0.7771993410214169
train metrics acc, f1 
0.8809318542480469, 0.8809477494383608
Epoch 3/8
----------
eval metrics, batch: 1024 acc, f1
0.798248291015625, 0.7991859299535251
eval metrics, batch: 2048 acc, f1
0.794921875, 0.7803778024707497
eval metrics, batch: 3072 acc, f1
0.79754638671875, 0.7872217589325806
eval metrics, batch: 4096 acc, f1
0.78155517578125, 0.756348287834434
train metrics, batch: 4096  acc, f1 
0.8863143920898438, 0.8846261052696781
eval metrics, batch: 5120 acc, f1
0.778717041015625, 0.751618538690782
eval metrics, batch: 6144 acc, f1
0.786590576171875, 0.762199476315163
eval metrics, batch: 7168 acc, f1
0.80072021484375, 0.7867128298928665
Epoch loss - train: tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4426, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.798431396484375, 0.7835774435597497
train metrics acc, f1 
0.8921051025390625, 0.8929106907570916
Epoch 4/8
----------
eval metrics, batch: 1024 acc, f1
0.79302978515625, 0.7889331507531433
eval metrics, batch: 2048 acc, f1
0.8040771484375, 0.7962680883472962
eval metrics, batch: 3072 acc, f1
0.7779541015625, 0.7461624337147642
eval metrics, batch: 4096 acc, f1
0.797332763671875, 0.782426367001933
train metrics, batch: 4096  acc, f1 
0.8968620300292969, 0.897870684803179
eval metrics, batch: 5120 acc, f1
0.787322998046875, 0.7715756006424334
eval metrics, batch: 6144 acc, f1
0.78900146484375, 0.7609101597620859
eval metrics, batch: 7168 acc, f1
0.79718017578125, 0.7868778860954335
Epoch loss - train: tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4575, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.797210693359375, 0.7827650462584589
train metrics acc, f1 
0.904296875, 0.9056537075896719
Epoch 5/8
----------
eval metrics, batch: 1024 acc, f1
0.793975830078125, 0.7955543442052028
eval metrics, batch: 2048 acc, f1
0.780029296875, 0.7550132553871253
eval metrics, batch: 3072 acc, f1
0.790191650390625, 0.7668622198107768
eval metrics, batch: 4096 acc, f1
0.783905029296875, 0.7678893368735045
train metrics, batch: 4096  acc, f1 
0.9043731689453125, 0.9062654242510357
eval metrics, batch: 5120 acc, f1
0.782928466796875, 0.7583653225532493
eval metrics, batch: 6144 acc, f1
0.78009033203125, 0.7462318636427666
eval metrics, batch: 7168 acc, f1
0.79290771484375, 0.7728763638797778
Epoch loss - train: tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4713, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.797515869140625, 0.7779228168825518
train metrics acc, f1 
0.9094276428222656, 0.9092215990120398
Epoch 6/8
----------
eval metrics, batch: 1024 acc, f1
0.795318603515625, 0.7916627838349952
eval metrics, batch: 2048 acc, f1
0.7957763671875, 0.7816639477977162
eval metrics, batch: 3072 acc, f1
0.785003662109375, 0.7571443345168741
eval metrics, batch: 4096 acc, f1
0.791046142578125, 0.7717590586352878
train metrics, batch: 4096  acc, f1 
0.9157829284667969, 0.9163011294058772
eval metrics, batch: 5120 acc, f1
0.79522705078125, 0.7749530453447814
eval metrics, batch: 6144 acc, f1
0.78021240234375, 0.7563599458728011
eval metrics, batch: 7168 acc, f1
0.803680419921875, 0.7923029735576147
Epoch loss - train: tensor(0.2318, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5444, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.771087646484375, 0.7404049143450424
train metrics acc, f1 
0.9198532104492188, 0.9193275891197837
Epoch 7/8
----------
eval metrics, batch: 1024 acc, f1
0.799468994140625, 0.7988613058250942
eval metrics, batch: 2048 acc, f1
0.78717041015625, 0.7668650130373738
eval metrics, batch: 3072 acc, f1
0.769805908203125, 0.7308090360800827
eval metrics, batch: 4096 acc, f1
0.783935546875, 0.7616322133189685
train metrics, batch: 4096  acc, f1 
0.9244842529296875, 0.9250435441120788
eval metrics, batch: 5120 acc, f1
0.788543701171875, 0.7631192095996718
eval metrics, batch: 6144 acc, f1
0.781158447265625, 0.7552810292461523
eval metrics, batch: 7168 acc, f1
0.7955322265625, 0.7807591623036649
Epoch loss - train: tensor(0.2165, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5557, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.77691650390625, 0.7478440841669541
train metrics acc, f1 
0.9279441833496094, 0.9273284780492684
Epoch 8/8
----------
eval metrics, batch: 1024 acc, f1
0.791778564453125, 0.7776582917847948
eval metrics, batch: 2048 acc, f1
0.775970458984375, 0.742628755740981
eval metrics, batch: 3072 acc, f1
0.780517578125, 0.7494076655052265
eval metrics, batch: 4096 acc, f1
0.79083251953125, 0.7714114194236926
train metrics, batch: 4096  acc, f1 
0.9302597045898438, 0.9307919442761963
eval metrics, batch: 5120 acc, f1
0.77984619140625, 0.7491655076495132
eval metrics, batch: 6144 acc, f1
0.779052734375, 0.7532883527567641
eval metrics, batch: 7168 acc, f1
0.783599853515625, 0.7568327560783238
Epoch loss - train: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5457, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.786590576171875, 0.7664250642974048
train metrics acc, f1 
0.9319877624511719, 0.9326350868840753
Training time 84m 60s
train_acc
0.4830207824707031	0.8405570983886719	0.8581581115722656	0.8706817626953125	0.8809318542480469	0.8863143920898438	0.8921051025390625	0.8968620300292969	0.904296875	0.9043731689453125	0.9094276428222656	0.9157829284667969	0.9198532104492188	0.9244842529296875	0.9279441833496094	0.9302597045898438	0.9319877624511719
train_f1
0.14623113995023151	0.8403091653071595	0.8568348343029636	0.8715490652257932	0.8809477494383608	0.8846261052696781	0.8929106907570916	0.897870684803179	0.9056537075896719	0.9062654242510357	0.9092215990120398	0.9163011294058772	0.9193275891197837	0.9250435441120788	0.9273284780492684	0.9307919442761963	0.9326350868840753
train_loss
tensor(0.3747, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3183, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2318, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2165, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.4736328125	0.780426025390625	0.769561767578125	0.777587890625	0.77960205078125	0.78350830078125	0.79827880859375	0.79583740234375	0.78521728515625	0.7972412109375	0.795684814453125	0.795318603515625	0.796661376953125	0.78753662109375	0.797576904296875	0.786865234375	0.79364013671875	0.798248291015625	0.794921875	0.79754638671875	0.78155517578125	0.778717041015625	0.786590576171875	0.80072021484375	0.798431396484375	0.79302978515625	0.8040771484375	0.7779541015625	0.797332763671875	0.787322998046875	0.78900146484375	0.79718017578125	0.797210693359375	0.793975830078125	0.780029296875	0.790191650390625	0.783905029296875	0.782928466796875	0.78009033203125	0.79290771484375	0.797515869140625	0.795318603515625	0.7957763671875	0.785003662109375	0.791046142578125	0.79522705078125	0.78021240234375	0.803680419921875	0.771087646484375	0.799468994140625	0.78717041015625	0.769805908203125	0.783935546875	0.788543701171875	0.781158447265625	0.7955322265625	0.77691650390625	0.791778564453125	0.775970458984375	0.780517578125	0.79083251953125	0.77984619140625	0.779052734375	0.783599853515625	0.786590576171875
valid_f1
0.10835401157981803	0.7884632346455767	0.7458859162039374	0.7534506089309878	0.7657780372316274	0.7617224237538627	0.7930494677520351	0.7826228229789446	0.7676153998547184	0.7922971114167813	0.7805565570815169	0.7928083778690803	0.7842642059252064	0.7624863537117904	0.7869463270484695	0.7678963110667996	0.7771993410214169	0.7991859299535251	0.7803778024707497	0.7872217589325806	0.756348287834434	0.751618538690782	0.762199476315163	0.7867128298928665	0.7835774435597497	0.7889331507531433	0.7962680883472962	0.7461624337147642	0.782426367001933	0.7715756006424334	0.7609101597620859	0.7868778860954335	0.7827650462584589	0.7955543442052028	0.7550132553871253	0.7668622198107768	0.7678893368735045	0.7583653225532493	0.7462318636427666	0.7728763638797778	0.7779228168825518	0.7916627838349952	0.7816639477977162	0.7571443345168741	0.7717590586352878	0.7749530453447814	0.7563599458728011	0.7923029735576147	0.7404049143450424	0.7988613058250942	0.7668650130373738	0.7308090360800827	0.7616322133189685	0.7631192095996718	0.7552810292461523	0.7807591623036649	0.7478440841669541	0.7776582917847948	0.742628755740981	0.7494076655052265	0.7714114194236926	0.7491655076495132	0.7532883527567641	0.7568327560783238	0.7664250642974048
valid_loss
tensor(0.4563, device='cuda:0')	tensor(0.4402, device='cuda:0')	tensor(0.4426, device='cuda:0')	tensor(0.4575, device='cuda:0')	tensor(0.4713, device='cuda:0')	tensor(0.5444, device='cuda:0')	tensor(0.5557, device='cuda:0')	tensor(0.5457, device='cuda:0')
Experiment end
########################################
----------------------------------------
Starting experiment alexnet_10
Experiment parameters Experiment[name: alexnet_10, model: AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace)
    (6): Linear(in_features=4096, out_features=1, bias=True)
  )
), params: Params(lr: 1e-06, weight_decay: 0, batch_size: 32, num_epochs: 8), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-06
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.66485595703125, 0.6916381198405122
train metrics acc, f1
0.6578750610351562, 0.689145067483727
Epoch 1/8
----------
eval metrics, batch: 1024 acc, f1
0.771759033203125, 0.7784722016527946
eval metrics, batch: 2048 acc, f1
0.777191162109375, 0.7744028674721132
eval metrics, batch: 3072 acc, f1
0.781219482421875, 0.777367162510481
eval metrics, batch: 4096 acc, f1
0.781341552734375, 0.7730943408176838
train metrics, batch: 4096  acc, f1 
0.8055343627929688, 0.805558098376663
eval metrics, batch: 5120 acc, f1
0.7808837890625, 0.7733871985860371
eval metrics, batch: 6144 acc, f1
0.781585693359375, 0.7754525774166222
eval metrics, batch: 7168 acc, f1
0.783203125, 0.7729771187523968
Epoch loss - train: tensor(0.4409, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4451, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7818603515625, 0.7717169136433316
train metrics acc, f1 
0.8211212158203125, 0.8209901050574151
Epoch 2/8
----------
eval metrics, batch: 1024 acc, f1
0.78369140625, 0.786570310147546
eval metrics, batch: 2048 acc, f1
0.782958984375, 0.7735752944922
eval metrics, batch: 3072 acc, f1
0.77764892578125, 0.7581972653657242
eval metrics, batch: 4096 acc, f1
0.7799072265625, 0.7667227325656618
train metrics, batch: 4096  acc, f1 
0.8280792236328125, 0.8270168193018953
eval metrics, batch: 5120 acc, f1
0.783294677734375, 0.7709871964395136
eval metrics, batch: 6144 acc, f1
0.783355712890625, 0.7729700342191947
eval metrics, batch: 7168 acc, f1
0.783172607421875, 0.7767057418523524
Epoch loss - train: tensor(0.3870, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4436, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.78265380859375, 0.7727939769029541
train metrics acc, f1 
0.8340263366699219, 0.8351800711420226
Epoch 3/8
----------
eval metrics, batch: 1024 acc, f1
0.78515625, 0.7922323220399008
eval metrics, batch: 2048 acc, f1
0.78070068359375, 0.7709422414892261
eval metrics, batch: 3072 acc, f1
0.783721923828125, 0.7688443850092957
eval metrics, batch: 4096 acc, f1
0.781005859375, 0.7668767461503476
train metrics, batch: 4096  acc, f1 
0.8379669189453125, 0.8368328454759875
eval metrics, batch: 5120 acc, f1
0.7867431640625, 0.7773955147808359
eval metrics, batch: 6144 acc, f1
0.78582763671875, 0.7749486916367367
eval metrics, batch: 7168 acc, f1
0.787933349609375, 0.7831486971446403
Epoch loss - train: tensor(0.3688, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4324, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.787506103515625, 0.7757704569606801
train metrics acc, f1 
0.8420448303222656, 0.8416188862411499
Epoch 4/8
----------
eval metrics, batch: 1024 acc, f1
0.787384033203125, 0.7948166691208953
eval metrics, batch: 2048 acc, f1
0.783905029296875, 0.7692357829558416
eval metrics, batch: 3072 acc, f1
0.784332275390625, 0.7673109216028449
eval metrics, batch: 4096 acc, f1
0.7867431640625, 0.7765413149143003
train metrics, batch: 4096  acc, f1 
0.8455238342285156, 0.8467207437043655
eval metrics, batch: 5120 acc, f1
0.78863525390625, 0.7736157416486893
eval metrics, batch: 6144 acc, f1
0.786834716796875, 0.7727494550541693
eval metrics, batch: 7168 acc, f1
0.7891845703125, 0.7709549071618037
Epoch loss - train: tensor(0.3566, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4348, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.787841796875, 0.7759009735026755
train metrics acc, f1 
0.8484382629394531, 0.8486409264938379
Epoch 5/8
----------
eval metrics, batch: 1024 acc, f1
0.791900634765625, 0.7937573722892659
eval metrics, batch: 2048 acc, f1
0.7908935546875, 0.7876534027519524
eval metrics, batch: 3072 acc, f1
0.79046630859375, 0.782004064008128
eval metrics, batch: 4096 acc, f1
0.789337158203125, 0.7783735191190163
train metrics, batch: 4096  acc, f1 
0.8509979248046875, 0.8517905792537166
eval metrics, batch: 5120 acc, f1
0.792205810546875, 0.7852389213057878
eval metrics, batch: 6144 acc, f1
0.78985595703125, 0.7760504748276311
eval metrics, batch: 7168 acc, f1
0.788665771484375, 0.7745548067845167
Epoch loss - train: tensor(0.3470, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4315, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.791595458984375, 0.7817025221366237
train metrics acc, f1 
0.8528709411621094, 0.8540219748610013
Epoch 6/8
----------
eval metrics, batch: 1024 acc, f1
0.78875732421875, 0.7959316037735849
eval metrics, batch: 2048 acc, f1
0.791046142578125, 0.7797471611927815
eval metrics, batch: 3072 acc, f1
0.790283203125, 0.7769265727455691
eval metrics, batch: 4096 acc, f1
0.789520263671875, 0.7788785226507646
train metrics, batch: 4096  acc, f1 
0.8545188903808594, 0.8557683943800465
eval metrics, batch: 5120 acc, f1
0.79132080078125, 0.7805519897304236
eval metrics, batch: 6144 acc, f1
0.79803466796875, 0.7904237127113813
eval metrics, batch: 7168 acc, f1
0.792144775390625, 0.7809052015311867
Epoch loss - train: tensor(0.3396, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4256, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7957763671875, 0.7838501291989665
train metrics acc, f1 
0.857086181640625, 0.857116704805492
Epoch 7/8
----------
eval metrics, batch: 1024 acc, f1
0.794677734375, 0.8004034650528065
eval metrics, batch: 2048 acc, f1
0.792022705078125, 0.7737008135480657
eval metrics, batch: 3072 acc, f1
0.794769287109375, 0.7901257684985801
eval metrics, batch: 4096 acc, f1
0.794586181640625, 0.7818223072185667
train metrics, batch: 4096  acc, f1 
0.8591995239257812, 0.8589088851852418
eval metrics, batch: 5120 acc, f1
0.79541015625, 0.7839927825750741
eval metrics, batch: 6144 acc, f1
0.7939453125, 0.7807792207792208
eval metrics, batch: 7168 acc, f1
0.80023193359375, 0.7942415288866537
Epoch loss - train: tensor(0.3320, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4321, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.79364013671875, 0.7799257957430189
train metrics acc, f1 
0.8617897033691406, 0.8612184704958535
Epoch 8/8
----------
eval metrics, batch: 1024 acc, f1
0.79290771484375, 0.7983837423495157
eval metrics, batch: 2048 acc, f1
0.796051025390625, 0.7817653397772916
eval metrics, batch: 3072 acc, f1
0.797393798828125, 0.7894853663950281
eval metrics, batch: 4096 acc, f1
0.7933349609375, 0.7809123261080556
train metrics, batch: 4096  acc, f1 
0.8627281188964844, 0.8631754251884974
eval metrics, batch: 5120 acc, f1
0.796112060546875, 0.7848932676518884
eval metrics, batch: 6144 acc, f1
0.792144775390625, 0.7754442649434572
eval metrics, batch: 7168 acc, f1
0.796905517578125, 0.7838934892027927
Epoch loss - train: tensor(0.3263, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4304, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.794464111328125, 0.7824401589301289
train metrics acc, f1 
0.8649787902832031, 0.8657138846417962
Training time 85m 47s
train_acc
0.6578750610351562	0.8055343627929688	0.8211212158203125	0.8280792236328125	0.8340263366699219	0.8379669189453125	0.8420448303222656	0.8455238342285156	0.8484382629394531	0.8509979248046875	0.8528709411621094	0.8545188903808594	0.857086181640625	0.8591995239257812	0.8617897033691406	0.8627281188964844	0.8649787902832031
train_f1
0.689145067483727	0.805558098376663	0.8209901050574151	0.8270168193018953	0.8351800711420226	0.8368328454759875	0.8416188862411499	0.8467207437043655	0.8486409264938379	0.8517905792537166	0.8540219748610013	0.8557683943800465	0.857116704805492	0.8589088851852418	0.8612184704958535	0.8631754251884974	0.8657138846417962
train_loss
tensor(0.4409, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3870, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3688, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3566, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3470, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3396, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3320, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.3263, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.66485595703125	0.771759033203125	0.777191162109375	0.781219482421875	0.781341552734375	0.7808837890625	0.781585693359375	0.783203125	0.7818603515625	0.78369140625	0.782958984375	0.77764892578125	0.7799072265625	0.783294677734375	0.783355712890625	0.783172607421875	0.78265380859375	0.78515625	0.78070068359375	0.783721923828125	0.781005859375	0.7867431640625	0.78582763671875	0.787933349609375	0.787506103515625	0.787384033203125	0.783905029296875	0.784332275390625	0.7867431640625	0.78863525390625	0.786834716796875	0.7891845703125	0.787841796875	0.791900634765625	0.7908935546875	0.79046630859375	0.789337158203125	0.792205810546875	0.78985595703125	0.788665771484375	0.791595458984375	0.78875732421875	0.791046142578125	0.790283203125	0.789520263671875	0.79132080078125	0.79803466796875	0.792144775390625	0.7957763671875	0.794677734375	0.792022705078125	0.794769287109375	0.794586181640625	0.79541015625	0.7939453125	0.80023193359375	0.79364013671875	0.79290771484375	0.796051025390625	0.797393798828125	0.7933349609375	0.796112060546875	0.792144775390625	0.796905517578125	0.794464111328125
valid_f1
0.6916381198405122	0.7784722016527946	0.7744028674721132	0.777367162510481	0.7730943408176838	0.7733871985860371	0.7754525774166222	0.7729771187523968	0.7717169136433316	0.786570310147546	0.7735752944922	0.7581972653657242	0.7667227325656618	0.7709871964395136	0.7729700342191947	0.7767057418523524	0.7727939769029541	0.7922323220399008	0.7709422414892261	0.7688443850092957	0.7668767461503476	0.7773955147808359	0.7749486916367367	0.7831486971446403	0.7757704569606801	0.7948166691208953	0.7692357829558416	0.7673109216028449	0.7765413149143003	0.7736157416486893	0.7727494550541693	0.7709549071618037	0.7759009735026755	0.7937573722892659	0.7876534027519524	0.782004064008128	0.7783735191190163	0.7852389213057878	0.7760504748276311	0.7745548067845167	0.7817025221366237	0.7959316037735849	0.7797471611927815	0.7769265727455691	0.7788785226507646	0.7805519897304236	0.7904237127113813	0.7809052015311867	0.7838501291989665	0.8004034650528065	0.7737008135480657	0.7901257684985801	0.7818223072185667	0.7839927825750741	0.7807792207792208	0.7942415288866537	0.7799257957430189	0.7983837423495157	0.7817653397772916	0.7894853663950281	0.7809123261080556	0.7848932676518884	0.7754442649434572	0.7838934892027927	0.7824401589301289
valid_loss
tensor(0.4451, device='cuda:0')	tensor(0.4436, device='cuda:0')	tensor(0.4324, device='cuda:0')	tensor(0.4348, device='cuda:0')	tensor(0.4315, device='cuda:0')	tensor(0.4256, device='cuda:0')	tensor(0.4321, device='cuda:0')	tensor(0.4304, device='cuda:0')
Experiment end
########################################
----------------------------------------
Starting experiment resnet_7
Experiment parameters Experiment[name: resnet_7, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 1e-05, weight_decay: 0, batch_size: 32, num_epochs: 8), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.4417724609375, 0.47626410124262725
train metrics acc, f1
0.423858642578125, 0.44286726081567607
Epoch 1/8
----------
eval metrics, batch: 1024 acc, f1
0.83660888671875, 0.8222679591023768
eval metrics, batch: 2048 acc, f1
0.812103271484375, 0.7805382284797718
eval metrics, batch: 3072 acc, f1
0.87078857421875, 0.8669975497895333
eval metrics, batch: 4096 acc, f1
0.83538818359375, 0.8122389306599833
train metrics, batch: 4096  acc, f1 
0.9334564208984375, 0.9311759739286193
eval metrics, batch: 5120 acc, f1
0.8455810546875, 0.8241223496697949
eval metrics, batch: 6144 acc, f1
0.850677490234375, 0.8356564672690021
eval metrics, batch: 7168 acc, f1
0.841064453125, 0.8175448430493274
Epoch loss - train: tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3000, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.879974365234375, 0.8767432385847254
train metrics acc, f1 
0.9438934326171875, 0.9453851409559457
Epoch 2/8
----------
eval metrics, batch: 1024 acc, f1
0.851409912109375, 0.8344947143002821
eval metrics, batch: 2048 acc, f1
0.846160888671875, 0.8293327013576193
eval metrics, batch: 3072 acc, f1
0.844818115234375, 0.8231734881941788
eval metrics, batch: 4096 acc, f1
0.865234375, 0.853948935044318
train metrics, batch: 4096  acc, f1 
0.9617691040039062, 0.9619372431656424
eval metrics, batch: 5120 acc, f1
0.87957763671875, 0.8730618284758412
eval metrics, batch: 6144 acc, f1
0.839141845703125, 0.8145385454417509
eval metrics, batch: 7168 acc, f1
0.83245849609375, 0.8046124279308136
Epoch loss - train: tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3839, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.852813720703125, 0.8350039341794671
train metrics acc, f1 
0.9732742309570312, 0.973129909180167
Epoch 3/8
----------
eval metrics, batch: 1024 acc, f1
0.861175537109375, 0.8486139305800526
eval metrics, batch: 2048 acc, f1
0.87255859375, 0.8631985848129463
eval metrics, batch: 3072 acc, f1
0.855377197265625, 0.837354566358925
eval metrics, batch: 4096 acc, f1
0.815338134765625, 0.7805780179134786
train metrics, batch: 4096  acc, f1 
0.9698829650878906, 0.9692850556915045
eval metrics, batch: 5120 acc, f1
0.8353271484375, 0.8086931858469829
eval metrics, batch: 6144 acc, f1
0.83551025390625, 0.8094867807153966
eval metrics, batch: 7168 acc, f1
0.824371337890625, 0.7931567408259353
Epoch loss - train: tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4443, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.84759521484375, 0.8288905639690263
train metrics acc, f1 
0.9803314208984375, 0.9803060281276976
Epoch 4/8
----------
eval metrics, batch: 1024 acc, f1
0.84881591796875, 0.8286524626452684
eval metrics, batch: 2048 acc, f1
0.86517333984375, 0.8530272787757818
eval metrics, batch: 3072 acc, f1
0.872406005859375, 0.861128641179792
eval metrics, batch: 4096 acc, f1
0.84686279296875, 0.8257880849881961
train metrics, batch: 4096  acc, f1 
0.9859428405761719, 0.9858760851650984
eval metrics, batch: 5120 acc, f1
0.866973876953125, 0.8526817398357498
eval metrics, batch: 6144 acc, f1
0.837188720703125, 0.8128135854882285
eval metrics, batch: 7168 acc, f1
0.849609375, 0.8314752752889679
Epoch loss - train: tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4646, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.866455078125, 0.8547241219042561
train metrics acc, f1 
0.9875907897949219, 0.9876511340988896
Epoch 5/8
----------
eval metrics, batch: 1024 acc, f1
0.842926025390625, 0.8209925920773484
eval metrics, batch: 2048 acc, f1
0.810028076171875, 0.771500936020262
eval metrics, batch: 3072 acc, f1
0.825592041015625, 0.7951392622862673
eval metrics, batch: 4096 acc, f1
0.8743896484375, 0.8654286274766233
train metrics, batch: 4096  acc, f1 
0.9866256713867188, 0.9867207029770472
eval metrics, batch: 5120 acc, f1
0.835235595703125, 0.8106344919504752
eval metrics, batch: 6144 acc, f1
0.841461181640625, 0.8187305907393838
eval metrics, batch: 7168 acc, f1
0.85382080078125, 0.8387205387205388
Epoch loss - train: tensor(0.0455, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5877, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.847320556640625, 0.8281169478132409
train metrics acc, f1 
0.9944877624511719, 0.9944840380658633
Epoch 6/8
----------
eval metrics, batch: 1024 acc, f1
0.854949951171875, 0.8383937982387543
eval metrics, batch: 2048 acc, f1
0.851318359375, 0.8349817097954206
eval metrics, batch: 3072 acc, f1
0.824615478515625, 0.7940660049449959
eval metrics, batch: 4096 acc, f1
0.87353515625, 0.8653496230829217
train metrics, batch: 4096  acc, f1 
0.9896354675292969, 0.9897093078306979
eval metrics, batch: 5120 acc, f1
0.85162353515625, 0.833618506604613
eval metrics, batch: 6144 acc, f1
0.8079833984375, 0.7676170778549268
eval metrics, batch: 7168 acc, f1
0.851715087890625, 0.8313491374822116
Epoch loss - train: tensor(0.0323, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6155, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.860565185546875, 0.8452497883149873
train metrics acc, f1 
0.9931488037109375, 0.9931471306471307
Epoch 7/8
----------
eval metrics, batch: 1024 acc, f1
0.8497314453125, 0.8311385459533608
eval metrics, batch: 2048 acc, f1
0.84100341796875, 0.8172955533735446
eval metrics, batch: 3072 acc, f1
0.827728271484375, 0.800198209039748
eval metrics, batch: 4096 acc, f1
0.843963623046875, 0.8215918210684253
train metrics, batch: 4096  acc, f1 
0.9964752197265625, 0.9964674037711612
eval metrics, batch: 5120 acc, f1
0.863861083984375, 0.8508176437146775
eval metrics, batch: 6144 acc, f1
0.84954833984375, 0.8307702869696554
eval metrics, batch: 7168 acc, f1
0.80841064453125, 0.7673953316042978
Epoch loss - train: tensor(0.0260, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8048, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.81439208984375, 0.7801792684689894
train metrics acc, f1 
0.9890060424804688, 0.9889170044378129
Epoch 8/8
----------
eval metrics, batch: 1024 acc, f1
0.8427734375, 0.8198979235125499
eval metrics, batch: 2048 acc, f1
0.866302490234375, 0.8544760006643415
eval metrics, batch: 3072 acc, f1
0.860565185546875, 0.8461046178719391
eval metrics, batch: 4096 acc, f1
0.832550048828125, 0.8056804901370542
train metrics, batch: 4096  acc, f1 
0.9982261657714844, 0.9982244250382799
eval metrics, batch: 5120 acc, f1
0.81927490234375, 0.7855124954726548
eval metrics, batch: 6144 acc, f1
0.865509033203125, 0.8528203586814949
eval metrics, batch: 7168 acc, f1
0.840240478515625, 0.8170284156443326
Epoch loss - train: tensor(0.0209, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.8755, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.85614013671875, 0.8411832086786605
train metrics acc, f1 
0.9962501525878906, 0.9962551382322576
Training time 112m 11s
train_acc
0.423858642578125	0.9334564208984375	0.9438934326171875	0.9617691040039062	0.9732742309570312	0.9698829650878906	0.9803314208984375	0.9859428405761719	0.9875907897949219	0.9866256713867188	0.9944877624511719	0.9896354675292969	0.9931488037109375	0.9964752197265625	0.9890060424804688	0.9982261657714844	0.9962501525878906
train_f1
0.44286726081567607	0.9311759739286193	0.9453851409559457	0.9619372431656424	0.973129909180167	0.9692850556915045	0.9803060281276976	0.9858760851650984	0.9876511340988896	0.9867207029770472	0.9944840380658633	0.9897093078306979	0.9931471306471307	0.9964674037711612	0.9889170044378129	0.9982244250382799	0.9962551382322576
train_loss
tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1305, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0455, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0323, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0260, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.0209, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.4417724609375	0.83660888671875	0.812103271484375	0.87078857421875	0.83538818359375	0.8455810546875	0.850677490234375	0.841064453125	0.879974365234375	0.851409912109375	0.846160888671875	0.844818115234375	0.865234375	0.87957763671875	0.839141845703125	0.83245849609375	0.852813720703125	0.861175537109375	0.87255859375	0.855377197265625	0.815338134765625	0.8353271484375	0.83551025390625	0.824371337890625	0.84759521484375	0.84881591796875	0.86517333984375	0.872406005859375	0.84686279296875	0.866973876953125	0.837188720703125	0.849609375	0.866455078125	0.842926025390625	0.810028076171875	0.825592041015625	0.8743896484375	0.835235595703125	0.841461181640625	0.85382080078125	0.847320556640625	0.854949951171875	0.851318359375	0.824615478515625	0.87353515625	0.85162353515625	0.8079833984375	0.851715087890625	0.860565185546875	0.8497314453125	0.84100341796875	0.827728271484375	0.843963623046875	0.863861083984375	0.84954833984375	0.80841064453125	0.81439208984375	0.8427734375	0.866302490234375	0.860565185546875	0.832550048828125	0.81927490234375	0.865509033203125	0.840240478515625	0.85614013671875
valid_f1
0.47626410124262725	0.8222679591023768	0.7805382284797718	0.8669975497895333	0.8122389306599833	0.8241223496697949	0.8356564672690021	0.8175448430493274	0.8767432385847254	0.8344947143002821	0.8293327013576193	0.8231734881941788	0.853948935044318	0.8730618284758412	0.8145385454417509	0.8046124279308136	0.8350039341794671	0.8486139305800526	0.8631985848129463	0.837354566358925	0.7805780179134786	0.8086931858469829	0.8094867807153966	0.7931567408259353	0.8288905639690263	0.8286524626452684	0.8530272787757818	0.861128641179792	0.8257880849881961	0.8526817398357498	0.8128135854882285	0.8314752752889679	0.8547241219042561	0.8209925920773484	0.771500936020262	0.7951392622862673	0.8654286274766233	0.8106344919504752	0.8187305907393838	0.8387205387205388	0.8281169478132409	0.8383937982387543	0.8349817097954206	0.7940660049449959	0.8653496230829217	0.833618506604613	0.7676170778549268	0.8313491374822116	0.8452497883149873	0.8311385459533608	0.8172955533735446	0.800198209039748	0.8215918210684253	0.8508176437146775	0.8307702869696554	0.7673953316042978	0.7801792684689894	0.8198979235125499	0.8544760006643415	0.8461046178719391	0.8056804901370542	0.7855124954726548	0.8528203586814949	0.8170284156443326	0.8411832086786605
valid_loss
tensor(0.3000, device='cuda:0')	tensor(0.3839, device='cuda:0')	tensor(0.4443, device='cuda:0')	tensor(0.4646, device='cuda:0')	tensor(0.5877, device='cuda:0')	tensor(0.6155, device='cuda:0')	tensor(0.8048, device='cuda:0')	tensor(0.8755, device='cuda:0')
Experiment end
########################################
----------------------------------------
Starting experiment resnet_8
Experiment parameters Experiment[name: resnet_8, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 1e-06, weight_decay: 0, batch_size: 32, num_epochs: 8), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-06
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.4749755859375, 0.07674144037780402
train metrics acc, f1
0.4691581726074219, 0.06756856359847495
Epoch 1/8
----------
eval metrics, batch: 1024 acc, f1
0.7744140625, 0.7491005362840268
eval metrics, batch: 2048 acc, f1
0.823638916015625, 0.8112733091669116
eval metrics, batch: 3072 acc, f1
0.829254150390625, 0.8150107455777814
eval metrics, batch: 4096 acc, f1
0.832977294921875, 0.8192834736668317
train metrics, batch: 4096  acc, f1 
0.8846397399902344, 0.8820705603412977
eval metrics, batch: 5120 acc, f1
0.83636474609375, 0.8224503311258278
eval metrics, batch: 6144 acc, f1
0.838836669921875, 0.8247552679608429
eval metrics, batch: 7168 acc, f1
0.837921142578125, 0.8230433478825843
Epoch loss - train: tensor(0.3264, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3687, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.840911865234375, 0.8264358248709839
train metrics acc, f1 
0.908935546875, 0.9073701855545294
Epoch 2/8
----------
eval metrics, batch: 1024 acc, f1
0.80938720703125, 0.7808728599494807
eval metrics, batch: 2048 acc, f1
0.843017578125, 0.8325956782087998
eval metrics, batch: 3072 acc, f1
0.84124755859375, 0.8277711561382598
eval metrics, batch: 4096 acc, f1
0.83782958984375, 0.8219884764839877
train metrics, batch: 4096  acc, f1 
0.9135856628417969, 0.912091707445797
eval metrics, batch: 5120 acc, f1
0.83831787109375, 0.8206135301686193
eval metrics, batch: 6144 acc, f1
0.843902587890625, 0.8316271108331413
eval metrics, batch: 7168 acc, f1
0.840301513671875, 0.8236919241265456
Epoch loss - train: tensor(0.2461, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3546, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.848663330078125, 0.8360606962213627
train metrics acc, f1 
0.92510986328125, 0.924665576865517
Epoch 3/8
----------
eval metrics, batch: 1024 acc, f1
0.82379150390625, 0.7995973899763987
eval metrics, batch: 2048 acc, f1
0.839019775390625, 0.8219649667555435
eval metrics, batch: 3072 acc, f1
0.84130859375, 0.8260753227640645
eval metrics, batch: 4096 acc, f1
0.8436279296875, 0.8289833789466657
train metrics, batch: 4096  acc, f1 
0.9275550842285156, 0.9268814803121715
eval metrics, batch: 5120 acc, f1
0.844085693359375, 0.8287926007841561
eval metrics, batch: 6144 acc, f1
0.837738037109375, 0.818785999113868
eval metrics, batch: 7168 acc, f1
0.84405517578125, 0.827388190785029
Epoch loss - train: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3523, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.855743408203125, 0.8447975834783465
train metrics acc, f1 
0.9338111877441406, 0.9338119452063155
Epoch 4/8
----------
eval metrics, batch: 1024 acc, f1
0.829498291015625, 0.8067383859697672
eval metrics, batch: 2048 acc, f1
0.85101318359375, 0.8396294592996518
eval metrics, batch: 3072 acc, f1
0.844635009765625, 0.829452949649928
eval metrics, batch: 4096 acc, f1
0.852935791015625, 0.8411301223090364
train metrics, batch: 4096  acc, f1 
0.936737060546875, 0.9366626437922975
eval metrics, batch: 5120 acc, f1
0.846527099609375, 0.8304507602575772
eval metrics, batch: 6144 acc, f1
0.844970703125, 0.8279249373348689
eval metrics, batch: 7168 acc, f1
0.85382080078125, 0.8414642218838949
Epoch loss - train: tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3676, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.85107421875, 0.8371052807263503
train metrics acc, f1 
0.9428520202636719, 0.9425841538243377
Epoch 5/8
----------
eval metrics, batch: 1024 acc, f1
0.847503662109375, 0.8347170310587768
eval metrics, batch: 2048 acc, f1
0.8397216796875, 0.8205916512946642
eval metrics, batch: 3072 acc, f1
0.85211181640625, 0.839928651648279
eval metrics, batch: 4096 acc, f1
0.85015869140625, 0.8368011699793924
train metrics, batch: 4096  acc, f1 
0.9444656372070312, 0.944363338964007
eval metrics, batch: 5120 acc, f1
0.84381103515625, 0.8262257232106478
eval metrics, batch: 6144 acc, f1
0.845550537109375, 0.8286439817166075
eval metrics, batch: 7168 acc, f1
0.848297119140625, 0.8321572070094878
Epoch loss - train: tensor(0.1688, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4058, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.841705322265625, 0.8229874074326861
train metrics acc, f1 
0.9493331909179688, 0.9487062639993821
Epoch 6/8
----------
eval metrics, batch: 1024 acc, f1
0.841766357421875, 0.8241717250500187
eval metrics, batch: 2048 acc, f1
0.84002685546875, 0.8207250341997264
eval metrics, batch: 3072 acc, f1
0.84722900390625, 0.8310610151187905
eval metrics, batch: 4096 acc, f1
0.845611572265625, 0.8291628676594739
train metrics, batch: 4096  acc, f1 
0.9512596130371094, 0.9509337450029377
eval metrics, batch: 5120 acc, f1
0.846466064453125, 0.8294055813638059
eval metrics, batch: 6144 acc, f1
0.850921630859375, 0.835172250902588
eval metrics, batch: 7168 acc, f1
0.860260009765625, 0.8506182102893681
Epoch loss - train: tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.3928, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.84893798828125, 0.834070796460177
train metrics acc, f1 
0.9541740417480469, 0.9540876969703919
Epoch 7/8
----------
eval metrics, batch: 1024 acc, f1
0.8436279296875, 0.8283071974266184
eval metrics, batch: 2048 acc, f1
0.83648681640625, 0.8149606299212598
eval metrics, batch: 3072 acc, f1
0.845611572265625, 0.8286304664476135
eval metrics, batch: 4096 acc, f1
0.85260009765625, 0.8391929684378745
train metrics, batch: 4096  acc, f1 
0.9551734924316406, 0.9551890479913056
eval metrics, batch: 5120 acc, f1
0.843292236328125, 0.8241739428180106
eval metrics, batch: 6144 acc, f1
0.841644287109375, 0.8222762612597184
eval metrics, batch: 7168 acc, f1
0.851715087890625, 0.8358723188650565
Epoch loss - train: tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4456, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8359375, 0.8137859369587808
train metrics acc, f1 
0.9591445922851562, 0.9585324113151149
Epoch 8/8
----------
eval metrics, batch: 1024 acc, f1
0.83172607421875, 0.8077137676105454
eval metrics, batch: 2048 acc, f1
0.84588623046875, 0.8288019526747576
eval metrics, batch: 3072 acc, f1
0.839874267578125, 0.8199691199176531
eval metrics, batch: 4096 acc, f1
0.843353271484375, 0.824398754746673
train metrics, batch: 4096  acc, f1 
0.9610977172851562, 0.9607061942265308
eval metrics, batch: 5120 acc, f1
0.840362548828125, 0.8205057818344028
eval metrics, batch: 6144 acc, f1
0.848602294921875, 0.8337745015915564
eval metrics, batch: 7168 acc, f1
0.842376708984375, 0.8235093114642064
Epoch loss - train: tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4372, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.8419189453125, 0.8228575336844265
train metrics acc, f1 
0.9642105102539062, 0.9639796670557159
Training time 112m 18s
train_acc
0.4691581726074219	0.8846397399902344	0.908935546875	0.9135856628417969	0.92510986328125	0.9275550842285156	0.9338111877441406	0.936737060546875	0.9428520202636719	0.9444656372070312	0.9493331909179688	0.9512596130371094	0.9541740417480469	0.9551734924316406	0.9591445922851562	0.9610977172851562	0.9642105102539062
train_f1
0.06756856359847495	0.8820705603412977	0.9073701855545294	0.912091707445797	0.924665576865517	0.9268814803121715	0.9338119452063155	0.9366626437922975	0.9425841538243377	0.944363338964007	0.9487062639993821	0.9509337450029377	0.9540876969703919	0.9551890479913056	0.9585324113151149	0.9607061942265308	0.9639796670557159
train_loss
tensor(0.3264, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2461, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1688, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1408, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.4749755859375	0.7744140625	0.823638916015625	0.829254150390625	0.832977294921875	0.83636474609375	0.838836669921875	0.837921142578125	0.840911865234375	0.80938720703125	0.843017578125	0.84124755859375	0.83782958984375	0.83831787109375	0.843902587890625	0.840301513671875	0.848663330078125	0.82379150390625	0.839019775390625	0.84130859375	0.8436279296875	0.844085693359375	0.837738037109375	0.84405517578125	0.855743408203125	0.829498291015625	0.85101318359375	0.844635009765625	0.852935791015625	0.846527099609375	0.844970703125	0.85382080078125	0.85107421875	0.847503662109375	0.8397216796875	0.85211181640625	0.85015869140625	0.84381103515625	0.845550537109375	0.848297119140625	0.841705322265625	0.841766357421875	0.84002685546875	0.84722900390625	0.845611572265625	0.846466064453125	0.850921630859375	0.860260009765625	0.84893798828125	0.8436279296875	0.83648681640625	0.845611572265625	0.85260009765625	0.843292236328125	0.841644287109375	0.851715087890625	0.8359375	0.83172607421875	0.84588623046875	0.839874267578125	0.843353271484375	0.840362548828125	0.848602294921875	0.842376708984375	0.8419189453125
valid_f1
0.07674144037780402	0.7491005362840268	0.8112733091669116	0.8150107455777814	0.8192834736668317	0.8224503311258278	0.8247552679608429	0.8230433478825843	0.8264358248709839	0.7808728599494807	0.8325956782087998	0.8277711561382598	0.8219884764839877	0.8206135301686193	0.8316271108331413	0.8236919241265456	0.8360606962213627	0.7995973899763987	0.8219649667555435	0.8260753227640645	0.8289833789466657	0.8287926007841561	0.818785999113868	0.827388190785029	0.8447975834783465	0.8067383859697672	0.8396294592996518	0.829452949649928	0.8411301223090364	0.8304507602575772	0.8279249373348689	0.8414642218838949	0.8371052807263503	0.8347170310587768	0.8205916512946642	0.839928651648279	0.8368011699793924	0.8262257232106478	0.8286439817166075	0.8321572070094878	0.8229874074326861	0.8241717250500187	0.8207250341997264	0.8310610151187905	0.8291628676594739	0.8294055813638059	0.835172250902588	0.8506182102893681	0.834070796460177	0.8283071974266184	0.8149606299212598	0.8286304664476135	0.8391929684378745	0.8241739428180106	0.8222762612597184	0.8358723188650565	0.8137859369587808	0.8077137676105454	0.8288019526747576	0.8199691199176531	0.824398754746673	0.8205057818344028	0.8337745015915564	0.8235093114642064	0.8228575336844265
valid_loss
tensor(0.3687, device='cuda:0')	tensor(0.3546, device='cuda:0')	tensor(0.3523, device='cuda:0')	tensor(0.3676, device='cuda:0')	tensor(0.4058, device='cuda:0')	tensor(0.3928, device='cuda:0')	tensor(0.4456, device='cuda:0')	tensor(0.4372, device='cuda:0')
Experiment end
########################################
----------------------------------------
Starting experiment resnet_9
Experiment parameters Experiment[name: resnet_9, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 1e-05, weight_decay: 0, batch_size: 32, num_epochs: 8), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.521514892578125, 0.674662295354097
train metrics acc, f1
0.5159645080566406, 0.6704019741541658
Epoch 1/8
----------
eval metrics, batch: 1024 acc, f1
0.615875244140625, 0.6337048569682507
eval metrics, batch: 2048 acc, f1
0.67401123046875, 0.6820644085957498
eval metrics, batch: 3072 acc, f1
0.7083740234375, 0.7102134885977681
eval metrics, batch: 4096 acc, f1
0.732574462890625, 0.7319609702382773
train metrics, batch: 4096  acc, f1 
0.7330780029296875, 0.7370580808080808
eval metrics, batch: 5120 acc, f1
0.7459716796875, 0.7436086983305612
eval metrics, batch: 6144 acc, f1
0.7557373046875, 0.7467569448838828
eval metrics, batch: 7168 acc, f1
0.763885498046875, 0.7559690900488882
Epoch loss - train: tensor(0.5646, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4990, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.769927978515625, 0.7622591529753082
train metrics acc, f1 
0.7738304138183594, 0.7714053276681716
Epoch 2/8
----------
eval metrics, batch: 1024 acc, f1
0.7730712890625, 0.7635612082670906
eval metrics, batch: 2048 acc, f1
0.775726318359375, 0.7647793105655667
eval metrics, batch: 3072 acc, f1
0.7777099609375, 0.7670759785111282
eval metrics, batch: 4096 acc, f1
0.7786865234375, 0.7667717244484467
train metrics, batch: 4096  acc, f1 
0.7886428833007812, 0.782862920608545
eval metrics, batch: 5120 acc, f1
0.78021240234375, 0.7678122380553227
eval metrics, batch: 6144 acc, f1
0.7822265625, 0.7709002183125723
eval metrics, batch: 7168 acc, f1
0.783355712890625, 0.7718463763458139
Epoch loss - train: tensor(0.4709, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4622, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.783203125, 0.7705574575285834
train metrics acc, f1 
0.7961387634277344, 0.7904282728303026
Epoch 3/8
----------
eval metrics, batch: 1024 acc, f1
0.78424072265625, 0.7698567708333334
eval metrics, batch: 2048 acc, f1
0.787841796875, 0.7789928789420142
eval metrics, batch: 3072 acc, f1
0.78668212890625, 0.7751833269008105
eval metrics, batch: 4096 acc, f1
0.7880859375, 0.7781611398632675
train metrics, batch: 4096  acc, f1 
0.8003730773925781, 0.7964716726496291
eval metrics, batch: 5120 acc, f1
0.786590576171875, 0.7742372881355932
eval metrics, batch: 6144 acc, f1
0.7889404296875, 0.7784753363228699
eval metrics, batch: 7168 acc, f1
0.790313720703125, 0.7801068902614651
Epoch loss - train: tensor(0.4475, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4492, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.79132080078125, 0.7815475049517603
train metrics acc, f1 
0.8039093017578125, 0.8001803678882963
Epoch 4/8
----------
eval metrics, batch: 1024 acc, f1
0.792633056640625, 0.7833296132138644
eval metrics, batch: 2048 acc, f1
0.79193115234375, 0.7803337843933243
eval metrics, batch: 3072 acc, f1
0.792694091796875, 0.7815123347592551
eval metrics, batch: 4096 acc, f1
0.7947998046875, 0.7859280483922317
train metrics, batch: 4096  acc, f1 
0.8058052062988281, 0.8026806928870163
eval metrics, batch: 5120 acc, f1
0.792449951171875, 0.7798815418972715
eval metrics, batch: 6144 acc, f1
0.792816162109375, 0.7804120710288838
eval metrics, batch: 7168 acc, f1
0.793426513671875, 0.7825360619397951
Epoch loss - train: tensor(0.4342, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4417, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.79327392578125, 0.7835367802134594
train metrics acc, f1 
0.8078994750976562, 0.8045897618973706
Epoch 5/8
----------
eval metrics, batch: 1024 acc, f1
0.78729248046875, 0.7717747216764899
eval metrics, batch: 2048 acc, f1
0.788482666015625, 0.7736520688416446
eval metrics, batch: 3072 acc, f1
0.790008544921875, 0.7771047261183636
eval metrics, batch: 4096 acc, f1
0.7916259765625, 0.7795997417688831
train metrics, batch: 4096  acc, f1 
0.8090896606445312, 0.8046466964892147
eval metrics, batch: 5120 acc, f1
0.79156494140625, 0.7798620511828789
eval metrics, batch: 6144 acc, f1
0.791229248046875, 0.7785008903998705
eval metrics, batch: 7168 acc, f1
0.791351318359375, 0.7794018004065434
Epoch loss - train: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4408, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.792877197265625, 0.7816350825263022
train metrics acc, f1 
0.8102951049804688, 0.8063081309299391
Epoch 6/8
----------
eval metrics, batch: 1024 acc, f1
0.796051025390625, 0.7829419597908344
eval metrics, batch: 2048 acc, f1
0.796844482421875, 0.7852788439828404
eval metrics, batch: 3072 acc, f1
0.79730224609375, 0.7868694647670389
eval metrics, batch: 4096 acc, f1
0.7969970703125, 0.787258539081489
train metrics, batch: 4096  acc, f1 
0.8124008178710938, 0.8091271812705707
eval metrics, batch: 5120 acc, f1
0.797149658203125, 0.7861119155645654
eval metrics, batch: 6144 acc, f1
0.796905517578125, 0.7852602368429544
eval metrics, batch: 7168 acc, f1
0.796600341796875, 0.7846735372984848
Epoch loss - train: tensor(0.4207, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4355, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.796600341796875, 0.7867131748215943
train metrics acc, f1 
0.8136520385742188, 0.8105693389897548
Epoch 7/8
----------
eval metrics, batch: 1024 acc, f1
0.791748046875, 0.7784415584415585
eval metrics, batch: 2048 acc, f1
0.7921142578125, 0.7779516265727883
eval metrics, batch: 3072 acc, f1
0.793548583984375, 0.7791741472172352
eval metrics, batch: 4096 acc, f1
0.79583740234375, 0.7837331092002328
train metrics, batch: 4096  acc, f1 
0.8145484924316406, 0.8098265104543587
eval metrics, batch: 5120 acc, f1
0.796844482421875, 0.7863675748531819
eval metrics, batch: 6144 acc, f1
0.796112060546875, 0.784017069149452
eval metrics, batch: 7168 acc, f1
0.79656982421875, 0.7855488354137177
Epoch loss - train: tensor(0.4176, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4339, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7972412109375, 0.7863940329218106
train metrics acc, f1 
0.8157539367675781, 0.8118633702473094
Epoch 8/8
----------
eval metrics, batch: 1024 acc, f1
0.7939453125, 0.7809499091616922
eval metrics, batch: 2048 acc, f1
0.795440673828125, 0.7840458777666807
eval metrics, batch: 3072 acc, f1
0.79595947265625, 0.7854575792581183
eval metrics, batch: 4096 acc, f1
0.794586181640625, 0.781595768843895
train metrics, batch: 4096  acc, f1 
0.8162994384765625, 0.8111381284806651
eval metrics, batch: 5120 acc, f1
0.794525146484375, 0.7812469540920758
eval metrics, batch: 6144 acc, f1
0.79437255859375, 0.781955860462106
eval metrics, batch: 7168 acc, f1
0.797119140625, 0.7874816188223259
Epoch loss - train: tensor(0.4155, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.4324, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.794525146484375, 0.7815308738116097
train metrics acc, f1 
0.816925048828125, 0.8119096702383658
Training time 97m 54s
train_acc
0.5159645080566406	0.7330780029296875	0.7738304138183594	0.7886428833007812	0.7961387634277344	0.8003730773925781	0.8039093017578125	0.8058052062988281	0.8078994750976562	0.8090896606445312	0.8102951049804688	0.8124008178710938	0.8136520385742188	0.8145484924316406	0.8157539367675781	0.8162994384765625	0.816925048828125
train_f1
0.6704019741541658	0.7370580808080808	0.7714053276681716	0.782862920608545	0.7904282728303026	0.7964716726496291	0.8001803678882963	0.8026806928870163	0.8045897618973706	0.8046466964892147	0.8063081309299391	0.8091271812705707	0.8105693389897548	0.8098265104543587	0.8118633702473094	0.8111381284806651	0.8119096702383658
train_loss
tensor(0.5646, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4709, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4475, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4342, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4207, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4176, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.4155, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.521514892578125	0.615875244140625	0.67401123046875	0.7083740234375	0.732574462890625	0.7459716796875	0.7557373046875	0.763885498046875	0.769927978515625	0.7730712890625	0.775726318359375	0.7777099609375	0.7786865234375	0.78021240234375	0.7822265625	0.783355712890625	0.783203125	0.78424072265625	0.787841796875	0.78668212890625	0.7880859375	0.786590576171875	0.7889404296875	0.790313720703125	0.79132080078125	0.792633056640625	0.79193115234375	0.792694091796875	0.7947998046875	0.792449951171875	0.792816162109375	0.793426513671875	0.79327392578125	0.78729248046875	0.788482666015625	0.790008544921875	0.7916259765625	0.79156494140625	0.791229248046875	0.791351318359375	0.792877197265625	0.796051025390625	0.796844482421875	0.79730224609375	0.7969970703125	0.797149658203125	0.796905517578125	0.796600341796875	0.796600341796875	0.791748046875	0.7921142578125	0.793548583984375	0.79583740234375	0.796844482421875	0.796112060546875	0.79656982421875	0.7972412109375	0.7939453125	0.795440673828125	0.79595947265625	0.794586181640625	0.794525146484375	0.79437255859375	0.797119140625	0.794525146484375
valid_f1
0.674662295354097	0.6337048569682507	0.6820644085957498	0.7102134885977681	0.7319609702382773	0.7436086983305612	0.7467569448838828	0.7559690900488882	0.7622591529753082	0.7635612082670906	0.7647793105655667	0.7670759785111282	0.7667717244484467	0.7678122380553227	0.7709002183125723	0.7718463763458139	0.7705574575285834	0.7698567708333334	0.7789928789420142	0.7751833269008105	0.7781611398632675	0.7742372881355932	0.7784753363228699	0.7801068902614651	0.7815475049517603	0.7833296132138644	0.7803337843933243	0.7815123347592551	0.7859280483922317	0.7798815418972715	0.7804120710288838	0.7825360619397951	0.7835367802134594	0.7717747216764899	0.7736520688416446	0.7771047261183636	0.7795997417688831	0.7798620511828789	0.7785008903998705	0.7794018004065434	0.7816350825263022	0.7829419597908344	0.7852788439828404	0.7868694647670389	0.787258539081489	0.7861119155645654	0.7852602368429544	0.7846735372984848	0.7867131748215943	0.7784415584415585	0.7779516265727883	0.7791741472172352	0.7837331092002328	0.7863675748531819	0.784017069149452	0.7855488354137177	0.7863940329218106	0.7809499091616922	0.7840458777666807	0.7854575792581183	0.781595768843895	0.7812469540920758	0.781955860462106	0.7874816188223259	0.7815308738116097
valid_loss
tensor(0.4990, device='cuda:0')	tensor(0.4622, device='cuda:0')	tensor(0.4492, device='cuda:0')	tensor(0.4417, device='cuda:0')	tensor(0.4408, device='cuda:0')	tensor(0.4355, device='cuda:0')	tensor(0.4339, device='cuda:0')	tensor(0.4324, device='cuda:0')
Experiment end
########################################
----------------------------------------
Starting experiment resnet_10
Experiment parameters Experiment[name: resnet_10, model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1, bias=True)
), params: Params(lr: 1e-06, weight_decay: 0, batch_size: 32, num_epochs: 8), optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-06
    weight_decay: 0
), criterion: BCEWithLogitsLoss()]
start metrics
eval metrics acc, f1
0.51641845703125, 0.6725085768610756
train metrics acc, f1
0.508758544921875, 0.6652403803661205
Epoch 1/8
----------
eval metrics, batch: 1024 acc, f1
0.512176513671875, 0.612550597474368
eval metrics, batch: 2048 acc, f1
0.517669677734375, 0.5923499522839235
eval metrics, batch: 3072 acc, f1
0.527191162109375, 0.5839353331363966
eval metrics, batch: 4096 acc, f1
0.536834716796875, 0.585248544803651
train metrics, batch: 4096  acc, f1 
0.5448951721191406, 0.6019717417051729
eval metrics, batch: 5120 acc, f1
0.54656982421875, 0.5884894477372182
eval metrics, batch: 6144 acc, f1
0.55523681640625, 0.5922672336615935
eval metrics, batch: 7168 acc, f1
0.562957763671875, 0.5974420238931835
Epoch loss - train: tensor(0.7042, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6832, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.570953369140625, 0.6054057088326925
train metrics acc, f1 
0.5767478942871094, 0.6197648397366698
Epoch 2/8
----------
eval metrics, batch: 1024 acc, f1
0.589324951171875, 0.6278587428445009
eval metrics, batch: 2048 acc, f1
0.596527099609375, 0.6317783038574015
eval metrics, batch: 3072 acc, f1
0.603790283203125, 0.6367680384970483
eval metrics, batch: 4096 acc, f1
0.609375, 0.6419780711568583
train metrics, batch: 4096  acc, f1 
0.6092758178710938, 0.6495572677879812
eval metrics, batch: 5120 acc, f1
0.615997314453125, 0.6482346034497218
eval metrics, batch: 6144 acc, f1
0.6217041015625, 0.6517586245645578
eval metrics, batch: 7168 acc, f1
0.62890625, 0.6561085972850679
Epoch loss - train: tensor(0.6522, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6349, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.634765625, 0.6613277491652046
train metrics acc, f1 
0.6335830688476562, 0.6672947566036037
Epoch 3/8
----------
eval metrics, batch: 1024 acc, f1
0.631561279296875, 0.6568513202398886
eval metrics, batch: 2048 acc, f1
0.63677978515625, 0.6600788256126121
eval metrics, batch: 3072 acc, f1
0.641357421875, 0.6654520610339331
eval metrics, batch: 4096 acc, f1
0.647430419921875, 0.6684650041610468
train metrics, batch: 4096  acc, f1 
0.6487197875976562, 0.6763074457091034
eval metrics, batch: 5120 acc, f1
0.65179443359375, 0.6729534510433387
eval metrics, batch: 6144 acc, f1
0.656524658203125, 0.6753771163219983
eval metrics, batch: 7168 acc, f1
0.662078857421875, 0.6812883170710646
Epoch loss - train: tensor(0.6220, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.6082, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.6663818359375, 0.684301721150514
train metrics acc, f1 
0.6683082580566406, 0.692166352168972
Epoch 4/8
----------
eval metrics, batch: 1024 acc, f1
0.68170166015625, 0.6972599558806455
eval metrics, batch: 2048 acc, f1
0.686126708984375, 0.6994711159161967
eval metrics, batch: 3072 acc, f1
0.6898193359375, 0.7031195233087978
eval metrics, batch: 4096 acc, f1
0.694122314453125, 0.7045541635961681
train metrics, batch: 4096  acc, f1 
0.6945037841796875, 0.7105265060328063
eval metrics, batch: 5120 acc, f1
0.697509765625, 0.7067629134370748
eval metrics, batch: 6144 acc, f1
0.700286865234375, 0.7093948808995414
eval metrics, batch: 7168 acc, f1
0.70263671875, 0.7108948492760503
Epoch loss - train: tensor(0.5888, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5776, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.705230712890625, 0.7146444503530385
train metrics acc, f1 
0.7067909240722656, 0.7218021709152374
Epoch 5/8
----------
eval metrics, batch: 1024 acc, f1
0.705230712890625, 0.7108516689118396
eval metrics, batch: 2048 acc, f1
0.70855712890625, 0.7143797104916856
eval metrics, batch: 3072 acc, f1
0.71099853515625, 0.7172627933361199
eval metrics, batch: 4096 acc, f1
0.7137451171875, 0.7198159985662226
train metrics, batch: 4096  acc, f1 
0.7129402160644531, 0.7235665139721036
eval metrics, batch: 5120 acc, f1
0.7156982421875, 0.7223910840932117
eval metrics, batch: 6144 acc, f1
0.71728515625, 0.7246135552913199
eval metrics, batch: 7168 acc, f1
0.72003173828125, 0.7265247719549276
Epoch loss - train: tensor(0.5710, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5612, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.7222900390625, 0.7280009564801531
train metrics acc, f1 
0.7233924865722656, 0.7332771767717824
Epoch 6/8
----------
eval metrics, batch: 1024 acc, f1
0.726470947265625, 0.7281055665099347
eval metrics, batch: 2048 acc, f1
0.72821044921875, 0.7312937484914314
eval metrics, batch: 3072 acc, f1
0.729766845703125, 0.7334998645679718
eval metrics, batch: 4096 acc, f1
0.73175048828125, 0.7344892164562316
train metrics, batch: 4096  acc, f1 
0.7356452941894531, 0.743077259599521
eval metrics, batch: 5120 acc, f1
0.733428955078125, 0.7344419785364668
eval metrics, batch: 6144 acc, f1
0.73529052734375, 0.7361922141119221
eval metrics, batch: 7168 acc, f1
0.737457275390625, 0.7378652609768731
Epoch loss - train: tensor(0.5501, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5453, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.738494873046875, 0.7387579646961983
train metrics acc, f1 
0.7429580688476562, 0.7482721777658231
Epoch 7/8
----------
eval metrics, batch: 1024 acc, f1
0.739715576171875, 0.7378676583581768
eval metrics, batch: 2048 acc, f1
0.740386962890625, 0.7394087915454127
eval metrics, batch: 3072 acc, f1
0.74151611328125, 0.7410736121301051
eval metrics, batch: 4096 acc, f1
0.743316650390625, 0.7421599583090647
train metrics, batch: 4096  acc, f1 
0.7468376159667969, 0.7504596745992653
eval metrics, batch: 5120 acc, f1
0.744354248046875, 0.7429816218206363
eval metrics, batch: 6144 acc, f1
0.74615478515625, 0.7447056657049905
eval metrics, batch: 7168 acc, f1
0.74700927734375, 0.7439935766784016
Epoch loss - train: tensor(0.5366, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5324, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.748565673828125, 0.74593727836196
train metrics acc, f1 
0.7524375915527344, 0.7549345769688273
Epoch 8/8
----------
eval metrics, batch: 1024 acc, f1
0.750457763671875, 0.745811184680904
eval metrics, batch: 2048 acc, f1
0.75189208984375, 0.7464920486435921
eval metrics, batch: 3072 acc, f1
0.753204345703125, 0.7476676339355363
eval metrics, batch: 4096 acc, f1
0.7545166015625, 0.7476629650542694
train metrics, batch: 4096  acc, f1 
0.75958251953125, 0.75922614954385
eval metrics, batch: 5120 acc, f1
0.755828857421875, 0.7486570540005655
eval metrics, batch: 6144 acc, f1
0.756744384765625, 0.7497724062156648
eval metrics, batch: 7168 acc, f1
0.7578125, 0.7509571329944141
Epoch loss - train: tensor(0.5219, device='cuda:0', grad_fn=<DivBackward0>)
Epoch loss - valid: tensor(0.5219, device='cuda:0')
epoch end metrics
eval metrics acc, f1 
0.75836181640625, 0.7517712709260769
train metrics acc, f1 
0.7634544372558594, 0.7633668769342904
Training time 97m 56s
train_acc
0.508758544921875	0.5448951721191406	0.5767478942871094	0.6092758178710938	0.6335830688476562	0.6487197875976562	0.6683082580566406	0.6945037841796875	0.7067909240722656	0.7129402160644531	0.7233924865722656	0.7356452941894531	0.7429580688476562	0.7468376159667969	0.7524375915527344	0.75958251953125	0.7634544372558594
train_f1
0.6652403803661205	0.6019717417051729	0.6197648397366698	0.6495572677879812	0.6672947566036037	0.6763074457091034	0.692166352168972	0.7105265060328063	0.7218021709152374	0.7235665139721036	0.7332771767717824	0.743077259599521	0.7482721777658231	0.7504596745992653	0.7549345769688273	0.75922614954385	0.7633668769342904
train_loss
tensor(0.7042, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6522, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.6220, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.5888, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.5710, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.5501, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.5366, device='cuda:0', grad_fn=<DivBackward0>)	tensor(0.5219, device='cuda:0', grad_fn=<DivBackward0>)
valid_acc
0.51641845703125	0.512176513671875	0.517669677734375	0.527191162109375	0.536834716796875	0.54656982421875	0.55523681640625	0.562957763671875	0.570953369140625	0.589324951171875	0.596527099609375	0.603790283203125	0.609375	0.615997314453125	0.6217041015625	0.62890625	0.634765625	0.631561279296875	0.63677978515625	0.641357421875	0.647430419921875	0.65179443359375	0.656524658203125	0.662078857421875	0.6663818359375	0.68170166015625	0.686126708984375	0.6898193359375	0.694122314453125	0.697509765625	0.700286865234375	0.70263671875	0.705230712890625	0.705230712890625	0.70855712890625	0.71099853515625	0.7137451171875	0.7156982421875	0.71728515625	0.72003173828125	0.7222900390625	0.726470947265625	0.72821044921875	0.729766845703125	0.73175048828125	0.733428955078125	0.73529052734375	0.737457275390625	0.738494873046875	0.739715576171875	0.740386962890625	0.74151611328125	0.743316650390625	0.744354248046875	0.74615478515625	0.74700927734375	0.748565673828125	0.750457763671875	0.75189208984375	0.753204345703125	0.7545166015625	0.755828857421875	0.756744384765625	0.7578125	0.75836181640625
valid_f1
0.6725085768610756	0.612550597474368	0.5923499522839235	0.5839353331363966	0.585248544803651	0.5884894477372182	0.5922672336615935	0.5974420238931835	0.6054057088326925	0.6278587428445009	0.6317783038574015	0.6367680384970483	0.6419780711568583	0.6482346034497218	0.6517586245645578	0.6561085972850679	0.6613277491652046	0.6568513202398886	0.6600788256126121	0.6654520610339331	0.6684650041610468	0.6729534510433387	0.6753771163219983	0.6812883170710646	0.684301721150514	0.6972599558806455	0.6994711159161967	0.7031195233087978	0.7045541635961681	0.7067629134370748	0.7093948808995414	0.7108948492760503	0.7146444503530385	0.7108516689118396	0.7143797104916856	0.7172627933361199	0.7198159985662226	0.7223910840932117	0.7246135552913199	0.7265247719549276	0.7280009564801531	0.7281055665099347	0.7312937484914314	0.7334998645679718	0.7344892164562316	0.7344419785364668	0.7361922141119221	0.7378652609768731	0.7387579646961983	0.7378676583581768	0.7394087915454127	0.7410736121301051	0.7421599583090647	0.7429816218206363	0.7447056657049905	0.7439935766784016	0.74593727836196	0.745811184680904	0.7464920486435921	0.7476676339355363	0.7476629650542694	0.7486570540005655	0.7497724062156648	0.7509571329944141	0.7517712709260769
valid_loss
tensor(0.6832, device='cuda:0')	tensor(0.6349, device='cuda:0')	tensor(0.6082, device='cuda:0')	tensor(0.5776, device='cuda:0')	tensor(0.5612, device='cuda:0')	tensor(0.5453, device='cuda:0')	tensor(0.5324, device='cuda:0')	tensor(0.5219, device='cuda:0')
Experiment end
########################################
